From 6427a574d2e5c904ab7f43bef3d04e6e2b1f06d3 Mon Sep 17 00:00:00 2001
From: Ann Thornton <ra43240@freescale.com>
Date: Wed, 26 Nov 2008 12:33:54 -0600
Subject: [PATCH] ENGR00038376 Change ioctl interface between mxc_v4l2_capture and cameras.

Used the bt656 interface.
Implemented code review comments.

Signed-off-by: Ann Thornton <ra43240@freescale.com>
---
 arch/arm/mach-mx3/mx31ads.c                        |   36 +
 drivers/media/video/mxc/capture/Kconfig            |   17 +
 drivers/media/video/mxc/capture/Makefile           |   10 +-
 drivers/media/video/mxc/capture/adv7180.c          |  753 ++++++--
 drivers/media/video/mxc/capture/emma_mt9v111.c     |  679 +++++++
 drivers/media/video/mxc/capture/emma_ov2640.c      |  444 +++++
 .../media/video/mxc/capture/emma_v4l2_capture.c    | 2075 +++++++++++++++++++
 drivers/media/video/mxc/capture/ipu_prp_enc.c      |   22 +-
 drivers/media/video/mxc/capture/ipu_prp_vf_adc.c   |   18 +-
 drivers/media/video/mxc/capture/ipu_prp_vf_sdc.c   |   13 +-
 .../media/video/mxc/capture/ipu_prp_vf_sdc_bg.c    |   12 +-
 drivers/media/video/mxc/capture/ipu_still.c        |    7 +-
 drivers/media/video/mxc/capture/mt9v111.c          |  877 ++++++---
 drivers/media/video/mxc/capture/mt9v111.h          |   22 +-
 .../media/video/mxc/capture/mx27_v4l2_capture.c    | 2076 --------------------
 drivers/media/video/mxc/capture/mxc_v4l2_capture.c | 1677 +++++++++++------
 drivers/media/video/mxc/capture/mxc_v4l2_capture.h |   12 +-
 drivers/media/video/mxc/capture/ov2640.c           |  736 ++++++--
 drivers/media/video/mxc/capture/ov3640.c           |  814 ++++++---
 drivers/media/video/v4l2-int-device.c              |    5 +-
 20 files changed, 6758 insertions(+), 3547 deletions(-)

diff --git a/arch/arm/mach-mx3/mx31ads.c b/arch/arm/mach-mx3/mx31ads.c
index 8b86174..ce854b6 100644
--- a/arch/arm/mach-mx3/mx31ads.c
+++ b/arch/arm/mach-mx3/mx31ads.c
@@ -29,6 +29,7 @@
 #include <linux/platform_device.h>
 #include <linux/fsl_devices.h>
 #include <linux/spi/spi.h>
+#include <linux/i2c.h>
 #include <linux/ata.h>
 #if defined(CONFIG_MTD) || defined(CONFIG_MTD_MODULE)
 #include <linux/mtd/mtd.h>
@@ -423,6 +424,40 @@ static inline void mxc_init_bl(void)
 }
 #endif
 
+/*!
+ * Data structures and data for mt9v111 camera.
+ */
+static struct mxc_camera_platform_data camera_mt9v111_data = {
+	.mclk = 27000000,
+};
+
+/*!
+ * Data structures and data for ov2640 camera.
+ */
+static struct mxc_camera_platform_data camera_ov2640_data = {
+	.core_regulator = NULL,
+	.io_regulator = NULL,
+	.analog_regulator = NULL,
+	.gpo_regulator = NULL,
+	.mclk = 24000000,
+};
+
+/*!
+ * Info to register i2c devices.
+ */
+static struct i2c_board_info mxc_i2c_info[] __initdata = {
+	{
+	 .type = "mt9v111",
+	 .addr = 0x48,
+	 .platform_data = (void *)&camera_mt9v111_data,
+	 },
+	{
+	 .type = "ov2640",
+	 .addr = 0x30,
+	 .platform_data = (void *)&camera_ov2640_data,
+	 },
+};
+
 #if defined(CONFIG_MXC_FIR) || defined(CONFIG_MXC_FIR_MODULE)
 /*!
  * Resource definition for the FIR
@@ -878,6 +913,7 @@ static void __init mxc_board_init(void)
 	mxc_init_nor_mtd();
 	mxc_init_nand_mtd();
 
+	i2c_register_board_info(0, mxc_i2c_info, ARRAY_SIZE(mxc_i2c_info));
 	spi_register_board_info(mxc_spi_board_info,
 				ARRAY_SIZE(mxc_spi_board_info));
 
diff --git a/drivers/media/video/mxc/capture/Kconfig b/drivers/media/video/mxc/capture/Kconfig
index 042cb3c..6c07bfd 100644
--- a/drivers/media/video/mxc/capture/Kconfig
+++ b/drivers/media/video/mxc/capture/Kconfig
@@ -30,22 +30,39 @@ choice
 config MXC_CAMERA_MC521DA
 	tristate "Magnachip mc521da camera support"
 	select I2C_MXC
+	depends on VIDEO_MXC_EMMA_CAMERA
 	---help---
 	  If you plan to use the mc521da Camera with your MXC system, say Y here.
 
+config MXC_EMMA_CAMERA_MICRON111
+	tristate "Micron mt9v111 camera support with eMMA"
+	select I2C_MXC
+	depends on VIDEO_MXC_EMMA_CAMERA
+	---help---
+	  If you plan to use the mt9v111 Camera with your MXC system, say Y here.
+
+config MXC_CAMERA_OV2640_EMMA
+	tristate "OmniVision ov2640 camera support with eMMA"
+	depends on VIDEO_MXC_EMMA_CAMERA
+	---help---
+	  If you plan to use the ov2640 Camera with your MXC system, say Y here.
+
 config MXC_CAMERA_MICRON111
 	tristate "Micron mt9v111 camera support"
 	select I2C_MXC
+	depends on ! VIDEO_MXC_EMMA_CAMERA
 	---help---
 	  If you plan to use the mt9v111 Camera with your MXC system, say Y here.
 
 config MXC_CAMERA_OV2640
 	tristate "OmniVision ov2640 camera support"
+	depends on !VIDEO_MXC_EMMA_CAMERA
 	---help---
 	  If you plan to use the ov2640 Camera with your MXC system, say Y here.
 
 config MXC_CAMERA_OV3640
 	tristate "OmniVision ov3640 camera support"
+	depends on !VIDEO_MXC_EMMA_CAMERA
 	---help---
 	  If you plan to use the ov3640 Camera with your MXC system, say Y here.
 
diff --git a/drivers/media/video/mxc/capture/Makefile b/drivers/media/video/mxc/capture/Makefile
index 1f5bd86..3b6d7c7 100644
--- a/drivers/media/video/mxc/capture/Makefile
+++ b/drivers/media/video/mxc/capture/Makefile
@@ -5,12 +5,15 @@ ifeq ($(CONFIG_VIDEO_MXC_IPU_CAMERA),y)
 	obj-$(CONFIG_MXC_IPU_PRP_ENC) += ipu_prp_enc.o ipu_still.o
 endif
 
-mx27_capture-objs := mx27_prphw.o mx27_prpsw.o mx27_v4l2_capture.o
+mx27_capture-objs := mx27_prphw.o mx27_prpsw.o emma_v4l2_capture.o
 obj-$(CONFIG_VIDEO_MXC_EMMA_CAMERA) += mx27_csi.o mx27_capture.o
 
 mc521da_camera-objs := mc521da.o sensor_clock.o
 obj-$(CONFIG_MXC_CAMERA_MC521DA) += mc521da_camera.o
 
+emma_mt9v111_camera-objs := emma_mt9v111.o sensor_clock.o
+obj-$(CONFIG_MXC_EMMA_CAMERA_MICRON111) += emma_mt9v111_camera.o
+
 mt9v111_camera-objs := mt9v111.o sensor_clock.o
 obj-$(CONFIG_MXC_CAMERA_MICRON111) += mt9v111_camera.o
 
@@ -20,11 +23,14 @@ obj-$(CONFIG_MXC_CAMERA_HV7161) += hv7161_camera.o
 s5k3aaex_camera-objs := s5k3aaex.o sensor_clock.o
 obj-$(CONFIG_MXC_CAMERA_S5K3AAEX) += s5k3aaex_camera.o
 
+emma_ov2640_camera-objs := emma_ov2640.o sensor_clock.o
+obj-$(CONFIG_MXC_CAMERA_OV2640_EMMA) += emma_ov2640_camera.o
+
 ov2640_camera-objs := ov2640.o sensor_clock.o
 obj-$(CONFIG_MXC_CAMERA_OV2640) += ov2640_camera.o
 
 ov3640_camera-objs := ov3640.o sensor_clock.o
 obj-$(CONFIG_MXC_CAMERA_OV3640) += ov3640_camera.o
 
-adv7180_tvin-objs := adv7180.o
+adv7180_tvin-objs := adv7180.o sensor_clock.o
 obj-$(CONFIG_MXC_TVIN_ADV7180) += adv7180_tvin.o
diff --git a/drivers/media/video/mxc/capture/adv7180.c b/drivers/media/video/mxc/capture/adv7180.c
index 6ccd219..478482b 100644
--- a/drivers/media/video/mxc/capture/adv7180.c
+++ b/drivers/media/video/mxc/capture/adv7180.c
@@ -31,20 +31,23 @@
 #include <linux/videodev2.h>
 #include <linux/workqueue.h>
 #include "asm-arm/arch-mxc/pmic_external.h"
+#include <media/v4l2-int-device.h>
 #include "mxc_v4l2_capture.h"
 
 extern void gpio_sensor_active(void);
+extern void gpio_sensor_inactive(void);
 extern PMIC_STATUS pmic_gpio_set_bit_val(t_mcu_gpio_reg reg, unsigned int bit,
 					 unsigned int val);
-struct i2c_client *adv7180_i2c_client;
 
-static int adv7180_probe(struct i2c_client *adapter, const struct i2c_device_id *id);
+static int adv7180_probe(struct i2c_client *adapter,
+			 const struct i2c_device_id *id);
 static int adv7180_detach(struct i2c_client *client);
 
 static const struct i2c_device_id adv7180_id[] = {
-	{ "adv7180", 0 },
+	{"adv7180", 0},
 	{},
 };
+
 MODULE_DEVICE_TABLE(i2c, adv7180_id);
 
 static struct i2c_driver adv7180_i2c_driver = {
@@ -57,10 +60,28 @@ static struct i2c_driver adv7180_i2c_driver = {
 	.id_table = adv7180_id,
 };
 
-/*! Structure initialized by adv7180_interface() and used to configure the
- *  CSI.
+/*!
+ * Maintains the information on the current state of the sesor.
  */
-static sensor_interface *interface_param;
+struct sensor {
+	struct v4l2_int_device *v4l2_int_device;
+	struct i2c_client *i2c_client;
+	struct v4l2_pix_format pix;
+	struct v4l2_captureparm streamcap;
+	bool on;
+
+	/* control settings */
+	int brightness;
+	int hue;
+	int contrast;
+	int saturation;
+	int red;
+	int green;
+	int blue;
+	int ae_mode;
+
+	v4l2_std_id std_id;
+} adv7180_data;
 
 /*! List of input video formats supported. The video formats is corresponding
  * with v4l2 id in video_fmt_t
@@ -114,7 +135,6 @@ static video_fmt_t video_fmts[] = {
 	 .active_width = 720,
 	 .active_height = (576 / 2),
 	 },
-
 };
 
 /*!* Standard index of ADV7180. */
@@ -128,15 +148,40 @@ static video_fmt_idx video_idx = ADV7180_PAL;
  */
 static DECLARE_MUTEX(mutex);
 
-#define IF_NAME                 "adv7180"
-#define ADV7180_INPUT_CTL              0x00     /* Input Control */
-#define ADV7180_STATUS_1               0x10     /* Status #1 */
-#define ADV7180_BRIGHTNESS             0x0a     /* Brightness */
-#define ADV7180_IDENT                  0x11     /* IDENT */
-#define ADV7180_VSYNC_FIELD_CTL_1      0x31     /* VSYNC Field Control #1 */
-#define ADV7180_MANUAL_WIN_CTL         0x3d     /* Manual Window Control */
-#define ADV7180_SD_SATURATION_CB       0xe3     /* SD Saturation Cb */
-#define ADV7180_SD_SATURATION_CR       0xe4     /* SD Saturation Cr */
+#define IF_NAME                    "adv7180"
+#define ADV7180_INPUT_CTL              0x00	/* Input Control */
+#define ADV7180_STATUS_1               0x10	/* Status #1 */
+#define ADV7180_BRIGHTNESS             0x0a	/* Brightness */
+#define ADV7180_IDENT                  0x11	/* IDENT */
+#define ADV7180_VSYNC_FIELD_CTL_1      0x31	/* VSYNC Field Control #1 */
+#define ADV7180_MANUAL_WIN_CTL         0x3d	/* Manual Window Control */
+#define ADV7180_SD_SATURATION_CB       0xe3	/* SD Saturation Cb */
+#define ADV7180_SD_SATURATION_CR       0xe4	/* SD Saturation Cr */
+
+/* supported controls */
+/* This hasn't been fully implemented yet.
+ * This is how it should work, though. */
+static struct v4l2_queryctrl adv7180_qctrl[] = {
+	{
+	.id = V4L2_CID_BRIGHTNESS,
+	.type = V4L2_CTRL_TYPE_INTEGER,
+	.name = "Brightness",
+	.minimum = 0,		/* check this value */
+	.maximum = 255,		/* check this value */
+	.step = 1,		/* check this value */
+	.default_value = 127,	/* check this value */
+	.flags = 0,
+	}, {
+	.id = V4L2_CID_SATURATION,
+	.type = V4L2_CTRL_TYPE_INTEGER,
+	.name = "Saturation",
+	.minimum = 0,		/* check this value */
+	.maximum = 255,		/* check this value */
+	.step = 0x1,		/* check this value */
+	.default_value = 127,	/* check this value */
+	.flags = 0,
+	}
+};
 
 /***********************************************************************
  * I2C transfert.
@@ -151,9 +196,9 @@ static DECLARE_MUTEX(mutex);
 static inline int adv7180_read(u8 reg)
 {
 	int val;
-	val = i2c_smbus_read_byte_data(adv7180_i2c_client, reg);
+	val = i2c_smbus_read_byte_data(adv7180_data.i2c_client, reg);
 	if (val < 0) {
-		dev_dbg(&adv7180_i2c_client->dev,
+		dev_dbg(&adv7180_data.i2c_client->dev,
 			"%s:read reg error: reg=%2x \n", __func__, reg);
 		return -1;
 	}
@@ -168,8 +213,8 @@ static inline int adv7180_read(u8 reg)
  */
 static int adv7180_write_reg(u8 reg, u8 val)
 {
-	if (i2c_smbus_write_byte_data(adv7180_i2c_client, reg, val) < 0) {
-		dev_dbg(&adv7180_i2c_client->dev,
+	if (i2c_smbus_write_byte_data(adv7180_data.i2c_client, reg, val) < 0) {
+		dev_dbg(&adv7180_data.i2c_client->dev,
 			"%s:write reg error:reg=%2x,val=%2x\n", __func__,
 			reg, val);
 		return -1;
@@ -181,164 +226,523 @@ static int adv7180_write_reg(u8 reg, u8 val)
  * mxc_v4l2_capture interface.
  ***********************************************************************/
 
-/*! Set video standard.
- *
- *  @param std		Video standard.
+/*!
+ * Return attributes of current video standard.
+ * Since this device autodetects the current standard, this function also
+ * sets the values that need to be changed if the standard changes.
+ * There is no set std equivalent function.
  *
- *  @return		       None.
+ *  @return		None.
  */
-static void adv7180_set_std(v4l2_std_id std)
+static void adv7180_get_std(v4l2_std_id *std)
 {
-	unsigned int dummy = 0;
+	int tmp;
+	int idx;
+
+	dev_dbg(&adv7180_data.i2c_client->dev, "In adv7180_get_std\n");
+
+	/* Read the AD_RESULT to get the detect output video standard */
+	tmp = adv7180_read(ADV7180_STATUS_1) & 0x70;
 
-	dev_dbg(&adv7180_i2c_client->dev, "adv7180_set_std call \n");
 	down(&mutex);
-	if (std == V4L2_STD_PAL) {
-		video_idx = ADV7180_PAL;
-		ipu_csi_set_window_pos(0, 0, dummy);
-	} else if (std == V4L2_STD_NTSC) {
-		video_idx = ADV7180_NTSC;
-		/* Get rid of the white dot line in NTSC signal input */
-		ipu_csi_set_window_pos(0, 12, dummy);
+	if (tmp == 0x40) {
+		/* PAL */
+		*std = V4L2_STD_PAL;
+		idx = ADV7180_PAL;
+	} else if (tmp == 0) {
+		/*NTSC*/
+		*std = V4L2_STD_NTSC;
+		idx = ADV7180_NTSC;
 	} else {
-		video_idx = ADV7180_NOT_LOCKED;
-		ipu_csi_set_window_pos(0, 0, dummy);
-		dev_dbg(&adv7180_i2c_client->dev,
-			"adv7180 set non-recognized std!\n");
+		*std = V4L2_STD_ALL;
+		idx = ADV7180_NOT_LOCKED;
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"Got invalid video standard! \n");
 	}
 	up(&mutex);
+
+	/* This assumes autodetect which this device uses. */
+	if (*std != adv7180_data.std_id) {
+		video_idx = idx;
+		adv7180_data.std_id = *std;
+		adv7180_data.pix.width = video_fmts[video_idx].raw_width;
+		adv7180_data.pix.height = video_fmts[video_idx].raw_height;
+	}
 }
 
-/*! ADV7180 video decoder interface initialization.
+/***********************************************************************
+ * IOCTL Functions from v4l2_int_ioctl_desc.
+ ***********************************************************************/
+
+/*!
+ * ioctl_g_ifparm - V4L2 sensor interface handler for vidioc_int_g_ifparm_num
+ * s: pointer to standard V4L2 device structure
+ * p: pointer to standard V4L2 vidioc_int_g_ifparm_num ioctl structure
  *
- *  @param *param	sensor_interface *.
- *  @param width	u32.
- *  @param height	u32.
+ * Gets slave interface parameters.
+ * Calculates the required xclk value to support the requested
+ * clock parameters in p.  This value is returned in the p
+ * parameter.
  *
- *  @return		None.
+ * vidioc_int_g_ifparm returns platform-specific information about the
+ * interface settings used by the sensor.
+ *
+ * Called on open.
  */
-static void adv7180_interface(sensor_interface *param, u32 width, u32 height)
+static int ioctl_g_ifparm(struct v4l2_int_device *s, struct v4l2_ifparm *p)
 {
-	param->clk_mode = IPU_CSI_CLK_MODE_CCIR656_PROGRESSIVE;
-	param->ext_vsync = 0x00;
-	param->Vsync_pol = 0x00;
-	param->Hsync_pol = 0x01;	/*! Signal is inverted. */
-	param->pixclk_pol = 0x00;
-	param->data_pol = 0x00;
-	param->data_width = IPU_CSI_DATA_WIDTH_8;
-	param->width = width - 1;
-	param->height = height - 1;
-	param->active_width = video_fmts[video_idx].active_width;
-	param->active_height = video_fmts[video_idx].active_height;
-	param->pixel_fmt = IPU_PIX_FMT_UYVY;	/*! YUV422. */
-
-	/*! Not used, ADV7180 has a dedicated clock */
-	param->mclk = 27000000;
+	dev_dbg(&adv7180_data.i2c_client->dev, "In adv7180:ioctl_g_ifparm\n");
+
+	if (s == NULL) {
+		pr_err("   ERROR!! no slave device set!\n");
+		return -1;
+	}
+
+	/* Initialize structure to 0s then set any non-0 values. */
+	memset(p, 0, sizeof(*p));
+	p->if_type = V4L2_IF_TYPE_BT656; /* This is the only possibility. */
+	p->u.bt656.mode = V4L2_IF_TYPE_BT656_MODE_NOBT_8BIT;
+	p->u.bt656.nobt_hs_inv = 1;
+
+	/* ADV7180 has a dedicated clock so no clock settings needed. */
+
+	return 0;
 }
 
-/*! ADV7180 video decoder set color configuration.
+/*!
+ * Sets the camera power.
  *
- *  @param bright	Brightness.
- *  @param saturation	Saturation.
- *  @param red		Red.
- *  @param green	Green.
- *  @param blue		Blue.
+ * s  pointer to the camera device
+ * on if 1, power is to be turned on.  0 means power is to be turned off
  *
- *  @return		None.
+ * ioctl_s_power - V4L2 sensor interface handler for vidioc_int_s_power_num
+ * @s: pointer to standard V4L2 device structure
+ * @on: power state to which device is to be set
+ *
+ * Sets devices power state to requrested state, if possible.
+ * This is called on open, close, suspend and resume.
  */
-static void
-adv7180_set_color(int bright, int saturation, int red, int green, int blue)
+static int ioctl_s_power(struct v4l2_int_device *s, int on)
 {
-	u8 b = (u8) bright, s = (u8) saturation;
+	struct sensor *sensor = s->priv;
 
-	adv7180_write_reg(ADV7180_BRIGHTNESS, b);
-	adv7180_write_reg(ADV7180_SD_SATURATION_CB, s);
-	adv7180_write_reg(ADV7180_SD_SATURATION_CR, s);
+	dev_dbg(&adv7180_data.i2c_client->dev, "In adv7180:ioctl_s_power\n");
+
+	sensor->on = on;
+
+	if (on)
+		gpio_sensor_active();
+	else
+		gpio_sensor_inactive();
+
+	return 0;
 }
 
-/*! ADV7180 video decoder get color configuration.
- *
- *  @param *bright	Brightness.
- *  @param *saturation	Saturation.
- *  @param *red		Red.
- *  @param *green	Green.
- *  @param *blue	Blue.
+/*!
+ * ioctl_g_parm - V4L2 sensor interface handler for VIDIOC_G_PARM ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @a: pointer to standard V4L2 VIDIOC_G_PARM ioctl structure
  *
- *  @return		None.
+ * Returns the sensor's video CAPTURE parameters.
  */
-static void
-adv7180_get_color(int *bright, int *saturation, int *red, int *green, int *blue)
+static int ioctl_g_parm(struct v4l2_int_device *s, struct v4l2_streamparm *a)
 {
-	int b, s;
+	struct sensor *sensor = s->priv;
+	struct v4l2_captureparm *cparm = &a->parm.capture;
+
+	dev_dbg(&adv7180_data.i2c_client->dev, "In adv7180:ioctl_g_parm\n");
+
+	switch (a->type) {
+	/* These are all the possible cases. */
+	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
+		pr_debug("   type is V4L2_BUF_TYPE_VIDEO_CAPTURE\n");
+		memset(a, 0, sizeof(*a));
+		a->type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+		cparm->capability = sensor->streamcap.capability;
+		cparm->timeperframe = sensor->streamcap.timeperframe;
+		cparm->capturemode = sensor->streamcap.capturemode;
+		break;
+
+	case V4L2_BUF_TYPE_VIDEO_OUTPUT:
+	case V4L2_BUF_TYPE_VIDEO_OVERLAY:
+	case V4L2_BUF_TYPE_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_VBI_OUTPUT:
+	case V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:
+		break;
+
+	default:
+		pr_debug("ioctl_g_parm:type is unknown %d\n", a->type);
+		break;
+	}
 
-	b = adv7180_read(ADV7180_BRIGHTNESS);
-	s = adv7180_read(ADV7180_SD_SATURATION_CB);
-	*bright = b;
-	*saturation = s;
+	return 0;
 }
 
-/*! ADV7180 video decoder configuration.
+/*!
+ * ioctl_s_parm - V4L2 sensor interface handler for VIDIOC_S_PARM ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @a: pointer to standard V4L2 VIDIOC_S_PARM ioctl structure
  *
- *  @param *frame_rate	Frame rate.
+ * Configures the sensor to use the input parameters, if possible.  If
+ * not possible, reverts to the old parameters and returns the
+ * appropriate error code.
  *
- *  @return		sensor_interface pointer.
+ * This driver cannot change these settings.
  */
-sensor_interface *adv7180_config(int *frame_rate, int high_quality)
+static int ioctl_s_parm(struct v4l2_int_device *s, struct v4l2_streamparm *a)
 {
-	down(&mutex);
-	adv7180_interface(interface_param, video_fmts[video_idx].raw_width,
-			  video_fmts[video_idx].raw_height);
-	up(&mutex);
+	dev_dbg(&adv7180_data.i2c_client->dev, "In adv7180:ioctl_s_parm\n");
+
+	switch (a->type) {
+	/* These are all the possible cases. */
+	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
+	case V4L2_BUF_TYPE_VIDEO_OUTPUT:
+	case V4L2_BUF_TYPE_VIDEO_OVERLAY:
+	case V4L2_BUF_TYPE_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_VBI_OUTPUT:
+	case V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:
+		break;
+
+	default:
+		pr_debug("   type is unknown - %d\n", a->type);
+		break;
+	}
 
-	return interface_param;
+	return 0;
 }
 
-/*! ADV7180 Reset function.
+/*!
+ * ioctl_g_fmt_cap - V4L2 sensor interface handler for ioctl_g_fmt_cap
+ * @s: pointer to standard V4L2 device structure
+ * @f: pointer to standard V4L2 v4l2_format structure
  *
- *  @return		None.
+ * Returns the sensor's current pixel format in the v4l2_format
+ * parameter.
  */
-static sensor_interface *adv7180_soft_reset(void)
+static int ioctl_g_fmt_cap(struct v4l2_int_device *s, struct v4l2_format *f)
 {
-	int frame_rate;
-	sensor_interface *s;
+	struct sensor *sensor = s->priv;
+
+	dev_dbg(&adv7180_data.i2c_client->dev, "In adv7180:ioctl_g_fmt_cap\n");
+
+	switch (f->type) {
+	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
+		pr_debug("   Returning size of %dx%d\n",
+			 sensor->pix.width, sensor->pix.height);
+		f->fmt.pix = sensor->pix;
+		break;
+
+	case V4L2_BUF_TYPE_PRIVATE: {
+		v4l2_std_id std;
+		adv7180_get_std(&std);
+		f->fmt.pix.pixelformat = (u32)std;
+		}
+		break;
+
+	default:
+		f->fmt.pix = sensor->pix;
+		break;
+	}
 
-	s = adv7180_config(&frame_rate, 0);
-	return s;
+	return 0;
 }
 
-/*! Return attributes of current video standard.
+/*!
+ * ioctl_queryctrl - V4L2 sensor interface handler for VIDIOC_QUERYCTRL ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @qc: standard V4L2 VIDIOC_QUERYCTRL ioctl structure
  *
- *  @return		None.
+ * If the requested control is supported, returns the control information
+ * from the video_control[] array.  Otherwise, returns -EINVAL if the
+ * control is not supported.
  */
-static void adv7180_get_std(v4l2_std_id * std)
+static int ioctl_queryctrl(struct v4l2_int_device *s,
+			   struct v4l2_queryctrl *qc)
 {
-	int tmp;
+	int i;
 
-	/* Read the AD_RESULT to get the detect output video standard */
-	tmp = adv7180_read(ADV7180_STATUS_1) & 0x70;
-	down(&mutex);
-	if (tmp == 0x40)	/* PAL */
-		*std = V4L2_STD_PAL;
-	else if (tmp == 0)
-		/*NTSC*/ *std = V4L2_STD_NTSC;
-	else {
-		*std = V4L2_STD_ALL;
-		dev_dbg(&adv7180_i2c_client->dev,
-			"Get invalid video standard! \n");
+	dev_dbg(&adv7180_data.i2c_client->dev, "In adv7180:ioctl_queryctrl\n");
+
+	for (i = 0; i < ARRAY_SIZE(adv7180_qctrl); i++)
+		if (qc->id && qc->id == adv7180_qctrl[i].id) {
+			memcpy(qc, &(adv7180_qctrl[i]),
+				sizeof(*qc));
+			return (0);
+		}
+
+	return -EINVAL;
+}
+
+/*!
+ * ioctl_g_ctrl - V4L2 sensor interface handler for VIDIOC_G_CTRL ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @vc: standard V4L2 VIDIOC_G_CTRL ioctl structure
+ *
+ * If the requested control is supported, returns the control's current
+ * value from the video_control[] array.  Otherwise, returns -EINVAL
+ * if the control is not supported.
+ */
+static int ioctl_g_ctrl(struct v4l2_int_device *s, struct v4l2_control *vc)
+{
+	int ret = 0;
+
+	dev_dbg(&adv7180_data.i2c_client->dev, "In adv7180:ioctl_g_ctrl\n");
+
+	switch (vc->id) {
+	case V4L2_CID_BRIGHTNESS:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_BRIGHTNESS\n");
+		adv7180_data.brightness = adv7180_read(ADV7180_BRIGHTNESS);
+		vc->value = adv7180_data.brightness;
+		break;
+	case V4L2_CID_CONTRAST:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_CONTRAST\n");
+		vc->value = adv7180_data.contrast;
+		break;
+	case V4L2_CID_SATURATION:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_SATURATION\n");
+		adv7180_data.saturation = adv7180_read(ADV7180_SD_SATURATION_CB);
+		vc->value = adv7180_data.saturation;
+		break;
+	case V4L2_CID_HUE:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_HUE\n");
+		vc->value = adv7180_data.hue;
+		break;
+	case V4L2_CID_AUTO_WHITE_BALANCE:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_AUTO_WHITE_BALANCE\n");
+		break;
+	case V4L2_CID_DO_WHITE_BALANCE:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_DO_WHITE_BALANCE\n");
+		break;
+	case V4L2_CID_RED_BALANCE:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_RED_BALANCE\n");
+		vc->value = adv7180_data.red;
+		break;
+	case V4L2_CID_BLUE_BALANCE:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_BLUE_BALANCE\n");
+		vc->value = adv7180_data.blue;
+		break;
+	case V4L2_CID_GAMMA:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_GAMMA\n");
+		break;
+	case V4L2_CID_EXPOSURE:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_EXPOSURE\n");
+		vc->value = adv7180_data.ae_mode;
+		break;
+	case V4L2_CID_AUTOGAIN:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_AUTOGAIN\n");
+		break;
+	case V4L2_CID_GAIN:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_GAIN\n");
+		break;
+	case V4L2_CID_HFLIP:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_HFLIP\n");
+		break;
+	case V4L2_CID_VFLIP:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_VFLIP\n");
+		break;
+	default:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   Default case\n");
+		vc->value = 0;
+		ret = -EPERM;
+		break;
 	}
-	up(&mutex);
+
+	return ret;
 }
 
-/*! Interface with 'mxc_v4l2_capture.c' */
-struct camera_sensor camera_sensor_if = {
-	.set_color = adv7180_set_color,
-	.get_color = adv7180_get_color,
-	.config = adv7180_config,
-	.reset = adv7180_soft_reset,
-	.set_std = adv7180_set_std,
-	.get_std = adv7180_get_std,
+/*!
+ * ioctl_s_ctrl - V4L2 sensor interface handler for VIDIOC_S_CTRL ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @vc: standard V4L2 VIDIOC_S_CTRL ioctl structure
+ *
+ * If the requested control is supported, sets the control's current
+ * value in HW (and updates the video_control[] array).  Otherwise,
+ * returns -EINVAL if the control is not supported.
+ */
+static int ioctl_s_ctrl(struct v4l2_int_device *s, struct v4l2_control *vc)
+{
+	int retval = 0;
+	u8 tmp;
+
+	dev_dbg(&adv7180_data.i2c_client->dev, "In adv7180:ioctl_s_ctrl\n");
+
+	switch (vc->id) {
+	case V4L2_CID_BRIGHTNESS:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_BRIGHTNESS\n");
+		tmp = vc->value;
+		adv7180_write_reg(ADV7180_BRIGHTNESS, tmp);
+		adv7180_data.brightness = vc->value;
+		break;
+	case V4L2_CID_CONTRAST:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_CONTRAST\n");
+		break;
+	case V4L2_CID_SATURATION:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_SATURATION\n");
+		tmp = vc->value;
+		adv7180_write_reg(ADV7180_SD_SATURATION_CB, tmp);
+		adv7180_write_reg(ADV7180_SD_SATURATION_CR, tmp);
+		adv7180_data.saturation = vc->value;
+		break;
+	case V4L2_CID_HUE:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_HUE\n");
+		break;
+	case V4L2_CID_AUTO_WHITE_BALANCE:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_AUTO_WHITE_BALANCE\n");
+		break;
+	case V4L2_CID_DO_WHITE_BALANCE:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_DO_WHITE_BALANCE\n");
+		break;
+	case V4L2_CID_RED_BALANCE:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_RED_BALANCE\n");
+		break;
+	case V4L2_CID_BLUE_BALANCE:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_BLUE_BALANCE\n");
+		break;
+	case V4L2_CID_GAMMA:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_GAMMA\n");
+		break;
+	case V4L2_CID_EXPOSURE:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_EXPOSURE\n");
+		break;
+	case V4L2_CID_AUTOGAIN:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_AUTOGAIN\n");
+		break;
+	case V4L2_CID_GAIN:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_GAIN\n");
+		break;
+	case V4L2_CID_HFLIP:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_HFLIP\n");
+		break;
+	case V4L2_CID_VFLIP:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   V4L2_CID_VFLIP\n");
+		break;
+	default:
+		dev_dbg(&adv7180_data.i2c_client->dev,
+			"   Default case\n");
+		retval = -EPERM;
+		break;
+	}
+
+	return retval;
+}
+
+/*!
+ * ioctl_init - V4L2 sensor interface handler for VIDIOC_INT_INIT
+ * @s: pointer to standard V4L2 device structure
+ */
+static int ioctl_init(struct v4l2_int_device *s)
+{
+	dev_dbg(&adv7180_data.i2c_client->dev, "In adv7180:ioctl_init\n");
+	return 0;
+}
+
+/*!
+ * ioctl_dev_init - V4L2 sensor interface handler for vidioc_int_dev_init_num
+ * @s: pointer to standard V4L2 device structure
+ *
+ * Initialise the device when slave attaches to the master.
+ */
+static int ioctl_dev_init(struct v4l2_int_device *s)
+{
+	dev_dbg(&adv7180_data.i2c_client->dev, "In adv7180:ioctl_dev_init\n");
+	return 0;
+}
+
+/*!
+ * This structure defines all the ioctls for this module.
+ */
+static struct v4l2_int_ioctl_desc adv7180_ioctl_desc[] = {
+
+	{vidioc_int_dev_init_num, (v4l2_int_ioctl_func *)ioctl_dev_init},
+
+	/*!
+	 * Delinitialise the dev. at slave detach.
+	 * The complement of ioctl_dev_init.
+	 */
+/*	{vidioc_int_dev_exit_num, (v4l2_int_ioctl_func *)ioctl_dev_exit}, */
+
+	{vidioc_int_s_power_num, (v4l2_int_ioctl_func *)ioctl_s_power},
+	{vidioc_int_g_ifparm_num, (v4l2_int_ioctl_func *)ioctl_g_ifparm},
+/*	{vidioc_int_g_needs_reset_num,
+				(v4l2_int_ioctl_func *)ioctl_g_needs_reset}, */
+/*	{vidioc_int_reset_num, (v4l2_int_ioctl_func *)ioctl_reset}, */
+	{vidioc_int_init_num, (v4l2_int_ioctl_func *)ioctl_init},
+
+	/*!
+	 * VIDIOC_ENUM_FMT ioctl for the CAPTURE buffer type.
+	 */
+/*	{vidioc_int_enum_fmt_cap_num,
+				(v4l2_int_ioctl_func *)ioctl_enum_fmt_cap}, */
+
+	/*!
+	 * VIDIOC_TRY_FMT ioctl for the CAPTURE buffer type.
+	 * This ioctl is used to negotiate the image capture size and
+	 * pixel format without actually making it take effect.
+	 */
+/*	{vidioc_int_try_fmt_cap_num,
+				(v4l2_int_ioctl_func *)ioctl_try_fmt_cap}, */
+
+	{vidioc_int_g_fmt_cap_num, (v4l2_int_ioctl_func *)ioctl_g_fmt_cap},
+
+	/*!
+	 * If the requested format is supported, configures the HW to use that
+	 * format, returns error code if format not supported or HW can't be
+	 * correctly configured.
+	 */
+/*	{vidioc_int_s_fmt_cap_num, (v4l2_int_ioctl_func *)ioctl_s_fmt_cap}, */
+
+	{vidioc_int_g_parm_num, (v4l2_int_ioctl_func *)ioctl_g_parm},
+	{vidioc_int_s_parm_num, (v4l2_int_ioctl_func *)ioctl_s_parm},
+	{vidioc_int_queryctrl_num, (v4l2_int_ioctl_func *)ioctl_queryctrl},
+	{vidioc_int_g_ctrl_num, (v4l2_int_ioctl_func *)ioctl_g_ctrl},
+	{vidioc_int_s_ctrl_num, (v4l2_int_ioctl_func *)ioctl_s_ctrl},
+};
+
+static struct v4l2_int_slave adv7180_slave = {
+	.ioctls = adv7180_ioctl_desc,
+	.num_ioctls = ARRAY_SIZE(adv7180_ioctl_desc),
 };
-EXPORT_SYMBOL(camera_sensor_if);
+
+static struct v4l2_int_device adv7180_int_device = {
+	.module = THIS_MODULE,
+	.name = "adv7180",
+	.type = v4l2_int_type_slave,
+	.u = {
+		.slave = &adv7180_slave,
+	},
+};
+
 
 /***********************************************************************
  * I2C client and driver.
@@ -350,6 +754,9 @@ EXPORT_SYMBOL(camera_sensor_if);
  */
 static void adv7180_hard_reset(void)
 {
+	dev_dbg(&adv7180_data.i2c_client->dev,
+		"In adv7180:adv7180_hard_reset\n");
+
 	/*! Driver works fine without explicit register
 	 * initialization. Furthermore, initializations takes about 2 seconds
 	 * at startup...
@@ -359,7 +766,8 @@ static void adv7180_hard_reset(void)
 	 * operations(autodection of all stds).
 	 */
 	adv7180_write_reg(ADV7180_INPUT_CTL, 0x09);
-	/*! Datasheet recommend */
+
+	/*! Datasheet recommends: */
 	adv7180_write_reg(ADV7180_VSYNC_FIELD_CTL_1, 0x02);
 	adv7180_write_reg(ADV7180_MANUAL_WIN_CTL, 0xa2);
 }
@@ -371,89 +779,122 @@ static void adv7180_hard_reset(void)
  *  @return		Error code indicating success or failure.
  */
 
-/*! ADV7180 I2C probe function.
+/*!
+ * ADV7180 I2C probe function.
+ * Function set in i2c_driver struct.
+ * Called by insmod.
  *
  *  @param *adapter	I2C adapter descriptor.
  *
  *  @return		Error code indicating success or failure.
  */
-static int adv7180_probe(struct i2c_client *client, const struct i2c_device_id *id)
+static int adv7180_probe(struct i2c_client *client,
+			 const struct i2c_device_id *id)
 {
 	int rev_id;
+	int ret = 0;
+
+	dev_dbg(&adv7180_data.i2c_client->dev, "In adv7180_probe\n");
+
+	/* Set initial values for the sensor struct. */
+	memset(&adv7180_data, 0, sizeof(adv7180_data));
+	adv7180_data.i2c_client = client;
+	adv7180_data.streamcap.timeperframe.denominator = 30;
+	adv7180_data.streamcap.timeperframe.numerator = 1;
+	adv7180_data.std_id = V4L2_STD_ALL;
+	video_idx = ADV7180_NOT_LOCKED;
+	adv7180_data.pix.width = video_fmts[video_idx].raw_width;
+	adv7180_data.pix.height = video_fmts[video_idx].raw_height;
+	adv7180_data.pix.pixelformat = V4L2_PIX_FMT_UYVY;  /* YUV422 */
+	adv7180_data.pix.priv = 1;  /* 1 is used to indicate TV in */
+
+	gpio_sensor_active();
 
 	/*! Put device into normal operational mode. */
 	pmic_gpio_set_bit_val(MCU_GPIO_REG_GPIO_CONTROL_1, 1, 1);
 	pmic_gpio_set_bit_val(MCU_GPIO_REG_GPIO_CONTROL_2, 4, 1);
 
-	adv7180_i2c_client = client;
-	dev_dbg(&adv7180_i2c_client->dev,
+	dev_dbg(&adv7180_data.i2c_client->dev,
 		"%s:adv7180 probe i2c address is 0x%02X \n",
-		__func__, adv7180_i2c_client->addr);
+		__func__, adv7180_data.i2c_client->addr);
+
 	/*! Read the revision ID of the tvin chip */
 	rev_id = adv7180_read(ADV7180_IDENT);
-	dev_dbg(&adv7180_i2c_client->dev,
+	dev_dbg(&adv7180_data.i2c_client->dev,
 		"%s:Analog Device adv7%2X0 detected! \n", __func__,
 		rev_id);
-	interface_param = (sensor_interface *)
-	    kmalloc(sizeof(sensor_interface), GFP_KERNEL);
-	if (!interface_param) {
-		dev_dbg(&adv7180_i2c_client->dev, " kmalloc failed \n");
-		return -1;
-	}
+
 	/*! ADV7180 initialization. */
 	adv7180_hard_reset();
 
-	return 0;
+	pr_debug("   type is %d (expect %d)\n",
+		 adv7180_int_device.type, v4l2_int_type_slave);
+	pr_debug("   num ioctls is %d\n",
+		 adv7180_int_device.u.slave->num_ioctls);
+
+	/* This function attaches this structure to the /dev/video0 device.
+	 * The pointer in priv points to the mt9v111_data structure here.*/
+	adv7180_int_device.priv = &adv7180_data;
+	ret = v4l2_int_device_register(&adv7180_int_device);
+
+	return ret;
 }
 
-/*! ADV7180 I2C detach function.
+/*!
+ * ADV7180 I2C detach function.
+ * Called on rmmod.
  *
- *  @param *client	struct i2c_client *.
+ *  @param *client	struct i2c_client*.
  *
  *  @return		Error code indicating success or failure.
  */
 static int adv7180_detach(struct i2c_client *client)
 {
-	dev_dbg(&adv7180_i2c_client->dev,
+	dev_dbg(&adv7180_data.i2c_client->dev,
 		"%s:Removing %s video decoder @ 0x%02X from adapter %s \n",
 		__func__, IF_NAME, client->addr << 1, client->adapter->name);
-	kfree(interface_param);
-	interface_param = NULL;
 
 	/*! Put device into power down mode. */
 	pmic_gpio_set_bit_val(MCU_GPIO_REG_GPIO_CONTROL_2, 4, 0);
+
 	/*! Disable TVIN module. */
 	pmic_gpio_set_bit_val(MCU_GPIO_REG_GPIO_CONTROL_1, 1, 0);
 
+	v4l2_int_device_unregister(&adv7180_int_device);
+
 	return 0;
 }
 
-/*! ADV7180 init function.
+/*!
+ * ADV7180 init function.
+ * Called on insmod.
  *
- *  @return		Error code indicating success or failure.
+ * @return    Error code indicating success or failure.
  */
 static __init int adv7180_init(void)
 {
 	u8 err = 0;
 
-	/*! Configuration of i.MX35 CSI I/O muxes. */
-	gpio_sensor_active();
+	dev_dbg(&adv7180_data.i2c_client->dev, "In adv7180_init\n");
+
+	/* Tells the i2c driver what functions to call for this driver. */
 	err = i2c_add_driver(&adv7180_i2c_driver);
 	if (err != 0)
-		dev_dbg(&adv7180_i2c_client->dev,
-			"%s:driver registration failed, error=%d \n",
+		pr_err("%s:driver registration failed, error=%d \n",
 			__func__, err);
 
 	return err;
 }
 
-extern void gpio_sensor_inactive(void);
-/*! ADV7180 cleanup function.
+/*!
+ * ADV7180 cleanup function.
+ * Called on rmmod.
  *
- *  @return		Error code indicating success or failure.
+ * @return   Error code indicating success or failure.
  */
 static void __exit adv7180_clean(void)
 {
+	dev_dbg(&adv7180_data.i2c_client->dev, "In adv7180_clean\n");
 	i2c_del_driver(&adv7180_i2c_driver);
 	gpio_sensor_inactive();
 }
diff --git a/drivers/media/video/mxc/capture/emma_mt9v111.c b/drivers/media/video/mxc/capture/emma_mt9v111.c
new file mode 100644
index 0000000..73e9bba
--- /dev/null
+++ b/drivers/media/video/mxc/capture/emma_mt9v111.c
@@ -0,0 +1,679 @@
+/*
+ * Copyright 2004-2008 Freescale Semiconductor, Inc. All Rights Reserved.
+ */
+
+/*
+ * The code contained herein is licensed under the GNU General Public
+ * License. You may obtain a copy of the GNU General Public License
+ * Version 2 or later at the following locations:
+ *
+ * http://www.opensource.org/licenses/gpl-license.html
+ * http://www.gnu.org/copyleft/gpl.html
+ */
+
+/*!
+ * @file mt9v111.c
+ *
+ * @brief mt9v111 camera driver functions
+ *
+ * @ingroup Camera
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/ctype.h>
+#include <linux/types.h>
+#include <linux/delay.h>
+#include <linux/device.h>
+#include <linux/i2c.h>
+#include <linux/clk.h>
+#include "mxc_v4l2_capture.h"
+#include "mt9v111.h"
+
+#ifdef MT9V111_DEBUG
+static u16 testpattern;
+#endif
+
+static sensor_interface *interface_param;
+static mt9v111_conf mt9v111_device;
+static int reset_frame_rate = 30;
+
+#define MT9V111_FRAME_RATE_NUM    20
+
+static mt9v111_image_format format[2] = {
+	{
+	 .index = 0,
+	 .width = 640,
+	 .height = 480,
+	 },
+	{
+	 .index = 1,
+	 .width = 352,
+	 .height = 288,
+	 },
+};
+
+static int mt9v111_attach(struct i2c_adapter *adapter);
+static int mt9v111_detach(struct i2c_client *client);
+
+static struct i2c_driver mt9v111_i2c_driver = {
+	.driver = {
+		   .owner = THIS_MODULE,
+		   .name = "MT9V111 Client",
+		   },
+	.attach_adapter = mt9v111_attach,
+	.detach_client = mt9v111_detach,
+};
+
+static struct i2c_client mt9v111_i2c_client = {
+	.name = "mt9v111 I2C dev",
+	.addr = MT9V111_I2C_ADDRESS,
+	.driver = &mt9v111_i2c_driver,
+};
+
+/*
+ * Function definitions
+ */
+
+#ifdef MT9V111_DEBUG
+static inline int mt9v111_read_reg(u8 reg)
+{
+	int val = i2c_smbus_read_word_data(&mt9v111_i2c_client, reg);
+	if (val != -1)
+		val = cpu_to_be16(val);
+	return val;
+}
+#endif
+
+static inline int mt9v111_write_reg(u8 reg, u16 val)
+{
+	pr_debug("write reg %x val %x.\n", reg, val);
+	return i2c_smbus_write_word_data(&mt9v111_i2c_client, reg,
+					 cpu_to_be16(val));
+}
+
+/*!
+ * Initialize mt9v111_sensor_lib
+ * Libarary for Sensor configuration through I2C
+ *
+ * @param       coreReg       Core Registers
+ * @param       ifpReg        IFP Register
+ *
+ * @return status
+ */
+static u8 mt9v111_sensor_lib(mt9v111_coreReg * coreReg, mt9v111_IFPReg * ifpReg)
+{
+	u8 reg;
+	u16 data;
+	u8 error = 0;
+
+	/*
+	 * setup to IFP registers
+	 */
+	reg = MT9V111I_ADDR_SPACE_SEL;
+	data = ifpReg->addrSpaceSel;
+	mt9v111_write_reg(reg, data);
+
+	/* Operation Mode Control */
+	reg = MT9V111I_MODE_CONTROL;
+	data = ifpReg->modeControl;
+	mt9v111_write_reg(reg, data);
+
+	/* Output format */
+	reg = MT9V111I_FORMAT_CONTROL;
+	data = ifpReg->formatControl;	/* Set bit 12 */
+	mt9v111_write_reg(reg, data);
+
+	/* AE limit 4 */
+	reg = MT9V111I_SHUTTER_WIDTH_LIMIT_AE;
+	data = ifpReg->gainLimitAE;
+	mt9v111_write_reg(reg, data);
+
+	reg = MT9V111I_OUTPUT_FORMAT_CTRL2;
+	data = ifpReg->outputFormatCtrl2;
+	mt9v111_write_reg(reg, data);
+
+	reg = MT9V111I_AE_SPEED;
+	data = ifpReg->AESpeed;
+	mt9v111_write_reg(reg, data);
+
+	/* output image size */
+	reg = MT9V111i_H_PAN;
+	data = 0x8000 | ifpReg->HPan;
+	mt9v111_write_reg(reg, data);
+
+	reg = MT9V111i_H_ZOOM;
+	data = 0x8000 | ifpReg->HZoom;
+	mt9v111_write_reg(reg, data);
+
+	reg = MT9V111i_H_SIZE;
+	data = 0x8000 | ifpReg->HSize;
+	mt9v111_write_reg(reg, data);
+
+	reg = MT9V111i_V_PAN;
+	data = 0x8000 | ifpReg->VPan;
+	mt9v111_write_reg(reg, data);
+
+	reg = MT9V111i_V_ZOOM;
+	data = 0x8000 | ifpReg->VZoom;
+	mt9v111_write_reg(reg, data);
+
+	reg = MT9V111i_V_SIZE;
+	data = 0x8000 | ifpReg->VSize;
+	mt9v111_write_reg(reg, data);
+
+	reg = MT9V111i_H_PAN;
+	data = ~0x8000 & ifpReg->HPan;
+	mt9v111_write_reg(reg, data);
+#if 0
+	reg = MT9V111I_UPPER_SHUTTER_DELAY_LIM;
+	data = ifpReg->upperShutterDelayLi;
+	mt9v111_write_reg(reg, data);
+
+	reg = MT9V111I_SHUTTER_60;
+	data = ifpReg->shutter_width_60;
+	mt9v111_write_reg(reg, data);
+
+	reg = MT9V111I_SEARCH_FLICK_60;
+	data = ifpReg->search_flicker_60;
+	mt9v111_write_reg(reg, data);
+#endif
+
+	/*
+	 * setup to sensor core registers
+	 */
+	reg = MT9V111I_ADDR_SPACE_SEL;
+	data = coreReg->addressSelect;
+	mt9v111_write_reg(reg, data);
+
+	/* enable changes and put the Sync bit on */
+	reg = MT9V111S_OUTPUT_CTRL;
+	data = MT9V111S_OUTCTRL_SYNC | MT9V111S_OUTCTRL_CHIP_ENABLE | 0x3000;
+	mt9v111_write_reg(reg, data);
+
+	/* min PIXCLK - Default */
+	reg = MT9V111S_PIXEL_CLOCK_SPEED;
+	data = coreReg->pixelClockSpeed;
+	mt9v111_write_reg(reg, data);
+
+	/* Setup image flipping / Dark rows / row/column skip */
+	reg = MT9V111S_READ_MODE;
+	data = coreReg->readMode;
+	mt9v111_write_reg(reg, data);
+
+	/*zoom 0 */
+	reg = MT9V111S_DIGITAL_ZOOM;
+	data = coreReg->digitalZoom;
+	mt9v111_write_reg(reg, data);
+
+	/* min H-blank */
+	reg = MT9V111S_HOR_BLANKING;
+	data = coreReg->horizontalBlanking;
+	mt9v111_write_reg(reg, data);
+
+	/* min V-blank */
+	reg = MT9V111S_VER_BLANKING;
+	data = coreReg->verticalBlanking;
+	mt9v111_write_reg(reg, data);
+
+	reg = MT9V111S_SHUTTER_WIDTH;
+	data = coreReg->shutterWidth;
+	mt9v111_write_reg(reg, data);
+
+	reg = MT9V111S_SHUTTER_DELAY;
+	data = ifpReg->upperShutterDelayLi;
+	mt9v111_write_reg(reg, data);
+
+	/* changes become effective */
+	reg = MT9V111S_OUTPUT_CTRL;
+	data = MT9V111S_OUTCTRL_CHIP_ENABLE | 0x3000;
+	mt9v111_write_reg(reg, data);
+
+	return error;
+}
+
+/*!
+ * mt9v111 sensor interface Initialization
+ * @param param            sensor_interface *
+ * @param width            u32
+ * @param height           u32
+ * @return  None
+ */
+static void mt9v111_interface(sensor_interface *param, u32 width, u32 height)
+{
+	param->Vsync_pol = 0x0;
+	param->clk_mode = 0x0;	/*gated */
+	param->pixclk_pol = 0x0;
+	param->data_width = 0x1;
+	param->data_pol = 0x0;
+	param->ext_vsync = 0x0;
+	param->Vsync_pol = 0x0;
+	param->Hsync_pol = 0x0;
+	param->width = width - 1;
+	param->height = height - 1;
+	param->active_width = width;
+	param->active_height = height;
+	param->pixel_fmt = IPU_PIX_FMT_UYVY;
+	param->mclk = 27000000;
+}
+
+/*!
+ * MT9V111 frame rate calculate
+ *
+ * @param frame_rate       int *
+ * @param mclk             int
+ * @return  None
+ */
+static void mt9v111_rate_cal(int *frame_rate, int mclk)
+{
+	int num_clock_per_row;
+	int max_rate = 0;
+
+	mt9v111_device.coreReg->horizontalBlanking = MT9V111_HORZBLANK_MIN;
+
+	num_clock_per_row = (format[0].width + 114 + MT9V111_HORZBLANK_MIN) * 2;
+	max_rate = mclk / (num_clock_per_row *
+			   (format[0].height + MT9V111_VERTBLANK_DEFAULT));
+
+	if ((*frame_rate > max_rate) || (*frame_rate == 0)) {
+		*frame_rate = max_rate;
+	}
+
+	mt9v111_device.coreReg->verticalBlanking
+	    = mclk / (*frame_rate * num_clock_per_row) - format[0].height;
+
+	reset_frame_rate = *frame_rate;
+}
+
+/*!
+ * MT9V111 sensor configuration
+ *
+ * @param frame_rate       int *
+ * @param high_quality     int
+ * @return  sensor_interface *
+ */
+sensor_interface *mt9v111_config(int *frame_rate, int high_quality)
+{
+	u32 out_width, out_height;
+
+	if (interface_param == NULL)
+		return NULL;
+
+	mt9v111_device.coreReg->addressSelect = MT9V111I_SEL_SCA;
+	mt9v111_device.ifpReg->addrSpaceSel = MT9V111I_SEL_IFP;
+
+	mt9v111_device.coreReg->windowHeight = MT9V111_WINHEIGHT;
+	mt9v111_device.coreReg->windowWidth = MT9V111_WINWIDTH;
+	mt9v111_device.coreReg->zoomColStart = 0;
+	mt9v111_device.coreReg->zomRowStart = 0;
+	mt9v111_device.coreReg->digitalZoom = 0x0;
+
+	mt9v111_device.coreReg->verticalBlanking = MT9V111_VERTBLANK_DEFAULT;
+	mt9v111_device.coreReg->horizontalBlanking = MT9V111_HORZBLANK_MIN;
+	mt9v111_device.coreReg->pixelClockSpeed = 0;
+	mt9v111_device.coreReg->readMode = 0xd0a1;
+
+	mt9v111_device.ifpReg->outputFormatCtrl2 = 0;
+	mt9v111_device.ifpReg->gainLimitAE = 0x300;
+	mt9v111_device.ifpReg->AESpeed = 0x80;
+
+	/* here is the default value */
+	mt9v111_device.ifpReg->formatControl = 0xc800;
+	mt9v111_device.ifpReg->modeControl = 0x708e;
+	mt9v111_device.ifpReg->awbSpeed = 0x4514;
+	mt9v111_device.coreReg->shutterWidth = 0xf8;
+
+	out_width = 640;
+	out_height = 480;
+
+	/*output size */
+	mt9v111_device.ifpReg->HPan = 0;
+	mt9v111_device.ifpReg->HZoom = 640;
+	mt9v111_device.ifpReg->HSize = out_width;
+	mt9v111_device.ifpReg->VPan = 0;
+	mt9v111_device.ifpReg->VZoom = 480;
+	mt9v111_device.ifpReg->VSize = out_height;
+
+	mt9v111_interface(interface_param, out_width, out_height);
+	set_mclk_rate(&interface_param->mclk);
+	mt9v111_rate_cal(frame_rate, interface_param->mclk);
+	mt9v111_sensor_lib(mt9v111_device.coreReg, mt9v111_device.ifpReg);
+
+	return interface_param;
+}
+
+/*!
+ * mt9v111 sensor set color configuration
+ *
+ * @param bright       int
+ * @param saturation   int
+ * @param red          int
+ * @param green        int
+ * @param blue         int
+ * @return  None
+ */
+static void
+mt9v111_set_color(int bright, int saturation, int red, int green, int blue)
+{
+	u8 reg;
+	u16 data;
+
+	switch (saturation) {
+	case 100:
+		mt9v111_device.ifpReg->awbSpeed = 0x4514;
+		break;
+	case 150:
+		mt9v111_device.ifpReg->awbSpeed = 0x6D14;
+		break;
+	case 75:
+		mt9v111_device.ifpReg->awbSpeed = 0x4D14;
+		break;
+	case 50:
+		mt9v111_device.ifpReg->awbSpeed = 0x5514;
+		break;
+	case 37:
+		mt9v111_device.ifpReg->awbSpeed = 0x5D14;
+		break;
+	case 25:
+		mt9v111_device.ifpReg->awbSpeed = 0x6514;
+		break;
+	default:
+		mt9v111_device.ifpReg->awbSpeed = 0x4514;
+		break;
+	}
+
+	reg = MT9V111I_ADDR_SPACE_SEL;
+	data = mt9v111_device.ifpReg->addrSpaceSel;
+	mt9v111_write_reg(reg, data);
+
+	/* Operation Mode Control */
+	reg = MT9V111I_AWB_SPEED;
+	data = mt9v111_device.ifpReg->awbSpeed;
+	mt9v111_write_reg(reg, data);
+}
+
+/*!
+ * mt9v111 sensor get color configuration
+ *
+ * @param bright       int *
+ * @param saturation   int *
+ * @param red          int *
+ * @param green        int *
+ * @param blue         int *
+ * @return  None
+ */
+static void
+mt9v111_get_color(int *bright, int *saturation, int *red, int *green, int *blue)
+{
+	*saturation = (mt9v111_device.ifpReg->awbSpeed & 0x3800) >> 11;
+	switch (*saturation) {
+	case 0:
+		*saturation = 100;
+		break;
+	case 1:
+		*saturation = 75;
+		break;
+	case 2:
+		*saturation = 50;
+		break;
+	case 3:
+		*saturation = 37;
+		break;
+	case 4:
+		*saturation = 25;
+		break;
+	case 5:
+		*saturation = 150;
+		break;
+	case 6:
+		*saturation = 0;
+		break;
+	default:
+		*saturation = 0;
+		break;
+	}
+}
+
+/*!
+ * mt9v111 sensor set AE measurement window mode configuration
+ *
+ * @param ae_mode      int
+ * @return  None
+ */
+static void mt9v111_set_ae_mode(int ae_mode)
+{
+	u8 reg;
+	u16 data;
+
+	mt9v111_device.ifpReg->modeControl &= 0xfff3;
+	mt9v111_device.ifpReg->modeControl |= (ae_mode & 0x03) << 2;
+
+	reg = MT9V111I_ADDR_SPACE_SEL;
+	data = mt9v111_device.ifpReg->addrSpaceSel;
+	mt9v111_write_reg(reg, data);
+
+	reg = MT9V111I_MODE_CONTROL;
+	data = mt9v111_device.ifpReg->modeControl;
+	mt9v111_write_reg(reg, data);
+}
+
+/*!
+ * mt9v111 sensor get AE measurement window mode configuration
+ *
+ * @param ae_mode      int *
+ * @return  None
+ */
+static void mt9v111_get_ae_mode(int *ae_mode)
+{
+	if (ae_mode != NULL) {
+		*ae_mode = (mt9v111_device.ifpReg->modeControl & 0xc) >> 2;
+	}
+}
+
+/*!
+ * mt9v111 Reset function
+ *
+ * @return  None
+ */
+static sensor_interface *mt9v111_reset(void)
+{
+	return mt9v111_config(&reset_frame_rate, 0);
+}
+
+struct camera_sensor camera_sensor_if = {
+	.set_color = mt9v111_set_color,
+	.get_color = mt9v111_get_color,
+	.set_ae_mode = mt9v111_set_ae_mode,
+	.get_ae_mode = mt9v111_get_ae_mode,
+	.config = mt9v111_config,
+	.reset = mt9v111_reset,
+};
+
+#ifdef MT9V111_DEBUG
+/*!
+ * Set sensor to test mode, which will generate test pattern.
+ *
+ * @return none
+ */
+static void mt9v111_test_pattern(bool flag)
+{
+	u16 data;
+
+	/* switch to sensor registers */
+	mt9v111_write_reg(MT9V111I_ADDR_SPACE_SEL, MT9V111I_SEL_SCA);
+
+	if (flag == true) {
+		testpattern = MT9V111S_OUTCTRL_TEST_MODE;
+
+		data = mt9v111_read_reg(MT9V111S_ROW_NOISE_CTRL) & 0xBF;
+		mt9v111_write_reg(MT9V111S_ROW_NOISE_CTRL, data);
+
+		mt9v111_write_reg(MT9V111S_TEST_DATA, 0);
+
+		/* changes take effect */
+		data = MT9V111S_OUTCTRL_CHIP_ENABLE | testpattern | 0x3000;
+		mt9v111_write_reg(MT9V111S_OUTPUT_CTRL, data);
+	} else {
+		testpattern = 0;
+
+		data = mt9v111_read_reg(MT9V111S_ROW_NOISE_CTRL) | 0x40;
+		mt9v111_write_reg(MT9V111S_ROW_NOISE_CTRL, data);
+
+		/* changes take effect */
+		data = MT9V111S_OUTCTRL_CHIP_ENABLE | testpattern | 0x3000;
+		mt9v111_write_reg(MT9V111S_OUTPUT_CTRL, data);
+	}
+}
+#endif
+
+/*!
+ * mt9v111 I2C detect_client function
+ *
+ * @param adapter            struct i2c_adapter *
+ * @param address            int
+ * @param kind               int
+ *
+ * @return  Error code indicating success or failure
+ */
+static int mt9v111_detect_client(struct i2c_adapter *adapter, int address,
+				 int kind)
+{
+	mt9v111_i2c_client.adapter = adapter;
+	if (i2c_attach_client(&mt9v111_i2c_client)) {
+		mt9v111_i2c_client.adapter = NULL;
+		printk(KERN_ERR "mt9v111_attach: i2c_attach_client failed\n");
+		return -1;
+	}
+
+	interface_param = (sensor_interface *)
+	    kmalloc(sizeof(sensor_interface), GFP_KERNEL);
+	if (!interface_param) {
+		printk(KERN_ERR "mt9v111_attach: kmalloc failed \n");
+		return -1;
+	}
+
+	printk(KERN_INFO "MT9V111 Detected\n");
+
+	return 0;
+}
+
+static unsigned short normal_i2c[] = { MT9V111_I2C_ADDRESS, I2C_CLIENT_END };
+
+/* Magic definition of all other variables and things */
+I2C_CLIENT_INSMOD;
+
+/*!
+ * mt9v111 I2C attach function
+ *
+ * @param adapter            struct i2c_adapter *
+ * @return  Error code indicating success or failure
+ */
+static int mt9v111_attach(struct i2c_adapter *adap)
+{
+	uint32_t mclk = 27000000;
+	struct clk *clk;
+	int err;
+
+	clk = clk_get(NULL, "csi_clk");
+	clk_enable(clk);
+	set_mclk_rate(&mclk);
+
+	err = i2c_probe(adap, &addr_data, &mt9v111_detect_client);
+
+	clk_disable(clk);
+	clk_put(clk);
+
+	return err;
+}
+
+/*!
+ * mt9v111 I2C detach function
+ *
+ * @param client            struct i2c_client *
+ * @return  Error code indicating success or failure
+ */
+static int mt9v111_detach(struct i2c_client *client)
+{
+	int err;
+
+	if (!mt9v111_i2c_client.adapter)
+		return -1;
+
+	err = i2c_detach_client(&mt9v111_i2c_client);
+	mt9v111_i2c_client.adapter = NULL;
+
+	if (interface_param)
+		kfree(interface_param);
+	interface_param = NULL;
+
+	return err;
+}
+
+extern void gpio_sensor_active(void);
+
+/*!
+ * MT9V111 init function
+ *
+ * @return  Error code indicating success or failure
+ */
+static __init int mt9v111_init(void)
+{
+	u8 err;
+
+	gpio_sensor_active();
+
+	mt9v111_device.coreReg = (mt9v111_coreReg *)
+	    kmalloc(sizeof(mt9v111_coreReg), GFP_KERNEL);
+	if (!mt9v111_device.coreReg)
+		return -1;
+
+	memset(mt9v111_device.coreReg, 0, sizeof(mt9v111_coreReg));
+
+	mt9v111_device.ifpReg = (mt9v111_IFPReg *)
+	    kmalloc(sizeof(mt9v111_IFPReg), GFP_KERNEL);
+	if (!mt9v111_device.ifpReg) {
+		kfree(mt9v111_device.coreReg);
+		mt9v111_device.coreReg = NULL;
+		return -1;
+	}
+
+	memset(mt9v111_device.ifpReg, 0, sizeof(mt9v111_IFPReg));
+
+	err = i2c_add_driver(&mt9v111_i2c_driver);
+
+	return err;
+}
+
+extern void gpio_sensor_inactive(void);
+/*!
+ * MT9V111 cleanup function
+ *
+ * @return  Error code indicating success or failure
+ */
+static void __exit mt9v111_clean(void)
+{
+	if (mt9v111_device.coreReg) {
+		kfree(mt9v111_device.coreReg);
+		mt9v111_device.coreReg = NULL;
+	}
+
+	if (mt9v111_device.ifpReg) {
+		kfree(mt9v111_device.ifpReg);
+		mt9v111_device.ifpReg = NULL;
+	}
+
+	i2c_del_driver(&mt9v111_i2c_driver);
+
+	gpio_sensor_inactive();
+}
+
+module_init(mt9v111_init);
+module_exit(mt9v111_clean);
+
+/* Exported symbols for modules. */
+EXPORT_SYMBOL(camera_sensor_if);
+
+MODULE_AUTHOR("Freescale Semiconductor, Inc.");
+MODULE_DESCRIPTION("Mt9v111 Camera Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/media/video/mxc/capture/emma_ov2640.c b/drivers/media/video/mxc/capture/emma_ov2640.c
new file mode 100644
index 0000000..b593eb6
--- /dev/null
+++ b/drivers/media/video/mxc/capture/emma_ov2640.c
@@ -0,0 +1,444 @@
+/*
+ * Copyright 2005-2008 Freescale Semiconductor, Inc. All Rights Reserved.
+ */
+
+/*
+ * The code contained herein is licensed under the GNU General Public
+ * License. You may obtain a copy of the GNU General Public License
+ * Version 2 or later at the following locations:
+ *
+ * http://www.opensource.org/licenses/gpl-license.html
+ * http://www.gnu.org/copyleft/gpl.html
+ */
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/ctype.h>
+#include <linux/types.h>
+#include <linux/delay.h>
+#include <linux/device.h>
+#include <linux/i2c.h>
+#include <linux/regulator/regulator.h>
+
+#include "mxc_v4l2_capture.h"
+
+enum ov2640_mode {
+	ov2640_mode_1600_1120,
+	ov2640_mode_800_600
+};
+
+struct reg_value {
+	u8 reg;
+	u8 value;
+	int delay_ms;
+};
+
+static struct reg_value ov2640_setting_1600_1120[] = {
+	{0xff, 0x1, 0}, {0x12, 0x80, 1}, {0xff, 0, 0}, {0x2c, 0xff, 0},
+	{0x2e, 0xdf, 0}, {0xff, 0x1, 0}, {0x3c, 0x32, 0}, {0x11, 0x01, 0},
+	{0x09, 0x00, 0}, {0x04, 0x28, 0}, {0x13, 0xe5, 0}, {0x14, 0x48, 0},
+	{0x2c, 0x0c, 0}, {0x33, 0x78, 0}, {0x3a, 0x33, 0}, {0x3b, 0xfb, 0},
+	{0x3e, 0x00, 0}, {0x43, 0x11, 0}, {0x16, 0x10, 0}, {0x39, 0x82, 0},
+	{0x35, 0x88, 0}, {0x22, 0x0a, 0}, {0x37, 0x40, 0}, {0x23, 0x00, 0},
+	{0x34, 0xa0, 0}, {0x36, 0x1a, 0}, {0x06, 0x02, 0}, {0x07, 0xc0, 0},
+	{0x0d, 0xb7, 0}, {0x0e, 0x01, 0}, {0x4c, 0x00, 0}, {0x4a, 0x81, 0},
+	{0x21, 0x99, 0}, {0x24, 0x40, 0}, {0x25, 0x38, 0}, {0x26, 0x82, 0},
+	{0x5c, 0x00, 0}, {0x63, 0x00, 0}, {0x46, 0x3f, 0}, {0x0c, 0x3c, 0},
+	{0x5d, 0x55, 0}, {0x5e, 0x7d, 0}, {0x5f, 0x7d, 0}, {0x60, 0x55, 0},
+	{0x61, 0x70, 0}, {0x62, 0x80, 0}, {0x7c, 0x05, 0}, {0x20, 0x80, 0},
+	{0x28, 0x30, 0}, {0x6c, 0x00, 0}, {0x6d, 0x80, 0}, {0x6e, 00, 0},
+	{0x70, 0x02, 0}, {0x71, 0x94, 0}, {0x73, 0xc1, 0}, {0x3d, 0x34, 0},
+	{0x5a, 0x57, 0}, {0x4f, 0xbb, 0}, {0x50, 0x9c, 0}, {0xff, 0x00, 0},
+	{0xe5, 0x7f, 0}, {0xf9, 0xc0, 0}, {0x41, 0x24, 0}, {0x44, 0x06, 0},
+	{0xe0, 0x14, 0}, {0x76, 0xff, 0}, {0x33, 0xa0, 0}, {0x42, 0x20, 0},
+	{0x43, 0x18, 0}, {0x4c, 0x00, 0}, {0x87, 0xd0, 0}, {0xd7, 0x03, 0},
+	{0xd9, 0x10, 0}, {0xd3, 0x82, 0}, {0xc8, 0x08, 0}, {0xc9, 0x80, 0},
+	{0x7c, 0x00, 0}, {0x7d, 0x00, 0}, {0x7c, 0x03, 0}, {0x7d, 0x48, 0},
+	{0x7d, 0x48, 0}, {0x7c, 0x08, 0}, {0x7d, 0x20, 0}, {0x7d, 0x10, 0},
+	{0x7d, 0x0e, 0}, {0x90, 0x00, 0}, {0x91, 0x0e, 0}, {0x91, 0x1a, 0},
+	{0x91, 0x31, 0}, {0x91, 0x5a, 0}, {0x91, 0x69, 0}, {0x91, 0x75, 0},
+	{0x91, 0x7e, 0}, {0x91, 0x88, 0}, {0x91, 0x8f, 0}, {0x91, 0x96, 0},
+	{0x91, 0xa3, 0}, {0x91, 0xaf, 0}, {0x91, 0xc4, 0}, {0x91, 0xd7, 0},
+	{0x91, 0xe8, 0}, {0x91, 0x20, 0}, {0x92, 0x00, 0}, {0x93, 0x06, 0},
+	{0x93, 0xe3, 0}, {0x93, 0x03, 0}, {0x93, 0x03, 0}, {0x93, 0x00, 0},
+	{0x93, 0x02, 0}, {0x93, 0x00, 0}, {0x93, 0x00, 0}, {0x93, 0x00, 0},
+	{0x93, 0x00, 0}, {0x93, 0x00, 0}, {0x93, 0x00, 0}, {0x93, 0x00, 0},
+	{0x96, 0x00, 0}, {0x97, 0x08, 0}, {0x97, 0x19, 0}, {0x97, 0x02, 0},
+	{0x97, 0x0c, 0}, {0x97, 0x24, 0}, {0x97, 0x30, 0}, {0x97, 0x28, 0},
+	{0x97, 0x26, 0}, {0x97, 0x02, 0}, {0x97, 0x98, 0}, {0x97, 0x80, 0},
+	{0x97, 0x00, 0}, {0x97, 0x00, 0}, {0xa4, 0x00, 0}, {0xa8, 0x00, 0},
+	{0xc5, 0x11, 0}, {0xc6, 0x51, 0}, {0xbf, 0x80, 0}, {0xc7, 0x10, 0},
+	{0xb6, 0x66, 0}, {0xb8, 0xa5, 0}, {0xb7, 0x64, 0}, {0xb9, 0x7c, 0},
+	{0xb3, 0xaf, 0}, {0xb4, 0x97, 0}, {0xb5, 0xff, 0}, {0xb0, 0xc5, 0},
+	{0xb1, 0x94, 0}, {0xb2, 0x0f, 0}, {0xc4, 0x5c, 0}, {0xa6, 0x00, 0},
+	{0xa7, 0x20, 0}, {0xa7, 0xd8, 0}, {0xa7, 0x1b, 0}, {0xa7, 0x31, 0},
+	{0xa7, 0x00, 0}, {0xa7, 0x18, 0}, {0xa7, 0x20, 0}, {0xa7, 0xd8, 0},
+	{0xa7, 0x19, 0}, {0xa7, 0x31, 0}, {0xa7, 0x00, 0}, {0xa7, 0x18, 0},
+	{0xa7, 0x20, 0}, {0xa7, 0xd8, 0}, {0xa7, 0x19, 0}, {0xa7, 0x31, 0},
+	{0xa7, 0x00, 0}, {0xa7, 0x18, 0}, {0xc0, 0xc8, 0}, {0xc1, 0x96, 0},
+	{0x86, 0x3d, 0}, {0x50, 0x00, 0}, {0x51, 0x90, 0}, {0x52, 0x18, 0},
+	{0x53, 0x00, 0}, {0x54, 0x00, 0}, {0x55, 0x88, 0}, {0x57, 0x00, 0},
+	{0x5a, 0x90, 0}, {0x5b, 0x18, 0}, {0x5c, 0x05, 0}, {0xc3, 0xef, 0},
+	{0x7f, 0x00, 0}, {0xda, 0x01, 0}, {0xe5, 0x1f, 0}, {0xe1, 0x67, 0},
+	{0xe0, 0x00, 0}, {0xdd, 0x7f, 0}, {0x05, 0x00, 0}
+};
+
+static struct reg_value ov2640_setting_800_600[] = {
+	{0xff, 0, 0}, {0xff, 1, 0}, {0x12, 0x80, 1}, {0xff, 00, 0},
+	{0x2c, 0xff, 0}, {0x2e, 0xdf, 0}, {0xff, 0x1, 0}, {0x3c, 0x32, 0},
+	{0x11, 0x01, 0}, {0x09, 0x00, 0}, {0x04, 0x28, 0}, {0x13, 0xe5, 0},
+	{0x14, 0x48, 0}, {0x2c, 0x0c, 0}, {0x33, 0x78, 0}, {0x3a, 0x33, 0},
+	{0x3b, 0xfb, 0}, {0x3e, 0x00, 0}, {0x43, 0x11, 0}, {0x16, 0x10, 0},
+	{0x39, 0x92, 0}, {0x35, 0xda, 0}, {0x22, 0x1a, 0}, {0x37, 0xc3, 0},
+	{0x23, 0x00, 0}, {0x34, 0xc0, 0}, {0x36, 0x1a, 0}, {0x06, 0x88, 0},
+	{0x07, 0xc0, 0}, {0x0d, 0x87, 0}, {0x0e, 0x41, 0}, {0x4c, 0x00, 0},
+	{0x4a, 0x81, 0}, {0x21, 0x99, 0}, {0x24, 0x40, 0}, {0x25, 0x38, 0},
+	{0x26, 0x82, 0}, {0x5c, 0x00, 0}, {0x63, 0x00, 0}, {0x46, 0x22, 0},
+	{0x0c, 0x3c, 0}, {0x5d, 0x55, 0}, {0x5e, 0x7d, 0}, {0x5f, 0x7d, 0},
+	{0x60, 0x55, 0}, {0x61, 0x70, 0}, {0x62, 0x80, 0}, {0x7c, 0x05, 0},
+	{0x20, 0x80, 0}, {0x28, 0x30, 0}, {0x6c, 0x00, 0}, {0x6d, 0x80, 0},
+	{0x6e, 00, 0}, {0x70, 0x02, 0}, {0x71, 0x94, 0}, {0x73, 0xc1, 0},
+	{0x12, 0x40, 0}, {0x17, 0x11, 0}, {0x18, 0x43, 0}, {0x19, 0x00, 0},
+	{0x1a, 0x4b, 0}, {0x32, 0x09, 0}, {0x37, 0xc0, 0}, {0x4f, 0xca, 0},
+	{0x50, 0xa8, 0}, {0x6d, 0x00, 0}, {0x3d, 0x38, 0}, {0xff, 0x00, 0},
+	{0xe5, 0x7f, 0}, {0xf9, 0xc0, 0}, {0x41, 0x24, 0}, {0x44, 0x06, 0},
+	{0xe0, 0x14, 0}, {0x76, 0xff, 0}, {0x33, 0xa0, 0}, {0x42, 0x20, 0},
+	{0x43, 0x18, 0}, {0x4c, 0x00, 0}, {0x87, 0xd0, 0}, {0x88, 0x3f, 0},
+	{0xd7, 0x03, 0}, {0xd9, 0x10, 0}, {0xd3, 0x82, 0}, {0xc8, 0x08, 0},
+	{0xc9, 0x80, 0}, {0x7c, 0x00, 0}, {0x7d, 0x00, 0}, {0x7c, 0x03, 0},
+	{0x7d, 0x48, 0}, {0x7d, 0x48, 0}, {0x7c, 0x08, 0}, {0x7d, 0x20, 0},
+	{0x7d, 0x10, 0}, {0x7d, 0x0e, 0}, {0x90, 0x00, 0}, {0x91, 0x0e, 0},
+	{0x91, 0x1a, 0}, {0x91, 0x31, 0}, {0x91, 0x5a, 0}, {0x91, 0x69, 0},
+	{0x91, 0x75, 0}, {0x91, 0x7e, 0}, {0x91, 0x88, 0}, {0x91, 0x8f, 0},
+	{0x91, 0x96, 0}, {0x91, 0xa3, 0}, {0x91, 0xaf, 0}, {0x91, 0xc4, 0},
+	{0x91, 0xd7, 0}, {0x91, 0xe8, 0}, {0x91, 0x20, 0}, {0x92, 0x00, 0},
+	{0x93, 0x06, 0}, {0x93, 0xe3, 0}, {0x93, 0x03, 0}, {0x93, 0x03, 0},
+	{0x93, 0x00, 0}, {0x93, 0x02, 0}, {0x93, 0x00, 0}, {0x93, 0x00, 0},
+	{0x93, 0x00, 0}, {0x93, 0x00, 0}, {0x93, 0x00, 0}, {0x93, 0x00, 0},
+	{0x93, 0x00, 0}, {0x96, 0x00, 0}, {0x97, 0x08, 0}, {0x97, 0x19, 0},
+	{0x97, 0x02, 0}, {0x97, 0x0c, 0}, {0x97, 0x24, 0}, {0x97, 0x30, 0},
+	{0x97, 0x28, 0}, {0x97, 0x26, 0}, {0x97, 0x02, 0}, {0x97, 0x98, 0},
+	{0x97, 0x80, 0}, {0x97, 0x00, 0}, {0x97, 0x00, 0}, {0xa4, 0x00, 0},
+	{0xa8, 0x00, 0}, {0xc5, 0x11, 0}, {0xc6, 0x51, 0}, {0xbf, 0x80, 0},
+	{0xc7, 0x10, 0}, {0xb6, 0x66, 0}, {0xb8, 0xa5, 0}, {0xb7, 0x64, 0},
+	{0xb9, 0x7c, 0}, {0xb3, 0xaf, 0}, {0xb4, 0x97, 0}, {0xb5, 0xff, 0},
+	{0xb0, 0xc5, 0}, {0xb1, 0x94, 0}, {0xb2, 0x0f, 0}, {0xc4, 0x5c, 0},
+	{0xa6, 0x00, 0}, {0xa7, 0x20, 0}, {0xa7, 0xd8, 0}, {0xa7, 0x1b, 0},
+	{0xa7, 0x31, 0}, {0xa7, 0x00, 0}, {0xa7, 0x18, 0}, {0xa7, 0x20, 0},
+	{0xa7, 0xd8, 0}, {0xa7, 0x19, 0}, {0xa7, 0x31, 0}, {0xa7, 0x00, 0},
+	{0xa7, 0x18, 0}, {0xa7, 0x20, 0}, {0xa7, 0xd8, 0}, {0xa7, 0x19, 0},
+	{0xa7, 0x31, 0}, {0xa7, 0x00, 0}, {0xa7, 0x18, 0}, {0xc0, 0x64, 0},
+	{0xc1, 0x4b, 0}, {0x86, 0x1d, 0}, {0x50, 0x00, 0}, {0x51, 0xc8, 0},
+	{0x52, 0x96, 0}, {0x53, 0x00, 0}, {0x54, 0x00, 0}, {0x55, 0x00, 0},
+	{0x57, 0x00, 0}, {0x5a, 0xc8, 0}, {0x5b, 0x96, 0}, {0x5c, 0x00, 0},
+	{0xc3, 0xef, 0}, {0x7f, 0x00, 0}, {0xda, 0x01, 0}, {0xe5, 0x1f, 0},
+	{0xe1, 0x67, 0}, {0xe0, 0x00, 0}, {0xdd, 0x7f, 0}, {0x05, 0x00, 0}
+};
+
+static struct regulator *io_regulator;
+static struct regulator *core_regulator;
+static struct regulator *analog_regulator;
+static struct regulator *gpo_regulator;
+u32 mclk = 24000000;
+
+struct i2c_client *ov2640_i2c_client;
+
+static sensor_interface *interface_param;
+static int reset_frame_rate = 30;
+static int ov2640_probe(struct i2c_client *adapter,
+			const struct i2c_device_id *id);
+static int ov2640_remove(struct i2c_client *client);
+
+static const struct i2c_device_id ov2640_id[] = {
+	{"ov2640", 0},
+	{},
+};
+
+MODULE_DEVICE_TABLE(i2c, ov2640_id);
+
+static struct i2c_driver ov2640_i2c_driver = {
+	.driver = {
+		   .owner = THIS_MODULE,
+		   .name = "ov2640",
+		   },
+	.probe = ov2640_probe,
+	.remove = ov2640_remove,
+	.id_table = ov2640_id,
+};
+
+/*!
+ * ov2640 I2C attach function
+ *
+ * @param adapter            struct i2c_adapter *
+ * @return  Error code indicating success or failure
+ */
+static int ov2640_probe(struct i2c_client *client,
+			const struct i2c_device_id *id)
+{
+	struct mxc_camera_platform_data *plat_data = client->dev.platform_data;
+
+	ov2640_i2c_client = client;
+	mclk = plat_data->mclk;
+
+	io_regulator = regulator_get(&client->dev, plat_data->io_regulator);
+	core_regulator = regulator_get(&client->dev, plat_data->core_regulator);
+	analog_regulator =
+	    regulator_get(&client->dev, plat_data->analog_regulator);
+	gpo_regulator = regulator_get(&client->dev, plat_data->gpo_regulator);
+
+	interface_param = (sensor_interface *)
+	    kmalloc(sizeof(sensor_interface), GFP_KERNEL);
+	if (!interface_param) {
+		dev_dbg(&ov2640_i2c_client->dev,
+			"ov2640_probe: kmalloc failed \n");
+		return -1;
+	}
+
+	return 0;
+}
+
+/*!
+ * ov2640 I2C detach function
+ *
+ * @param client            struct i2c_client *
+ * @return  Error code indicating success or failure
+ */
+static int ov2640_remove(struct i2c_client *client)
+{
+	kfree(interface_param);
+	interface_param = NULL;
+
+	if (!IS_ERR_VALUE((unsigned long)io_regulator)) {
+		regulator_disable(io_regulator);
+		regulator_put(io_regulator, NULL);
+	}
+
+	if (!IS_ERR_VALUE((unsigned long)core_regulator)) {
+		regulator_disable(core_regulator);
+		regulator_put(core_regulator, NULL);
+	}
+
+	if (!IS_ERR_VALUE((unsigned long)gpo_regulator)) {
+		regulator_disable(gpo_regulator);
+		regulator_put(gpo_regulator, NULL);
+	}
+
+	if (!IS_ERR_VALUE((unsigned long)analog_regulator)) {
+		regulator_disable(analog_regulator);
+		regulator_put(analog_regulator, NULL);
+	}
+
+	return 0;
+}
+
+static int ov2640_write_reg(u8 reg, u8 val)
+{
+	if (i2c_smbus_write_byte_data(ov2640_i2c_client, reg, val) < 0) {
+		dev_dbg(&ov2640_i2c_client->dev,
+			"%s:write reg errorr:reg=%x,val=%x\n", __func__, reg,
+			val);
+		return -1;
+	}
+	return 0;
+}
+
+static int ov2640_init_mode(enum ov2640_mode mode)
+{
+	struct reg_value *setting;
+	int i, num;
+
+	switch (mode) {
+	case ov2640_mode_1600_1120:
+		setting = ov2640_setting_1600_1120;
+		num = ARRAY_SIZE(ov2640_setting_1600_1120);
+		break;
+	case ov2640_mode_800_600:
+		setting = ov2640_setting_800_600;
+		num = ARRAY_SIZE(ov2640_setting_800_600);
+		break;
+	default:
+		return 0;
+	}
+
+	for (i = 0; i < num; i++) {
+		ov2640_write_reg(setting[i].reg, setting[i].value);
+		if (setting[i].delay_ms > 0)
+			msleep(setting[i].delay_ms);
+	}
+
+	return 0;
+}
+
+/*!
+ * ov2640 sensor interface Initialization
+ * @param param            sensor_interface *
+ * @param width            u32
+ * @param height           u32
+ * @return  None
+ */
+static void ov2640_interface(sensor_interface *param, u32 width, u32 height)
+{
+	param->Vsync_pol = 0x0;
+	param->clk_mode = 0x0;	/*gated */
+	param->pixclk_pol = 0x0;
+	param->data_width = 0x1;
+	param->data_pol = 0x0;
+	param->ext_vsync = 0x0;
+	param->Vsync_pol = 0x0;
+	param->Hsync_pol = 0x0;
+	param->width = width - 1;
+	param->height = height - 1;
+	param->active_width = width;
+	param->active_height = height;
+	param->pixel_fmt = IPU_PIX_FMT_UYVY;
+	param->mclk = mclk;
+}
+
+static void ov2640_set_color(int bright, int saturation, int red, int green,
+			     int blue)
+{
+
+}
+
+static void ov2640_get_color(int *bright, int *saturation, int *red, int *green,
+			     int *blue)
+{
+
+}
+static void ov2640_set_ae_mode(int ae_mode)
+{
+
+}
+static void ov2640_get_ae_mode(int *ae_mode)
+{
+
+}
+
+extern void gpio_sensor_active(void);
+
+static sensor_interface *ov2640_config(int *frame_rate, int high_quality)
+{
+
+	u32 out_width, out_height;
+
+	/*set io votage */
+	if (!IS_ERR_VALUE((unsigned long)io_regulator)) {
+		regulator_set_voltage(io_regulator, 2800000);
+		if (regulator_enable(io_regulator) != 0) {
+			dev_dbg(&ov2640_i2c_client->dev,
+				"%s:io set voltage error\n", __func__);
+			return NULL;
+		} else {
+			dev_dbg(&ov2640_i2c_client->dev,
+				"%s:io set voltage ok\n", __func__);
+		}
+	}
+
+	/*core votage */
+	if (!IS_ERR_VALUE((unsigned long)core_regulator)) {
+		regulator_set_voltage(core_regulator, 1300000);
+		if (regulator_enable(core_regulator) != 0) {
+			dev_dbg(&ov2640_i2c_client->dev,
+				"%s:core set voltage error\n", __func__);
+			return NULL;
+		} else {
+			dev_dbg(&ov2640_i2c_client->dev,
+				"%s:core set voltage ok\n", __func__);
+		}
+	}
+
+	/*GPO 3 */
+	if (!IS_ERR_VALUE((unsigned long)gpo_regulator)) {
+		if (regulator_enable(gpo_regulator) != 0) {
+			dev_dbg(&ov2640_i2c_client->dev,
+				"%s:gpo3 enable error\n", __func__);
+			return NULL;
+		} else {
+			dev_dbg(&ov2640_i2c_client->dev, "%s:gpo3 enable ok\n",
+				__func__);
+		}
+	}
+
+	if (!IS_ERR_VALUE((unsigned long)analog_regulator)) {
+		regulator_set_voltage(analog_regulator, 2000000);
+		if (regulator_enable(analog_regulator) != 0) {
+			dev_dbg(&ov2640_i2c_client->dev,
+				"%s:analog set voltage error\n", __func__);
+			return NULL;
+		} else {
+			dev_dbg(&ov2640_i2c_client->dev,
+				"%s:analog set voltage ok\n", __func__);
+		}
+	}
+
+	gpio_sensor_active();
+
+	if (high_quality) {
+		out_width = 1600;
+		out_height = 1120;
+	} else {
+		out_width = 800;
+		out_height = 600;
+	}
+	ov2640_interface(interface_param, out_width, out_height);
+	set_mclk_rate(&interface_param->mclk);
+
+	if (high_quality)
+		ov2640_init_mode(ov2640_mode_1600_1120);
+	else
+		ov2640_init_mode(ov2640_mode_800_600);
+
+	msleep(300);
+
+	return interface_param;
+}
+
+static sensor_interface *ov2640_reset(void)
+{
+	return ov2640_config(&reset_frame_rate, 0);
+}
+
+struct camera_sensor camera_sensor_if = {
+	.set_color = ov2640_set_color,
+	.get_color = ov2640_get_color,
+	.set_ae_mode = ov2640_set_ae_mode,
+	.get_ae_mode = ov2640_get_ae_mode,
+	.config = ov2640_config,
+	.reset = ov2640_reset,
+};
+
+EXPORT_SYMBOL(camera_sensor_if);
+
+/*!
+ * ov2640 init function
+ *
+ * @return  Error code indicating success or failure
+ */
+static __init int ov2640_init(void)
+{
+	u8 err;
+
+	err = i2c_add_driver(&ov2640_i2c_driver);
+
+	return err;
+}
+
+extern void gpio_sensor_inactive(void);
+/*!
+ * OV2640 cleanup function
+ *
+ * @return  Error code indicating success or failure
+ */
+static void __exit ov2640_clean(void)
+{
+	i2c_del_driver(&ov2640_i2c_driver);
+
+	gpio_sensor_inactive();
+}
+
+module_init(ov2640_init);
+module_exit(ov2640_clean);
+
+MODULE_AUTHOR("Freescale Semiconductor, Inc.");
+MODULE_DESCRIPTION("OV2640 Camera Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/media/video/mxc/capture/emma_v4l2_capture.c b/drivers/media/video/mxc/capture/emma_v4l2_capture.c
new file mode 100644
index 0000000..4d7bc5c
--- /dev/null
+++ b/drivers/media/video/mxc/capture/emma_v4l2_capture.c
@@ -0,0 +1,2075 @@
+/*
+ * Copyright 2004-2008 Freescale Semiconductor, Inc. All Rights Reserved.
+ */
+
+/*
+ * The code contained herein is licensed under the GNU General Public
+ * License. You may obtain a copy of the GNU General Public License
+ * Version 2 or later at the following locations:
+ *
+ * http://www.opensource.org/licenses/gpl-license.html
+ * http://www.gnu.org/copyleft/gpl.html
+ */
+
+/*!
+ * @file mx27_v4l2_capture.c
+ *
+ * @brief MX27 Video For Linux 2 driver
+ *
+ * @ingroup MXC_V4L2_CAPTURE
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/fs.h>
+#include <linux/slab.h>
+#include <linux/ctype.h>
+#include <linux/pagemap.h>
+#include <linux/vmalloc.h>
+#include <linux/types.h>
+#include <linux/fb.h>
+#include <linux/pci.h>
+#include <linux/platform_device.h>
+#include <linux/version.h>
+#include <media/v4l2-dev.h>
+#include <asm/io.h>
+#include <asm/semaphore.h>
+
+#include "mxc_v4l2_capture.h"
+#include "mx27_prp.h"
+#include "mx27_csi.h"
+
+static int csi_mclk_flag_backup;
+static int video_nr = -1;
+static cam_data *g_cam;
+
+/*!
+ * Free frame buffers
+ *
+ * @param cam      Structure cam_data *
+ *
+ * @return status  0 success.
+ */
+static int mxc_free_frame_buf(cam_data *cam)
+{
+	int i;
+
+	for (i = 0; i < FRAME_NUM; i++) {
+		if (cam->frame[i].vaddress != 0) {
+			dma_free_coherent(0,
+					  cam->frame[i].buffer.length,
+					  cam->frame[i].vaddress,
+					  cam->frame[i].paddress);
+			cam->frame[i].vaddress = 0;
+		}
+	}
+
+	return 0;
+}
+
+/*!
+ * Allocate frame buffers
+ *
+ * @param cam      Structure cam_data *
+ *
+ * @param count    int number of buffer need to allocated
+ *
+ * @return status  -0 Successfully allocated a buffer, -ENOBUFS	failed.
+ */
+static int mxc_allocate_frame_buf(cam_data *cam, int count)
+{
+	int i;
+
+	for (i = 0; i < count; i++) {
+		cam->frame[i].vaddress =
+			dma_alloc_coherent(0,
+					PAGE_ALIGN(cam->v2f. fmt.pix.sizeimage),
+					   &cam->frame[i].paddress,
+					   GFP_DMA | GFP_KERNEL);
+		if (cam->frame[i].vaddress == 0) {
+			pr_debug("mxc_allocate_frame_buf failed.\n");
+			mxc_free_frame_buf(cam);
+			return -ENOBUFS;
+		}
+		cam->frame[i].buffer.index = i;
+		cam->frame[i].buffer.flags = V4L2_BUF_FLAG_MAPPED;
+		cam->frame[i].buffer.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+		cam->frame[i].buffer.length =
+		    PAGE_ALIGN(cam->v2f.fmt.pix.sizeimage);
+		cam->frame[i].buffer.memory = V4L2_MEMORY_MMAP;
+		cam->frame[i].buffer.m.offset = cam->frame[i].paddress;
+		cam->frame[i].index = i;
+	}
+
+	return 0;
+}
+
+/*!
+ * Free frame buffers status
+ *
+ * @param cam    Structure cam_data *
+ *
+ * @return none
+ */
+static void mxc_free_frames(cam_data *cam)
+{
+	int i;
+
+	for (i = 0; i < FRAME_NUM; i++) {
+		cam->frame[i].buffer.flags = V4L2_BUF_FLAG_MAPPED;
+	}
+
+	cam->enc_counter = 0;
+	cam->skip_frame = 0;
+	INIT_LIST_HEAD(&cam->ready_q);
+	INIT_LIST_HEAD(&cam->working_q);
+	INIT_LIST_HEAD(&cam->done_q);
+}
+
+/*!
+ * Return the buffer status
+ *
+ * @param cam 	   Structure cam_data *
+ * @param buf      Structure v4l2_buffer *
+ *
+ * @return status  0 success, EINVAL failed.
+ */
+static int mxc_v4l2_buffer_status(cam_data *cam, struct v4l2_buffer *buf)
+{
+	/* check range */
+	if (buf->index < 0 || buf->index >= FRAME_NUM) {
+		pr_debug("mxc_v4l2_buffer_status buffers not allocated\n");
+		return -EINVAL;
+	}
+
+	memcpy(buf, &(cam->frame[buf->index].buffer), sizeof(*buf));
+	return 0;
+}
+
+/*!
+ * start the encoder job
+ *
+ * @param cam      structure cam_data *
+ *
+ * @return status  0 Success
+ */
+static int mxc_streamon(cam_data *cam)
+{
+	struct mxc_v4l_frame *frame;
+	int err = 0;
+
+	if (!cam)
+		return -EIO;
+
+	if (list_empty(&cam->ready_q)) {
+		printk(KERN_ERR "mxc_streamon buffer not been queued yet\n");
+		return -EINVAL;
+	}
+
+	cam->capture_pid = current->pid;
+
+	if (cam->enc_enable) {
+		err = cam->enc_enable(cam);
+		if (err != 0) {
+			return err;
+		}
+	}
+
+	cam->ping_pong_csi = 0;
+	if (cam->enc_update_eba) {
+		frame =
+		    list_entry(cam->ready_q.next, struct mxc_v4l_frame, queue);
+		list_del(cam->ready_q.next);
+		list_add_tail(&frame->queue, &cam->working_q);
+		err = cam->enc_update_eba(frame->paddress, &cam->ping_pong_csi);
+
+		frame =
+		    list_entry(cam->ready_q.next, struct mxc_v4l_frame, queue);
+		list_del(cam->ready_q.next);
+		list_add_tail(&frame->queue, &cam->working_q);
+		err |=
+		    cam->enc_update_eba(frame->paddress, &cam->ping_pong_csi);
+	} else {
+		return -EINVAL;
+	}
+
+	return err;
+}
+
+/*!
+ * Shut down the encoder job
+ *
+ * @param cam      structure cam_data *
+ *
+ * @return status  0 Success
+ */
+static int mxc_streamoff(cam_data *cam)
+{
+	int err = 0;
+
+	if (!cam)
+		return -EIO;
+
+	if (cam->enc_disable) {
+		err = cam->enc_disable(cam);
+	}
+	mxc_free_frames(cam);
+	return err;
+}
+
+/*!
+ * Valid whether the palette is supported
+ *
+ * @param palette pixel format
+ *
+ * @return 0 if failed
+ */
+static inline int valid_mode(u32 palette)
+{
+	/*
+	 * MX27 PrP channel 2 supports YUV444, but YUV444 is not
+	 * defined by V4L2 :(
+	 */
+	return ((palette == V4L2_PIX_FMT_YUYV) ||
+		(palette == V4L2_PIX_FMT_YUV420));
+}
+
+/*!
+ * Valid and adjust the overlay window size, position
+ *
+ * @param cam      structure cam_data *
+ * @param win      struct v4l2_window  *
+ *
+ * @return 0
+ */
+static int verify_preview(cam_data *cam, struct v4l2_window *win)
+{
+	if (cam->output >= num_registered_fb) {
+		pr_debug("verify_preview No matched.\n");
+		return -1;
+	}
+	cam->overlay_fb = (struct fb_info *)registered_fb[cam->output];
+
+	/* TODO: suppose 16bpp, 4 bytes alignment */
+	win->w.left &= ~0x1;
+
+	if (win->w.width + win->w.left > cam->overlay_fb->var.xres)
+		win->w.width = cam->overlay_fb->var.xres - win->w.left;
+	if (win->w.height + win->w.top > cam->overlay_fb->var.yres)
+		win->w.height = cam->overlay_fb->var.yres - win->w.top;
+
+	/*
+	 * TODO: suppose 16bpp. Rounded down to a multiple of 2 pixels for
+	 * width according to PrP limitations.
+	 */
+	if ((cam->rotation == V4L2_MXC_ROTATE_90_RIGHT)
+	    || (cam->rotation == V4L2_MXC_ROTATE_90_RIGHT_VFLIP)
+	    || (cam->rotation == V4L2_MXC_ROTATE_90_RIGHT_HFLIP)
+	    || (cam->rotation == V4L2_MXC_ROTATE_90_LEFT))
+		win->w.height &= ~0x1;
+	else
+		win->w.width &= ~0x1;
+
+	return 0;
+}
+
+/*!
+ * start the viewfinder job
+ *
+ * @param cam      structure cam_data *
+ *
+ * @return status  0 Success
+ */
+static int start_preview(cam_data *cam)
+{
+	int err = 0;
+
+	err = prp_vf_select(cam);
+	if (err != 0)
+		return err;
+
+	cam->overlay_pid = current->pid;
+	err = cam->vf_start_sdc(cam);
+
+	return err;
+}
+
+/*!
+ * shut down the viewfinder job
+ *
+ * @param cam      structure cam_data *
+ *
+ * @return status  0 Success
+ */
+static int stop_preview(cam_data *cam)
+{
+	int err = 0;
+
+	err = prp_vf_deselect(cam);
+	return err;
+}
+
+/*!
+ * V4L2 - mxc_v4l2_g_fmt function
+ *
+ * @param cam         structure cam_data *
+ *
+ * @param f           structure v4l2_format *
+ *
+ * @return  status    0 success, EINVAL failed
+ */
+static int mxc_v4l2_g_fmt(cam_data *cam, struct v4l2_format *f)
+{
+	int retval = 0;
+
+	switch (f->type) {
+	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
+		f->fmt.pix.width = cam->v2f.fmt.pix.width;
+		f->fmt.pix.height = cam->v2f.fmt.pix.height;
+		f->fmt.pix.sizeimage = cam->v2f.fmt.pix.sizeimage;
+		f->fmt.pix.pixelformat = cam->v2f.fmt.pix.pixelformat;
+		f->fmt.pix.bytesperline = cam->v2f.fmt.pix.bytesperline;
+		f->fmt.pix.colorspace = V4L2_COLORSPACE_JPEG;
+		retval = 0;
+		break;
+	case V4L2_BUF_TYPE_VIDEO_OVERLAY:
+		f->fmt.win = cam->win;
+		break;
+	default:
+		retval = -EINVAL;
+	}
+	return retval;
+}
+
+/*!
+ * V4L2 - mxc_v4l2_s_fmt function
+ *
+ * @param cam         structure cam_data *
+ *
+ * @param f           structure v4l2_format *
+ *
+ * @return  status    0 success, EINVAL failed
+ */
+static int mxc_v4l2_s_fmt(cam_data *cam, struct v4l2_format *f)
+{
+	int retval = 0;
+	int size = 0;
+	int bytesperline = 0;
+
+	switch (f->type) {
+	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
+		if (!valid_mode(f->fmt.pix.pixelformat)) {
+			pr_debug("mxc_v4l2_s_fmt: format not supported\n");
+			retval = -EINVAL;
+		}
+
+		if (cam->rotation != V4L2_MXC_ROTATE_NONE)
+			pr_debug("mxc_v4l2_s_fmt: capture rotation ignored\n");
+
+		switch (f->fmt.pix.pixelformat) {
+		case V4L2_PIX_FMT_YUYV:
+			f->fmt.pix.width &= ~0x1;	/* Multiple of 2 */
+			size = f->fmt.pix.width * f->fmt.pix.height * 2;
+			bytesperline = f->fmt.pix.width * 2;
+			break;
+		case V4L2_PIX_FMT_YUV420:
+			f->fmt.pix.width &= ~0x7;	/* Multiple of 8 */
+			f->fmt.pix.height &= ~0x1;	/* Multiple of 2 */
+			size = f->fmt.pix.width * f->fmt.pix.height * 3 / 2;
+			bytesperline = f->fmt.pix.width * 3 / 2;
+			break;
+		default:
+			/* Suppose it's YUV444 or 32bpp */
+			size = f->fmt.pix.width * f->fmt.pix.height * 4;
+			bytesperline = f->fmt.pix.width * 4;
+			pr_info("mxc_v4l2_s_fmt: default assume"
+				" to be YUV444 interleaved.\n");
+			break;
+		}
+
+		if (f->fmt.pix.bytesperline < bytesperline) {
+			f->fmt.pix.bytesperline = bytesperline;
+		} else {
+			bytesperline = f->fmt.pix.bytesperline;
+		}
+
+		if (f->fmt.pix.sizeimage > size) {
+			pr_debug("mxc_v4l2_s_fmt: sizeimage bigger than"
+				 " needed.\n");
+			size = f->fmt.pix.sizeimage;
+		}
+		f->fmt.pix.sizeimage = size;
+
+		cam->v2f.fmt.pix.sizeimage = size;
+		cam->v2f.fmt.pix.bytesperline = bytesperline;
+		cam->v2f.fmt.pix.width = f->fmt.pix.width;
+		cam->v2f.fmt.pix.height = f->fmt.pix.height;
+		cam->v2f.fmt.pix.pixelformat = f->fmt.pix.pixelformat;
+		retval = 0;
+		break;
+	case V4L2_BUF_TYPE_VIDEO_OVERLAY:
+		retval = verify_preview(cam, &f->fmt.win);
+		cam->win = f->fmt.win;
+		break;
+	default:
+		retval = -EINVAL;
+	}
+	return retval;
+}
+
+/*!
+ * get control param
+ *
+ * @param cam         structure cam_data *
+ *
+ * @param c           structure v4l2_control *
+ *
+ * @return  status    0 success, EINVAL failed
+ */
+static int mxc_get_v42l_control(cam_data *cam, struct v4l2_control *c)
+{
+	int status = 0;
+
+	switch (c->id) {
+	case V4L2_CID_HFLIP:
+		c->value = cam->rotation;
+		break;
+	case V4L2_CID_VFLIP:
+		c->value = cam->rotation;
+		break;
+	case V4L2_CID_MXC_ROT:
+		c->value = cam->rotation;
+		break;
+	case V4L2_CID_BRIGHTNESS:
+		c->value = cam->bright;
+		break;
+	case V4L2_CID_HUE:
+		c->value = cam->hue;
+		break;
+	case V4L2_CID_CONTRAST:
+		c->value = cam->contrast;
+		break;
+	case V4L2_CID_SATURATION:
+		c->value = cam->saturation;
+		break;
+	case V4L2_CID_RED_BALANCE:
+		c->value = cam->red;
+		break;
+	case V4L2_CID_BLUE_BALANCE:
+		c->value = cam->blue;
+		break;
+	case V4L2_CID_BLACK_LEVEL:
+		c->value = cam->ae_mode;
+		break;
+	default:
+		status = -EINVAL;
+	}
+	return status;
+}
+
+/*!
+ * V4L2 - set_control function
+ * V4L2_CID_MXC_ROT is the extention for rotation/mirroring.
+ *
+ * @param cam         structure cam_data *
+ *
+ * @param c           structure v4l2_control *
+ *
+ * @return  status    0 success, EINVAL failed
+ */
+static int mxc_set_v42l_control(cam_data *cam, struct v4l2_control *c)
+{
+	switch (c->id) {
+	case V4L2_CID_HFLIP:
+		if (c->value == 1) {
+			if ((cam->rotation != V4L2_MXC_ROTATE_VERT_FLIP) &&
+			    (cam->rotation != V4L2_MXC_ROTATE_180))
+				cam->rotation = V4L2_MXC_ROTATE_HORIZ_FLIP;
+			else
+				cam->rotation = V4L2_MXC_ROTATE_180;
+		} else {
+			if (cam->rotation == V4L2_MXC_ROTATE_HORIZ_FLIP)
+				cam->rotation = V4L2_MXC_ROTATE_NONE;
+			else if (cam->rotation == V4L2_MXC_ROTATE_180)
+				cam->rotation = V4L2_MXC_ROTATE_VERT_FLIP;
+		}
+		break;
+	case V4L2_CID_VFLIP:
+		if (c->value == 1) {
+			if ((cam->rotation != V4L2_MXC_ROTATE_HORIZ_FLIP) &&
+			    (cam->rotation != V4L2_MXC_ROTATE_180))
+				cam->rotation = V4L2_MXC_ROTATE_VERT_FLIP;
+			else
+				cam->rotation = V4L2_MXC_ROTATE_180;
+		} else {
+			if (cam->rotation == V4L2_MXC_ROTATE_VERT_FLIP)
+				cam->rotation = V4L2_MXC_ROTATE_NONE;
+			if (cam->rotation == V4L2_MXC_ROTATE_180)
+				cam->rotation = V4L2_MXC_ROTATE_HORIZ_FLIP;
+		}
+		break;
+	case V4L2_CID_MXC_ROT:
+		switch (c->value) {
+		case V4L2_MXC_ROTATE_NONE:
+		case V4L2_MXC_ROTATE_VERT_FLIP:
+		case V4L2_MXC_ROTATE_HORIZ_FLIP:
+		case V4L2_MXC_ROTATE_180:
+		case V4L2_MXC_ROTATE_90_RIGHT:
+		case V4L2_MXC_ROTATE_90_RIGHT_VFLIP:
+		case V4L2_MXC_ROTATE_90_RIGHT_HFLIP:
+		case V4L2_MXC_ROTATE_90_LEFT:
+			cam->rotation = c->value;
+			break;
+		default:
+			return -EINVAL;
+		}
+		break;
+	case V4L2_CID_HUE:
+		cam->hue = c->value;
+		break;
+	case V4L2_CID_CONTRAST:
+		cam->contrast = c->value;
+		break;
+	case V4L2_CID_BRIGHTNESS:
+		cam->bright = c->value;
+	case V4L2_CID_SATURATION:
+		cam->saturation = c->value;
+	case V4L2_CID_RED_BALANCE:
+		cam->red = c->value;
+	case V4L2_CID_BLUE_BALANCE:
+		cam->blue = c->value;
+		csi_enable_mclk(CSI_MCLK_I2C, true, true);
+		cam->cam_sensor->set_color(cam->bright, cam->saturation,
+					   cam->red, cam->green, cam->blue);
+		csi_enable_mclk(CSI_MCLK_I2C, false, false);
+		break;
+	case V4L2_CID_BLACK_LEVEL:
+		cam->ae_mode = c->value & 0x03;
+		csi_enable_mclk(CSI_MCLK_I2C, true, true);
+		if (cam->cam_sensor->set_ae_mode)
+			cam->cam_sensor->set_ae_mode(cam->ae_mode);
+		csi_enable_mclk(CSI_MCLK_I2C, false, false);
+		break;
+	case V4L2_CID_MXC_FLASH:
+		break;
+	default:
+		return -EINVAL;
+	}
+	return 0;
+}
+
+/*!
+ * V4L2 - mxc_v4l2_s_param function
+ *
+ * @param cam         structure cam_data *
+ *
+ * @param parm        structure v4l2_streamparm *
+ *
+ * @return  status    0 success, EINVAL failed
+ */
+static int mxc_v4l2_s_param(cam_data *cam, struct v4l2_streamparm *parm)
+{
+	sensor_interface *param;
+	csi_signal_cfg_t csi_param;
+
+	if (parm->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) {
+		pr_debug("mxc_v4l2_s_param invalid type\n");
+		return -EINVAL;
+	}
+
+	if (parm->parm.capture.timeperframe.denominator >
+	    cam->standard.frameperiod.denominator) {
+		pr_debug("mxc_v4l2_s_param frame rate %d larger "
+			 "than standard supported %d\n",
+			 parm->parm.capture.timeperframe.denominator,
+			 cam->standard.frameperiod.denominator);
+		return -EINVAL;
+	}
+
+	cam->streamparm.parm.capture.capability = V4L2_CAP_TIMEPERFRAME;
+
+	csi_enable_mclk(CSI_MCLK_I2C, true, true);
+	param = cam->cam_sensor->config
+	    (&parm->parm.capture.timeperframe.denominator,
+	     parm->parm.capture.capturemode);
+	csi_enable_mclk(CSI_MCLK_I2C, false, false);
+
+	cam->streamparm.parm.capture.timeperframe =
+	    parm->parm.capture.timeperframe;
+
+	if ((parm->parm.capture.capturemode != 0) &&
+	    (parm->parm.capture.capturemode != V4L2_MODE_HIGHQUALITY)) {
+		pr_debug("mxc_v4l2_s_param frame un-supported capture mode\n");
+		return -EINVAL;
+	}
+
+	if (parm->parm.capture.capturemode ==
+	    cam->streamparm.parm.capture.capturemode) {
+		return 0;
+	}
+
+	/* resolution changed, so need to re-program the CSI */
+	csi_param.sens_clksrc = 0;
+	csi_param.clk_mode = param->clk_mode;
+	csi_param.pixclk_pol = param->pixclk_pol;
+	csi_param.data_width = param->data_width;
+	csi_param.data_pol = param->data_pol;
+	csi_param.ext_vsync = param->ext_vsync;
+	csi_param.Vsync_pol = param->Vsync_pol;
+	csi_param.Hsync_pol = param->Hsync_pol;
+	csi_init_interface(param->width, param->height, param->pixel_fmt,
+			   csi_param);
+
+	if (parm->parm.capture.capturemode != V4L2_MODE_HIGHQUALITY) {
+		cam->streamparm.parm.capture.capturemode = 0;
+	} else {
+		cam->streamparm.parm.capture.capturemode =
+		    V4L2_MODE_HIGHQUALITY;
+		cam->streamparm.parm.capture.extendedmode =
+		    parm->parm.capture.extendedmode;
+		cam->streamparm.parm.capture.readbuffers = 1;
+	}
+	return 0;
+}
+
+/*!
+ * Dequeue one V4L capture buffer
+ *
+ * @param cam         structure cam_data *
+ * @param buf         structure v4l2_buffer *
+ *
+ * @return  status    0 success, EINVAL invalid frame number,
+ *                    ETIME timeout, ERESTARTSYS interrupted by user
+ */
+static int mxc_v4l_dqueue(cam_data *cam, struct v4l2_buffer *buf)
+{
+	int retval = 0;
+	struct mxc_v4l_frame *frame;
+
+	if (!wait_event_interruptible_timeout(cam->enc_queue,
+					      cam->enc_counter != 0, 10 * HZ)) {
+		printk(KERN_ERR "mxc_v4l_dqueue timeout enc_counter %x\n",
+		       cam->enc_counter);
+		return -ETIME;
+	} else if (signal_pending(current)) {
+		printk(KERN_ERR "mxc_v4l_dqueue() interrupt received\n");
+		return -ERESTARTSYS;
+	}
+
+	cam->enc_counter--;
+
+	frame = list_entry(cam->done_q.next, struct mxc_v4l_frame, queue);
+	list_del(cam->done_q.next);
+	if (frame->buffer.flags & V4L2_BUF_FLAG_DONE) {
+		frame->buffer.flags &= ~V4L2_BUF_FLAG_DONE;
+	} else if (frame->buffer.flags & V4L2_BUF_FLAG_QUEUED) {
+		printk(KERN_ERR "VIDIOC_DQBUF: Buffer not filled.\n");
+		frame->buffer.flags &= ~V4L2_BUF_FLAG_QUEUED;
+		retval = -EINVAL;
+	} else if ((frame->buffer.flags & 0x7) == V4L2_BUF_FLAG_MAPPED) {
+		printk(KERN_ERR "VIDIOC_DQBUF: Buffer not queued.\n");
+		retval = -EINVAL;
+	}
+
+	buf->bytesused = cam->v2f.fmt.pix.sizeimage;
+	buf->index = frame->index;
+	buf->flags = frame->buffer.flags;
+
+	return retval;
+}
+
+/*!
+ * V4L interface - open function
+ *
+ * @param inode        structure inode *
+ * @param file         structure file *
+ *
+ * @return  status    0 success, ENODEV invalid device instance,
+ *                    ENODEV timeout, ERESTARTSYS interrupted by user
+ */
+static int mxc_v4l_open(struct inode *inode, struct file *file)
+{
+	sensor_interface *param;
+	csi_signal_cfg_t csi_param;
+	struct video_device *dev = video_devdata(file);
+	cam_data *cam = dev->priv;
+	int err = 0;
+
+	if (!cam) {
+		pr_info("Internal error, cam_data not found!\n");
+		return -ENODEV;
+	}
+
+	if (down_interruptible(&cam->busy_lock))
+		return -EINTR;
+
+	if (signal_pending(current))
+		goto oops;
+
+	if (cam->open_count++ == 0) {
+		wait_event_interruptible(cam->power_queue,
+					 cam->low_power == false);
+
+		err = prp_enc_select(cam);
+
+		cam->enc_counter = 0;
+		cam->skip_frame = 0;
+		INIT_LIST_HEAD(&cam->ready_q);
+		INIT_LIST_HEAD(&cam->working_q);
+		INIT_LIST_HEAD(&cam->done_q);
+
+		csi_enable_mclk(CSI_MCLK_I2C, true, true);
+		param = cam->cam_sensor->reset();
+		if (param == NULL) {
+			cam->open_count--;
+			csi_enable_mclk(CSI_MCLK_I2C, false, false);
+			err = -ENODEV;
+			goto oops;
+		}
+		csi_param.sens_clksrc = 0;
+		csi_param.clk_mode = param->clk_mode;
+		csi_param.pixclk_pol = param->pixclk_pol;
+		csi_param.data_width = param->data_width;
+		csi_param.data_pol = param->data_pol;
+		csi_param.ext_vsync = param->ext_vsync;
+		csi_param.Vsync_pol = param->Vsync_pol;
+		csi_param.Hsync_pol = param->Hsync_pol;
+		csi_init_interface(param->width, param->height,
+				   param->pixel_fmt, csi_param);
+		cam->cam_sensor->get_color(&cam->bright, &cam->saturation,
+					   &cam->red, &cam->green, &cam->blue);
+		if (cam->cam_sensor->get_ae_mode)
+			cam->cam_sensor->get_ae_mode(&cam->ae_mode);
+		csi_enable_mclk(CSI_MCLK_I2C, false, false);
+		prp_init(cam);
+
+	}
+
+	file->private_data = dev;
+      oops:
+	up(&cam->busy_lock);
+	return err;
+}
+
+/*!
+ * V4L interface - close function
+ *
+ * @param inode    struct inode *
+ * @param file     struct file *
+ *
+ * @return         0 success
+ */
+static int mxc_v4l_close(struct inode *inode, struct file *file)
+{
+	struct video_device *dev = video_devdata(file);
+	int err = 0;
+	cam_data *cam = dev->priv;
+
+	/* for the case somebody hit the ctrl C */
+	if (cam->overlay_pid == current->pid) {
+		err = stop_preview(cam);
+		cam->overlay_on = false;
+	}
+	if (cam->capture_pid == current->pid) {
+		err |= mxc_streamoff(cam);
+		cam->capture_on = false;
+		wake_up_interruptible(&cam->enc_queue);
+	}
+
+	if (--cam->open_count == 0) {
+		wait_event_interruptible(cam->power_queue,
+					 cam->low_power == false);
+		pr_debug("mxc_v4l_close: release resource\n");
+
+		err |= prp_enc_deselect(cam);
+
+		mxc_free_frame_buf(cam);
+		file->private_data = NULL;
+
+		/* capture off */
+		wake_up_interruptible(&cam->enc_queue);
+		mxc_free_frames(cam);
+		cam->enc_counter++;
+		prp_exit(cam);
+	}
+
+	return err;
+}
+
+#ifdef CONFIG_VIDEO_MXC_CSI_DMA
+#include <asm/arch/dma.h>
+
+#define CSI_DMA_STATUS_IDLE	0	/* DMA is not started */
+#define CSI_DMA_STATUS_WORKING	1	/* DMA is transfering the data */
+#define CSI_DMA_STATUS_DONE	2	/* One frame completes successfully */
+#define CSI_DMA_STATUS_ERROR	3	/* Error occurs during the DMA */
+
+/*
+ * Sometimes the start of the DMA is not synchronized with the CSI
+ * SOF (Start of Frame) interrupt which will lead to incorrect
+ * captured image. In this case the driver will re-try capturing
+ * another frame. The following macro defines the maximum re-try
+ * times.
+ */
+#define CSI_DMA_RETRY		8
+
+/*
+ * Size of the physical contiguous memory area used to hold image data
+ * transfered by DMA. It can be less than the size of the image data.
+ */
+#define CSI_MEM_SIZE		(1024 * 600)
+
+/* Number of bytes for one DMA transfer */
+#define CSI_DMA_LENGTH		(1024 * 200)
+
+static int g_dma_channel;
+static int g_dma_status = CSI_DMA_STATUS_DONE;
+static volatile int g_dma_completed;	/* number of completed DMA transfers */
+static volatile int g_dma_copied;	/* number of copied DMA transfers */
+static struct tasklet_struct g_dma_tasklet;
+static char *g_user_buf;	/* represents the buf passed by read() */
+static int g_user_count;	/* represents the count passed by read() */
+
+/*!
+ * @brief setup the DMA to transfer data
+ *	  There may be more than one DMA to transfer the whole image. Those
+ *	  DMAs work like chain. This function is used to setup the DMA in
+ *	  case there is enough space to hold the data.
+ * @param	data	pointer to the cam structure
+ */
+static void mxc_csi_dma_chaining(void *data)
+{
+	cam_data *cam = (cam_data *) data;
+	int count, chained = 0;
+	int max_dma = CSI_MEM_SIZE / CSI_DMA_LENGTH;
+	mxc_dma_requestbuf_t dma_request;
+
+	while (chained * CSI_DMA_LENGTH < g_user_count) {
+		/*
+		 * Calculate how many bytes the DMA should transfer. It may
+		 * be less than CSI_DMA_LENGTH if the DMA is the last one.
+		 */
+		if ((chained + 1) * CSI_DMA_LENGTH > g_user_count)
+			count = g_user_count - chained * CSI_DMA_LENGTH;
+		else
+			count = CSI_DMA_LENGTH;
+		pr_debug("%s() DMA chained count = %d\n", __FUNCTION__, count);
+
+		/* Config DMA */
+		memset(&dma_request, 0, sizeof(mxc_dma_requestbuf_t));
+		dma_request.dst_addr = cam->still_buf
+		    + (chained % max_dma) * CSI_DMA_LENGTH;
+		dma_request.src_addr = (dma_addr_t) CSI_CSIRXFIFO_PHYADDR;
+		dma_request.num_of_bytes = count;
+		mxc_dma_config(g_dma_channel, &dma_request, 1,
+			       MXC_DMA_MODE_READ);
+
+		chained++;
+	}
+}
+
+/*!
+ * @brief Copy image data from physical contiguous memory to user space buffer
+ *	  Once the data are copied, there will be more spare space in the
+ *	  physical contiguous memory to receive data from DMA.
+ * @param	data	pointer to the cam structure
+ */
+static void mxc_csi_dma_task(unsigned long data)
+{
+	cam_data *cam = (cam_data *) data;
+	int count;
+	int max_dma = CSI_MEM_SIZE / CSI_DMA_LENGTH;
+
+	while (g_dma_copied < g_dma_completed) {
+		/*
+		 * Calculate how many bytes the DMA has transfered. It may
+		 * be less than CSI_DMA_LENGTH if the DMA is the last one.
+		 */
+		if ((g_dma_copied + 1) * CSI_DMA_LENGTH > g_user_count)
+			count = g_user_count - g_dma_copied * CSI_DMA_LENGTH;
+		else
+			count = CSI_DMA_LENGTH;
+		if (copy_to_user(g_user_buf + g_dma_copied * CSI_DMA_LENGTH,
+				 cam->still_buf_vaddr + (g_dma_copied % max_dma)
+				 * CSI_DMA_LENGTH, count))
+			pr_debug("Warning: some bytes not copied\n");
+
+		g_dma_copied++;
+	}
+
+	/* If the whole image has been captured */
+	if (g_dma_copied * CSI_DMA_LENGTH >= g_user_count) {
+		cam->still_counter++;
+		wake_up_interruptible(&cam->still_queue);
+	}
+
+	pr_debug("%s() DMA completed = %d copied = %d\n",
+		 __FUNCTION__, g_dma_completed, g_dma_copied);
+}
+
+/*!
+ * @brief DMA interrupt callback function
+ * @param	data	pointer to the cam structure
+ * @param	error	DMA error flag
+ * @param	count	number of bytes transfered by the DMA
+ */
+static void mxc_csi_dma_callback(void *data, int error, unsigned int count)
+{
+	cam_data *cam = (cam_data *) data;
+	int max_dma = CSI_MEM_SIZE / CSI_DMA_LENGTH;
+	unsigned long lock_flags;
+
+	spin_lock_irqsave(&cam->int_lock, lock_flags);
+
+	g_dma_completed++;
+
+	if (error != MXC_DMA_DONE) {
+		g_dma_status = CSI_DMA_STATUS_ERROR;
+		pr_debug("%s() DMA error\n", __FUNCTION__);
+	}
+
+	/* If the whole image has been captured */
+	if ((g_dma_status != CSI_DMA_STATUS_ERROR)
+	    && (g_dma_completed * CSI_DMA_LENGTH >= g_user_count))
+		g_dma_status = CSI_DMA_STATUS_DONE;
+
+	if ((g_dma_status == CSI_DMA_STATUS_WORKING) &&
+	    (g_dma_completed >= g_dma_copied + max_dma)) {
+		g_dma_status = CSI_DMA_STATUS_ERROR;
+		pr_debug("%s() Previous buffer over written\n", __FUNCTION__);
+	}
+
+	/* Schedule the tasklet */
+	tasklet_schedule(&g_dma_tasklet);
+
+	spin_unlock_irqrestore(&cam->int_lock, lock_flags);
+
+	pr_debug("%s() count = %d bytes\n", __FUNCTION__, count);
+}
+
+/*!
+ * @brief CSI interrupt callback function
+ * @param	data	pointer to the cam structure
+ * @param	status	CSI interrupt status
+ */
+static void mxc_csi_irq_callback(void *data, unsigned long status)
+{
+	cam_data *cam = (cam_data *) data;
+	unsigned long lock_flags;
+
+	spin_lock_irqsave(&cam->int_lock, lock_flags);
+
+	/* Wait for SOF (Start of Frame) interrupt to sync the image */
+	if (status & BIT_SOF_INT) {
+		if (g_dma_status == CSI_DMA_STATUS_IDLE) {
+			/* Start DMA transfer to capture image */
+			mxc_dma_enable(g_dma_channel);
+			g_dma_status = CSI_DMA_STATUS_WORKING;
+			pr_debug("%s() DMA started.\n", __FUNCTION__);
+		} else if (g_dma_status == CSI_DMA_STATUS_WORKING) {
+			/*
+			 * Another SOF occurs during DMA transfer. In this
+			 * case the image is not synchronized so need to
+			 * report error and probably try again.
+			 */
+			g_dma_status = CSI_DMA_STATUS_ERROR;
+			pr_debug("%s() Image is not synchronized with DMA - "
+				 "SOF before DMA completes\n", __FUNCTION__);
+		}
+	}
+
+	spin_unlock_irqrestore(&cam->int_lock, lock_flags);
+
+	pr_debug("%s() g_dma_status = %d\n", __FUNCTION__, g_dma_status);
+}
+
+/*!
+ * V4L interface - read function
+ *
+ * @param file       struct file *
+ * @param read buf   char *
+ * @param count      size_t
+ * @param ppos       structure loff_t *
+ *
+ * @return           bytes read
+ */
+static ssize_t
+mxc_v4l_read(struct file *file, char *buf, size_t count, loff_t *ppos)
+{
+	int err = 0;
+	struct video_device *dev = video_devdata(file);
+	cam_data *cam = dev->priv;
+	int retry = CSI_DMA_RETRY;
+
+	g_user_buf = buf;
+
+	if (down_interruptible(&cam->busy_lock))
+		return -EINTR;
+
+	/* Video capture and still image capture are exclusive */
+	if (cam->capture_on == true) {
+		err = -EBUSY;
+		goto exit0;
+	}
+
+	/* The CSI-DMA can not do CSC */
+	if (cam->v2f.fmt.pix.pixelformat != V4L2_PIX_FMT_YUYV) {
+		pr_info("mxc_v4l_read support YUYV pixel format only\n");
+		err = -EINVAL;
+		goto exit0;
+	}
+
+	/* The CSI-DMA can not do resize or crop */
+	if ((cam->v2f.fmt.pix.width != cam->crop_bounds.width)
+	    || (cam->v2f.fmt.pix.height != cam->crop_bounds.height)) {
+		pr_info("mxc_v4l_read resize is not supported\n");
+		pr_info("supported image size width = %d height = %d\n",
+			cam->crop_bounds.width, cam->crop_bounds.height);
+		err = -EINVAL;
+		goto exit0;
+	}
+	if ((cam->crop_current.left != cam->crop_bounds.left)
+	    || (cam->crop_current.width != cam->crop_bounds.width)
+	    || (cam->crop_current.top != cam->crop_bounds.top)
+	    || (cam->crop_current.height != cam->crop_bounds.height)) {
+		pr_info("mxc_v4l_read cropping is not supported\n");
+		err = -EINVAL;
+		goto exit0;
+	}
+
+	cam->still_buf_vaddr = dma_alloc_coherent(0,
+						  PAGE_ALIGN(CSI_MEM_SIZE),
+						  &cam->still_buf,
+						  GFP_DMA | GFP_KERNEL);
+
+	if (!cam->still_buf_vaddr) {
+		pr_info("mxc_v4l_read failed at allocate still_buf\n");
+		err = -ENOBUFS;
+		goto exit0;
+	}
+
+	/* Initialize DMA */
+	g_dma_channel = mxc_dma_request(MXC_DMA_CSI_RX, "CSI RX DMA");
+	if (g_dma_channel < 0) {
+		pr_debug("mxc_v4l_read failed to request DMA channel\n");
+		err = -EIO;
+		goto exit1;
+	}
+
+	err = mxc_dma_callback_set(g_dma_channel,
+				   (mxc_dma_callback_t) mxc_csi_dma_callback,
+				   (void *)cam);
+	if (err != 0) {
+		pr_debug("mxc_v4l_read failed to set DMA callback\n");
+		err = -EIO;
+		goto exit2;
+	}
+
+	g_user_buf = buf;
+	if (cam->v2f.fmt.pix.sizeimage < count)
+		g_user_count = cam->v2f.fmt.pix.sizeimage;
+	else
+		g_user_count = count & ~0x3;
+
+	tasklet_init(&g_dma_tasklet, mxc_csi_dma_task, (unsigned long)cam);
+	g_dma_status = CSI_DMA_STATUS_DONE;
+	csi_set_callback(mxc_csi_irq_callback, cam);
+	csi_enable_prpif(0);
+
+	/* clear current SOF first */
+	csi_clear_status(BIT_SOF_INT);
+	csi_enable_mclk(CSI_MCLK_RAW, true, true);
+
+	do {
+		g_dma_completed = g_dma_copied = 0;
+		mxc_csi_dma_chaining(cam);
+		cam->still_counter = 0;
+		g_dma_status = CSI_DMA_STATUS_IDLE;
+
+		if (!wait_event_interruptible_timeout(cam->still_queue,
+						      cam->still_counter != 0,
+						      10 * HZ)) {
+			pr_info("mxc_v4l_read timeout counter %x\n",
+				cam->still_counter);
+			err = -ETIME;
+			goto exit3;
+		}
+
+		if (g_dma_status == CSI_DMA_STATUS_DONE)
+			break;
+
+		if (retry-- == 0)
+			break;
+
+		pr_debug("Now retry image capture\n");
+	} while (1);
+
+	if (g_dma_status != CSI_DMA_STATUS_DONE)
+		err = -EIO;
+
+      exit3:
+	csi_enable_prpif(1);
+	g_dma_status = CSI_DMA_STATUS_DONE;
+	csi_set_callback(0, 0);
+	csi_enable_mclk(CSI_MCLK_RAW, false, false);
+	tasklet_kill(&g_dma_tasklet);
+
+      exit2:
+	mxc_dma_free(g_dma_channel);
+
+      exit1:
+	dma_free_coherent(0, PAGE_ALIGN(CSI_MEM_SIZE),
+			  cam->still_buf_vaddr, cam->still_buf);
+	cam->still_buf = 0;
+
+      exit0:
+	up(&cam->busy_lock);
+	if (err < 0)
+		return err;
+	else
+		return g_user_count;
+}
+#else
+/*!
+ * V4L interface - read function
+ *
+ * @param file       struct file *
+ * @param read buf   char *
+ * @param count      size_t
+ * @param ppos       structure loff_t *
+ *
+ * @return           bytes read
+ */
+static ssize_t
+mxc_v4l_read(struct file *file, char *buf, size_t count, loff_t *ppos)
+{
+	int err = 0;
+	u8 *v_address;
+	struct video_device *dev = video_devdata(file);
+	cam_data *cam = dev->priv;
+
+	if (down_interruptible(&cam->busy_lock))
+		return -EINTR;
+
+	/* Video capture and still image capture are exclusive */
+	if (cam->capture_on == true) {
+		err = -EBUSY;
+		goto exit0;
+	}
+
+	v_address = dma_alloc_coherent(0,
+				       PAGE_ALIGN(cam->v2f.fmt.pix.sizeimage),
+				       &cam->still_buf, GFP_DMA | GFP_KERNEL);
+
+	if (!v_address) {
+		pr_info("mxc_v4l_read failed at allocate still_buf\n");
+		err = -ENOBUFS;
+		goto exit0;
+	}
+
+	if (prp_still_select(cam)) {
+		err = -EIO;
+		goto exit1;
+	}
+
+	cam->still_counter = 0;
+	if (cam->csi_start(cam)) {
+		err = -EIO;
+		goto exit2;
+	}
+
+	if (!wait_event_interruptible_timeout(cam->still_queue,
+					      cam->still_counter != 0,
+					      10 * HZ)) {
+		pr_info("mxc_v4l_read timeout counter %x\n",
+			cam->still_counter);
+		err = -ETIME;
+		goto exit2;
+	}
+	err = copy_to_user(buf, v_address, cam->v2f.fmt.pix.sizeimage);
+
+      exit2:
+	prp_still_deselect(cam);
+
+      exit1:
+	dma_free_coherent(0, cam->v2f.fmt.pix.sizeimage, v_address,
+			  cam->still_buf);
+	cam->still_buf = 0;
+
+      exit0:
+	up(&cam->busy_lock);
+	if (err < 0)
+		return err;
+	else
+		return (cam->v2f.fmt.pix.sizeimage - err);
+}
+#endif				/* CONFIG_VIDEO_MXC_CSI_DMA */
+
+/*!
+ * V4L interface - ioctl function
+ *
+ * @param inode      struct inode *
+ *
+ * @param file       struct file *
+ *
+ * @param ioctlnr    unsigned int
+ *
+ * @param arg        void *
+ *
+ * @return           0 success, ENODEV for invalid device instance,
+ *                   -1 for other errors.
+ */
+static int
+mxc_v4l_do_ioctl(struct inode *inode, struct file *file,
+		 unsigned int ioctlnr, void *arg)
+{
+	struct video_device *dev = video_devdata(file);
+	cam_data *cam = dev->priv;
+	int retval = 0;
+	unsigned long lock_flags;
+
+	if (!cam)
+		return -EBADF;
+
+	wait_event_interruptible(cam->power_queue, cam->low_power == false);
+	/* make this _really_ smp-safe */
+	if (down_interruptible(&cam->busy_lock))
+		return -EBUSY;
+
+	switch (ioctlnr) {
+		/*!
+		 * V4l2 VIDIOC_QUERYCAP ioctl
+		 */
+	case VIDIOC_QUERYCAP:{
+			struct v4l2_capability *cap = arg;
+			strcpy(cap->driver, "mxc_v4l2");
+			cap->version = KERNEL_VERSION(0, 1, 11);
+			cap->capabilities = V4L2_CAP_VIDEO_CAPTURE |
+			    V4L2_CAP_VIDEO_OVERLAY | V4L2_CAP_STREAMING
+			    | V4L2_CAP_READWRITE;
+			cap->card[0] = '\0';
+			cap->bus_info[0] = '\0';
+			retval = 0;
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_G_FMT ioctl
+		 */
+	case VIDIOC_G_FMT:{
+			struct v4l2_format *gf = arg;
+			retval = mxc_v4l2_g_fmt(cam, gf);
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_S_FMT ioctl
+		 */
+	case VIDIOC_S_FMT:{
+			struct v4l2_format *sf = arg;
+			retval = mxc_v4l2_s_fmt(cam, sf);
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_REQBUFS ioctl
+		 */
+	case VIDIOC_REQBUFS:{
+			struct v4l2_requestbuffers *req = arg;
+			if (req->count > FRAME_NUM) {
+				pr_info("VIDIOC_REQBUFS: not enough buffer\n");
+				req->count = FRAME_NUM;
+			}
+
+			if ((req->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) ||
+			    (req->memory != V4L2_MEMORY_MMAP)) {
+				pr_debug("VIDIOC_REQBUFS: wrong buffer type\n");
+				retval = -EINVAL;
+				break;
+			}
+
+			mxc_streamoff(cam);
+			mxc_free_frame_buf(cam);
+
+			retval = mxc_allocate_frame_buf(cam, req->count);
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_QUERYBUF ioctl
+		 */
+	case VIDIOC_QUERYBUF:{
+			struct v4l2_buffer *buf = arg;
+			int index = buf->index;
+
+			if (buf->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) {
+				pr_debug
+				    ("VIDIOC_QUERYBUFS: wrong buffer type\n");
+				retval = -EINVAL;
+				break;
+			}
+
+			memset(buf, 0, sizeof(buf));
+			buf->index = index;
+
+			down(&cam->param_lock);
+			retval = mxc_v4l2_buffer_status(cam, buf);
+			up(&cam->param_lock);
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_QBUF ioctl
+		 */
+	case VIDIOC_QBUF:{
+			struct v4l2_buffer *buf = arg;
+			int index = buf->index;
+
+			pr_debug("VIDIOC_QBUF: %d\n", buf->index);
+
+			spin_lock_irqsave(&cam->int_lock, lock_flags);
+			if ((cam->frame[index].buffer.flags & 0x7) ==
+			    V4L2_BUF_FLAG_MAPPED) {
+				cam->frame[index].buffer.flags |=
+				    V4L2_BUF_FLAG_QUEUED;
+				if (cam->skip_frame > 0) {
+					list_add_tail(&cam->frame[index].queue,
+						      &cam->working_q);
+					retval =
+					    cam->enc_update_eba(cam->
+								frame[index].
+								paddress,
+								&cam->
+								ping_pong_csi);
+					cam->skip_frame = 0;
+				} else {
+					list_add_tail(&cam->frame[index].queue,
+						      &cam->ready_q);
+				}
+			} else if (cam->frame[index].buffer.flags &
+				   V4L2_BUF_FLAG_QUEUED) {
+				pr_debug
+				    ("VIDIOC_QBUF: buffer already queued\n");
+			} else if (cam->frame[index].buffer.
+				   flags & V4L2_BUF_FLAG_DONE) {
+				pr_debug
+				    ("VIDIOC_QBUF: overwrite done buffer.\n");
+				cam->frame[index].buffer.flags &=
+				    ~V4L2_BUF_FLAG_DONE;
+				cam->frame[index].buffer.flags |=
+				    V4L2_BUF_FLAG_QUEUED;
+			}
+			buf->flags = cam->frame[index].buffer.flags;
+			spin_unlock_irqrestore(&cam->int_lock, lock_flags);
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_DQBUF ioctl
+		 */
+	case VIDIOC_DQBUF:{
+			struct v4l2_buffer *buf = arg;
+
+			retval = mxc_v4l_dqueue(cam, buf);
+
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_STREAMON ioctl
+		 */
+	case VIDIOC_STREAMON:{
+			cam->capture_on = true;
+			retval = mxc_streamon(cam);
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_STREAMOFF ioctl
+		 */
+	case VIDIOC_STREAMOFF:{
+			retval = mxc_streamoff(cam);
+			cam->capture_on = false;
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_G_CTRL ioctl
+		 */
+	case VIDIOC_G_CTRL:{
+			retval = mxc_get_v42l_control(cam, arg);
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_S_CTRL ioctl
+		 */
+	case VIDIOC_S_CTRL:{
+			retval = mxc_set_v42l_control(cam, arg);
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_CROPCAP ioctl
+		 */
+	case VIDIOC_CROPCAP:{
+			struct v4l2_cropcap *cap = arg;
+
+			if (cap->type != V4L2_BUF_TYPE_VIDEO_CAPTURE &&
+			    cap->type != V4L2_BUF_TYPE_VIDEO_OVERLAY) {
+				retval = -EINVAL;
+				break;
+			}
+			cap->bounds = cam->crop_bounds;
+			cap->defrect = cam->crop_defrect;
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_G_CROP ioctl
+		 */
+	case VIDIOC_G_CROP:{
+			struct v4l2_crop *crop = arg;
+
+			if (crop->type != V4L2_BUF_TYPE_VIDEO_CAPTURE &&
+			    crop->type != V4L2_BUF_TYPE_VIDEO_OVERLAY) {
+				retval = -EINVAL;
+				break;
+			}
+			crop->c = cam->crop_current;
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_S_CROP ioctl
+		 */
+	case VIDIOC_S_CROP:{
+			struct v4l2_crop *crop = arg;
+			struct v4l2_rect *b = &cam->crop_bounds;
+			int i;
+
+			if (crop->type != V4L2_BUF_TYPE_VIDEO_CAPTURE &&
+			    crop->type != V4L2_BUF_TYPE_VIDEO_OVERLAY) {
+				retval = -EINVAL;
+				break;
+			}
+
+			crop->c.top = (crop->c.top < b->top) ? b->top
+			    : crop->c.top;
+			if (crop->c.top > b->top + b->height)
+				crop->c.top = b->top + b->height - 1;
+			if (crop->c.height > b->top + b->height - crop->c.top)
+				crop->c.height =
+				    b->top + b->height - crop->c.top;
+
+			crop->c.left = (crop->c.left < b->left) ? b->left
+			    : crop->c.left;
+			if (crop->c.left > b->left + b->width)
+				crop->c.left = b->left + b->width - 1;
+			if (crop->c.width > b->left - crop->c.left + b->width)
+				crop->c.width =
+				    b->left - crop->c.left + b->width;
+
+			crop->c.width &= ~0x1;
+
+			/*
+			 * MX27 PrP limitation:
+			 * The right spare space (CSI_FRAME_X_SIZE
+			 *  - SOURCE_LINE_STRIDE - PICTURE_X_SIZE)) must be
+			 * multiple of 32.
+			 * So we tune the crop->c.left value to the closest
+			 * desired cropping value and meet the PrP requirement.
+			 */
+			i = ((b->left + b->width)
+			     - (crop->c.left + crop->c.width)) % 32;
+			if (i <= 16) {
+				if (crop->c.left + crop->c.width + i
+				    <= b->left + b->width)
+					crop->c.left += i;
+				else if (crop->c.left - (32 - i) >= b->left)
+					crop->c.left -= 32 - i;
+				else {
+					retval = -EINVAL;
+					break;
+				}
+			} else {
+				if (crop->c.left - (32 - i) >= b->left)
+					crop->c.left -= 32 - i;
+				else if (crop->c.left + crop->c.width + i
+					 <= b->left + b->width)
+					crop->c.left += i;
+				else {
+					retval = -EINVAL;
+					break;
+				}
+			}
+
+			cam->crop_current = crop->c;
+
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_OVERLAY ioctl
+		 */
+	case VIDIOC_OVERLAY:{
+			int *on = arg;
+			if (*on) {
+				cam->overlay_on = true;
+				retval = start_preview(cam);
+			}
+			if (!*on) {
+				retval = stop_preview(cam);
+				cam->overlay_on = false;
+			}
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_G_FBUF ioctl
+		 */
+	case VIDIOC_G_FBUF:{
+			struct v4l2_framebuffer *fb = arg;
+			struct fb_var_screeninfo *var;
+
+			if (cam->output >= num_registered_fb) {
+				retval = -EINVAL;
+				break;
+			}
+
+			var = &registered_fb[cam->output]->var;
+			cam->v4l2_fb.fmt.width = var->xres;
+			cam->v4l2_fb.fmt.height = var->yres;
+			cam->v4l2_fb.fmt.bytesperline =
+			    var->xres_virtual * var->bits_per_pixel;
+			cam->v4l2_fb.fmt.colorspace = V4L2_COLORSPACE_SRGB;
+			*fb = cam->v4l2_fb;
+			break;
+		}
+
+		/*!
+		 * V4l2 VIDIOC_S_FBUF ioctl
+		 */
+	case VIDIOC_S_FBUF:{
+			struct v4l2_framebuffer *fb = arg;
+			cam->v4l2_fb.flags = fb->flags;
+			cam->v4l2_fb.fmt.pixelformat = fb->fmt.pixelformat;
+			break;
+		}
+
+	case VIDIOC_G_PARM:{
+			struct v4l2_streamparm *parm = arg;
+			if (parm->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) {
+				pr_debug("VIDIOC_G_PARM invalid type\n");
+				retval = -EINVAL;
+				break;
+			}
+			parm->parm.capture = cam->streamparm.parm.capture;
+			break;
+		}
+	case VIDIOC_S_PARM:{
+			struct v4l2_streamparm *parm = arg;
+			retval = mxc_v4l2_s_param(cam, parm);
+			break;
+		}
+
+		/* linux v4l2 bug, kernel c0485619 user c0405619 */
+	case VIDIOC_ENUMSTD:{
+			struct v4l2_standard *e = arg;
+			*e = cam->standard;
+			pr_debug("VIDIOC_ENUMSTD call\n");
+			retval = 0;
+			break;
+		}
+
+	case VIDIOC_G_STD:{
+			v4l2_std_id *e = arg;
+			*e = cam->standard.id;
+			break;
+		}
+
+	case VIDIOC_S_STD:{
+			break;
+		}
+
+	case VIDIOC_ENUMOUTPUT:
+		{
+			struct v4l2_output *output = arg;
+
+			if (output->index >= num_registered_fb) {
+				retval = -EINVAL;
+				break;
+			}
+
+			strncpy(output->name,
+				registered_fb[output->index]->fix.id, 31);
+			output->type = V4L2_OUTPUT_TYPE_ANALOG;
+			output->audioset = 0;
+			output->modulator = 0;
+			output->std = V4L2_STD_UNKNOWN;
+
+			break;
+		}
+	case VIDIOC_G_OUTPUT:
+		{
+			int *p_output_num = arg;
+
+			*p_output_num = cam->output;
+			break;
+		}
+	case VIDIOC_S_OUTPUT:
+		{
+			int *p_output_num = arg;
+
+			if (*p_output_num >= num_registered_fb) {
+				retval = -EINVAL;
+				break;
+			}
+
+			cam->output = *p_output_num;
+			break;
+		}
+
+	case VIDIOC_ENUM_FMT:
+	case VIDIOC_TRY_FMT:
+	case VIDIOC_QUERYCTRL:
+	case VIDIOC_ENUMINPUT:
+	case VIDIOC_G_INPUT:
+	case VIDIOC_S_INPUT:
+	case VIDIOC_G_TUNER:
+	case VIDIOC_S_TUNER:
+	case VIDIOC_G_FREQUENCY:
+	case VIDIOC_S_FREQUENCY:
+	default:
+		retval = -EINVAL;
+		break;
+	}
+
+	up(&cam->busy_lock);
+	return retval;
+}
+
+/*
+ * V4L interface - ioctl function
+ *
+ * @return  None
+ */
+static int
+mxc_v4l_ioctl(struct inode *inode, struct file *file,
+	      unsigned int cmd, unsigned long arg)
+{
+	return video_usercopy(inode, file, cmd, arg, mxc_v4l_do_ioctl);
+}
+
+/*!
+ * V4L interface - mmap function
+ *
+ * @param file        structure file *
+ *
+ * @param vma         structure vm_area_struct *
+ *
+ * @return status     0 Success, EINTR busy lock error, ENOBUFS remap_page error
+ */
+static int mxc_mmap(struct file *file, struct vm_area_struct *vma)
+{
+	struct video_device *dev = video_devdata(file);
+	unsigned long size;
+	int res = 0;
+	cam_data *cam = dev->priv;
+
+	pr_debug("pgoff=0x%lx, start=0x%lx, end=0x%lx\n",
+		 vma->vm_pgoff, vma->vm_start, vma->vm_end);
+
+	/* make this _really_ smp-safe */
+	if (down_interruptible(&cam->busy_lock))
+		return -EINTR;
+
+	size = vma->vm_end - vma->vm_start;
+	vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
+
+	if (remap_pfn_range(vma, vma->vm_start,
+			    vma->vm_pgoff, size, vma->vm_page_prot)) {
+		pr_debug("mxc_mmap: remap_pfn_range failed\n");
+		res = -ENOBUFS;
+		goto mxc_mmap_exit;
+	}
+
+	vma->vm_flags &= ~VM_IO;	/* using shared anonymous pages */
+
+      mxc_mmap_exit:
+	up(&cam->busy_lock);
+	return res;
+}
+
+/*!
+ * V4L interface - poll function
+ *
+ * @param file       structure file *
+ *
+ * @param wait       structure poll_table *
+ *
+ * @return  status   POLLIN | POLLRDNORM
+ */
+static unsigned int mxc_poll(struct file *file, poll_table * wait)
+{
+	struct video_device *dev = video_devdata(file);
+	cam_data *cam = dev->priv;
+	wait_queue_head_t *queue = NULL;
+	int res = POLLIN | POLLRDNORM;
+
+	if (down_interruptible(&cam->busy_lock))
+		return -EINTR;
+
+	queue = &cam->enc_queue;
+	poll_wait(file, queue, wait);
+
+	up(&cam->busy_lock);
+	return res;
+}
+
+static struct
+file_operations mxc_v4l_fops = {
+	.owner = THIS_MODULE,
+	.open = mxc_v4l_open,
+	.release = mxc_v4l_close,
+	.read = mxc_v4l_read,
+	.ioctl = mxc_v4l_ioctl,
+	.mmap = mxc_mmap,
+	.poll = mxc_poll,
+};
+
+static struct video_device mxc_v4l_template = {
+	.owner = THIS_MODULE,
+	.name = "Mxc Camera",
+	.type = 0,
+	.type2 = VID_TYPE_CAPTURE,
+	.fops = &mxc_v4l_fops,
+	.release = video_device_release,
+};
+
+static void camera_platform_release(struct device *device)
+{
+}
+
+/*! Device Definition for Mt9v111 devices */
+static struct platform_device mxc_v4l2_devices = {
+	.name = "mxc_v4l2",
+	.dev = {
+		.release = camera_platform_release,
+		},
+	.id = 0,
+};
+
+extern struct camera_sensor camera_sensor_if;
+
+/*!
+* Camera V4l2 callback function.
+*
+* @return status
+*/
+static void camera_callback(u32 mask, void *dev)
+{
+	struct mxc_v4l_frame *done_frame;
+	struct mxc_v4l_frame *ready_frame;
+
+	cam_data *cam = (cam_data *) dev;
+	if (cam == NULL)
+		return;
+
+	if (list_empty(&cam->working_q)) {
+		printk(KERN_ERR "camera_callback: working queue empty\n");
+		return;
+	}
+
+	done_frame =
+	    list_entry(cam->working_q.next, struct mxc_v4l_frame, queue);
+	if (done_frame->buffer.flags & V4L2_BUF_FLAG_QUEUED) {
+		done_frame->buffer.flags |= V4L2_BUF_FLAG_DONE;
+		done_frame->buffer.flags &= ~V4L2_BUF_FLAG_QUEUED;
+
+		if (list_empty(&cam->ready_q)) {
+			cam->skip_frame++;
+		} else {
+			ready_frame =
+			    list_entry(cam->ready_q.next, struct mxc_v4l_frame,
+				       queue);
+			list_del(cam->ready_q.next);
+			list_add_tail(&ready_frame->queue, &cam->working_q);
+			cam->enc_update_eba(ready_frame->paddress,
+					    &cam->ping_pong_csi);
+		}
+
+		/* Added to the done queue */
+		list_del(cam->working_q.next);
+		list_add_tail(&done_frame->queue, &cam->done_q);
+
+		/* Wake up the queue */
+		cam->enc_counter++;
+		wake_up_interruptible(&cam->enc_queue);
+	} else {
+		printk(KERN_ERR "camera_callback :buffer not queued\n");
+	}
+}
+
+/*!
+ * initialize cam_data structure
+ *
+ * @param cam      structure cam_data *
+ *
+ * @return status  0 Success
+ */
+static void init_camera_struct(cam_data *cam)
+{
+	int i;
+
+	/* Default everything to 0 */
+	memset(cam, 0, sizeof(cam_data));
+
+	init_MUTEX(&cam->param_lock);
+	init_MUTEX(&cam->busy_lock);
+
+	cam->video_dev = video_device_alloc();
+	if (cam->video_dev == NULL)
+		return;
+
+	*(cam->video_dev) = mxc_v4l_template;
+
+	video_set_drvdata(cam->video_dev, cam);
+	dev_set_drvdata(&mxc_v4l2_devices.dev, (void *)cam);
+	cam->video_dev->minor = -1;
+
+	for (i = 0; i < FRAME_NUM; i++) {
+		cam->frame[i].width = 0;
+		cam->frame[i].height = 0;
+		cam->frame[i].paddress = 0;
+	}
+
+	init_waitqueue_head(&cam->enc_queue);
+	init_waitqueue_head(&cam->still_queue);
+
+	/* setup cropping */
+	cam->crop_bounds.left = 0;
+	cam->crop_bounds.width = 640;
+	cam->crop_bounds.top = 0;
+	cam->crop_bounds.height = 480;
+	cam->crop_current = cam->crop_defrect = cam->crop_bounds;
+	cam->streamparm.parm.capture.capturemode = 0;
+
+	cam->standard.index = 0;
+	cam->standard.id = V4L2_STD_UNKNOWN;
+	cam->standard.frameperiod.denominator = 30;
+	cam->standard.frameperiod.numerator = 1;
+	cam->standard.framelines = 480;
+	cam->streamparm.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	cam->streamparm.parm.capture.timeperframe = cam->standard.frameperiod;
+	cam->streamparm.parm.capture.capability = V4L2_CAP_TIMEPERFRAME;
+	cam->overlay_on = false;
+	cam->capture_on = false;
+	cam->skip_frame = 0;
+	cam->v4l2_fb.capability = V4L2_FBUF_CAP_EXTERNOVERLAY;
+	cam->v4l2_fb.flags = V4L2_FBUF_FLAG_PRIMARY;
+
+	cam->v2f.fmt.pix.sizeimage = 352 * 288 * 3 / 2;
+	cam->v2f.fmt.pix.bytesperline = 288 * 3 / 2;
+	cam->v2f.fmt.pix.width = 288;
+	cam->v2f.fmt.pix.height = 352;
+	cam->v2f.fmt.pix.pixelformat = V4L2_PIX_FMT_YUV420;
+	cam->win.w.width = 160;
+	cam->win.w.height = 160;
+	cam->win.w.left = 0;
+	cam->win.w.top = 0;
+
+	cam->cam_sensor = &camera_sensor_if;
+	cam->enc_callback = camera_callback;
+
+	init_waitqueue_head(&cam->power_queue);
+	cam->int_lock = __SPIN_LOCK_UNLOCKED(cam->int_lock);
+	spin_lock_init(&cam->int_lock);
+}
+
+extern void gpio_sensor_active(void);
+extern void gpio_sensor_inactive(void);
+
+/*!
+ * camera_power function
+ *    Turn Sensor power On/Off
+ *
+ * @param       cameraOn      true to turn camera on, otherwise shut down
+ *
+ * @return status
+ */
+static u8 camera_power(bool cameraOn)
+{
+	if (cameraOn == true) {
+		gpio_sensor_active();
+		csi_enable_mclk(csi_mclk_flag_backup, true, true);
+	} else {
+		csi_mclk_flag_backup = csi_read_mclk_flag();
+		csi_enable_mclk(csi_mclk_flag_backup, false, false);
+		gpio_sensor_inactive();
+	}
+	return 0;
+}
+
+/*!
+ * This function is called to put the sensor in a low power state. Refer to the
+ * document driver-model/driver.txt in the kernel source tree for more
+ * information.
+ *
+ * @param   pdev  the device structure used to give information on which I2C
+ *                to suspend
+ * @param   state the power state the device is entering
+ *
+ * @return  The function returns 0 on success and -1 on failure.
+ */
+static int mxc_v4l2_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	cam_data *cam = platform_get_drvdata(pdev);
+
+	if (cam == NULL) {
+		return -1;
+	}
+
+	cam->low_power = true;
+
+	if (cam->overlay_on == true)
+		stop_preview(cam);
+	if ((cam->capture_on == true) && cam->enc_disable) {
+		cam->enc_disable(cam);
+	}
+	camera_power(false);
+
+	return 0;
+}
+
+/*!
+ * This function is called to bring the sensor back from a low power state.Refer
+ * to the document driver-model/driver.txt in the kernel source tree for more
+ * information.
+ *
+ * @param   pdev  the device structure
+ *
+ * @return  The function returns 0 on success and -1 on failure
+ */
+static int mxc_v4l2_resume(struct platform_device *pdev)
+{
+	cam_data *cam = platform_get_drvdata(pdev);
+
+	if (cam == NULL) {
+		return -1;
+	}
+
+	cam->low_power = false;
+	wake_up_interruptible(&cam->power_queue);
+
+	if (cam->overlay_on == true)
+		start_preview(cam);
+	if (cam->capture_on == true)
+		mxc_streamon(cam);
+	camera_power(true);
+
+	return 0;
+}
+
+/*!
+ * This structure contains pointers to the power management callback functions.
+ */
+static struct platform_driver mxc_v4l2_driver = {
+	.driver = {
+		   .name = "mxc_v4l2",
+		   .owner = THIS_MODULE,
+		   .bus = &platform_bus_type,
+		   },
+	.probe = NULL,
+	.remove = NULL,
+	.suspend = mxc_v4l2_suspend,
+	.resume = mxc_v4l2_resume,
+	.shutdown = NULL,
+};
+
+/*!
+ * Entry point for the V4L2
+ *
+ * @return  Error code indicating success or failure
+ */
+static __init int camera_init(void)
+{
+	u8 err = 0;
+	cam_data *cam;
+
+	g_cam = kmalloc(sizeof(cam_data), GFP_KERNEL);
+	if (g_cam == NULL) {
+		pr_debug("failed to mxc_v4l_register_camera\n");
+		return -1;
+	}
+
+	cam = &g_cam;
+	init_camera_struct(cam);
+
+	/* Register the I2C device */
+	err = platform_device_register(&mxc_v4l2_devices);
+	if (err != 0) {
+		pr_debug("camera_init: platform_device_register failed.\n");
+		video_device_release(cam->video_dev);
+		kfree(cam);
+		g_cam = NULL;
+	}
+
+	/* Register the device driver structure. */
+	err = platform_driver_register(&mxc_v4l2_driver);
+	if (err != 0) {
+		platform_device_unregister(&mxc_v4l2_devices);
+		pr_debug("camera_init: driver_register failed.\n");
+		video_device_release(cam->video_dev);
+		kfree(cam);
+		g_cam = NULL;
+		return err;
+	}
+
+	/* register v4l device */
+	if (video_register_device(cam->video_dev, VFL_TYPE_GRABBER, video_nr)
+	    == -1) {
+		platform_driver_unregister(&mxc_v4l2_driver);
+		platform_device_unregister(&mxc_v4l2_devices);
+		video_device_release(cam->video_dev);
+		kfree(cam);
+		g_cam = NULL;
+		pr_debug("video_register_device failed\n");
+		return -1;
+	}
+
+	return err;
+}
+
+/*!
+ * Exit and cleanup for the V4L2
+ *
+ */
+static void __exit camera_exit(void)
+{
+	pr_debug("unregistering video\n");
+
+	video_unregister_device(g_cam->video_dev);
+
+	platform_driver_unregister(&mxc_v4l2_driver);
+	platform_device_unregister(&mxc_v4l2_devices);
+
+	if (g_cam->open_count) {
+		pr_debug("camera open -- setting ops to NULL\n");
+	} else {
+		pr_debug("freeing camera\n");
+		mxc_free_frame_buf(g_cam);
+		kfree(g_cam);
+		g_cam = NULL;
+	}
+}
+
+module_init(camera_init);
+module_exit(camera_exit);
+
+module_param(video_nr, int, 0444);
+
+MODULE_AUTHOR("Freescale Semiconductor, Inc.");
+MODULE_DESCRIPTION("V4L2 capture driver for Mxc based cameras");
+MODULE_LICENSE("GPL");
+MODULE_SUPPORTED_DEVICE("video");
diff --git a/drivers/media/video/mxc/capture/ipu_prp_enc.c b/drivers/media/video/mxc/capture/ipu_prp_enc.c
index 5d7c5e5..2f46da3 100644
--- a/drivers/media/video/mxc/capture/ipu_prp_enc.c
+++ b/drivers/media/video/mxc/capture/ipu_prp_enc.c
@@ -24,6 +24,12 @@
 #include "ipu_prp_sw.h"
 #include <linux/dma-mapping.h>
 
+#ifdef CAMERA_DBG
+	#define CAMERA_TRACE(x) (printk)x
+#else
+	#define CAMERA_TRACE(x)
+#endif
+
 static ipu_rotate_mode_t grotation = IPU_ROTATE_NONE;
 
 /*
@@ -63,24 +69,25 @@ static int prp_enc_setup(cam_data * cam)
 	int err = 0;
 	dma_addr_t dummy = 0xdeadbeaf;
 
+	CAMERA_TRACE("In prp_enc_setup\n");
 	if (!cam) {
 		printk(KERN_ERR "cam private is NULL\n");
 		return -ENXIO;
 	}
-
 	memset(&enc, 0, sizeof(ipu_channel_params_t));
 
 	ipu_csi_get_window_size(&enc.csi_prp_enc_mem.in_width,
-				&enc.csi_prp_enc_mem.in_height,
-				cam->cam_sensor->csi);
+				&enc.csi_prp_enc_mem.in_height, cam->csi);
+
 	enc.csi_prp_enc_mem.in_pixel_fmt = IPU_PIX_FMT_UYVY;
 	enc.csi_prp_enc_mem.out_width = cam->v2f.fmt.pix.width;
 	enc.csi_prp_enc_mem.out_height = cam->v2f.fmt.pix.height;
-	enc.csi_prp_enc_mem.csi = cam->cam_sensor->csi;
+	enc.csi_prp_enc_mem.csi = cam->csi;
 	if (cam->rotation >= IPU_ROTATE_90_RIGHT) {
 		enc.csi_prp_enc_mem.out_width = cam->v2f.fmt.pix.height;
 		enc.csi_prp_enc_mem.out_height = cam->v2f.fmt.pix.width;
 	}
+
 	if (cam->v2f.fmt.pix.pixelformat == V4L2_PIX_FMT_YUV420) {
 		enc.csi_prp_enc_mem.out_pixel_fmt = IPU_PIX_FMT_YUV420P;
 		pr_info("YUV420\n");
@@ -113,7 +120,7 @@ static int prp_enc_setup(cam_data * cam)
 		return err;
 	}
 
-	ipu_csi_enable_mclk_if(CSI_MCLK_ENC, cam->cam_sensor->csi, true, true);
+	ipu_csi_enable_mclk_if(CSI_MCLK_ENC, cam->csi, true, true);
 
 	grotation = cam->rotation;
 	if (cam->rotation >= IPU_ROTATE_90_RIGHT) {
@@ -244,6 +251,7 @@ static int prp_enc_setup(cam_data * cam)
 			return err;
 		}
 	}
+
 	return err;
 }
 
@@ -296,6 +304,7 @@ static int prp_enc_enabling_tasks(void *private)
 {
 	cam_data *cam = (cam_data *) private;
 	int err = 0;
+	CAMERA_TRACE("IPU:In prp_enc_enabling_tasks\n");
 
 	if (cam->rotation >= IPU_ROTATE_90_RIGHT) {
 		err = ipu_request_irq(IPU_IRQ_PRP_ENC_ROT_OUT_EOF,
@@ -349,8 +358,7 @@ static int prp_enc_disabling_tasks(void *private)
 		ipu_uninit_channel(MEM_ROT_ENC_MEM);
 	}
 
-	ipu_csi_enable_mclk_if(CSI_MCLK_ENC,
-		cam->cam_sensor->csi, false, false);
+	ipu_csi_enable_mclk_if(CSI_MCLK_ENC, cam->csi, false, false);
 
 	return err;
 }
diff --git a/drivers/media/video/mxc/capture/ipu_prp_vf_adc.c b/drivers/media/video/mxc/capture/ipu_prp_vf_adc.c
index 823d181..6df0f3d 100644
--- a/drivers/media/video/mxc/capture/ipu_prp_vf_adc.c
+++ b/drivers/media/video/mxc/capture/ipu_prp_vf_adc.c
@@ -85,8 +85,7 @@ static int prpvf_start(void *private)
 		if (err != 0)
 			return err;
 
-		ipu_csi_enable_mclk_if(CSI_MCLK_VF,
-			cam->cam_sensor->csi, true, true);
+		ipu_csi_enable_mclk_if(CSI_MCLK_VF, cam->csi, true, true);
 
 		if (cam->vf_bufs_vaddr[0]) {
 			dma_free_coherent(0, cam->vf_bufs_size[0],
@@ -282,8 +281,7 @@ static int prpvf_start(void *private)
 			       "initializing CSI_PRP_VF_ADC\n");
 			return err;
 		}
-		ipu_csi_enable_mclk_if(CSI_MCLK_VF,
-			cam->cam_sensor->csi, true, true);
+		ipu_csi_enable_mclk_if(CSI_MCLK_VF, cam->csi, true, true);
 		err = ipu_init_channel_buffer(CSI_PRP_VF_ADC, IPU_OUTPUT_BUFFER,
 					      format, cam->win.w.width,
 					      cam->win.w.height,
@@ -307,8 +305,7 @@ static int prpvf_start(void *private)
 			return err;
 		}
 
-		ipu_csi_enable_mclk_if(CSI_MCLK_VF,
-			cam->cam_sensor->csi, true, true);
+		ipu_csi_enable_mclk_if(CSI_MCLK_VF, cam->csi, true, true);
 
 		if (cam->vf_bufs[0]) {
 			dma_free_coherent(0, cam->vf_bufs_size[0],
@@ -478,15 +475,13 @@ static int prpvf_stop(void *private)
 		ipu_uninit_channel(MEM_ROT_VF_MEM);
 		ipu_uninit_channel(ADC_SYS2);
 
-		ipu_csi_enable_mclk_if(CSI_MCLK_VF,
-			cam->cam_sensor->csi, false, false);
+		ipu_csi_enable_mclk_if(CSI_MCLK_VF, cam->csi, false, false);
 	}
 #ifndef CONFIG_MXC_IPU_PRP_VF_SDC
 	else if (cam->rotation == IPU_ROTATE_NONE) {
 		ipu_disable_channel(CSI_PRP_VF_ADC, false);
 		ipu_uninit_channel(CSI_PRP_VF_ADC);
-		ipu_csi_enable_mclk_if(CSI_MCLK_VF,
-			cam->cam_sensor->csi, false, false);
+		ipu_csi_enable_mclk_if(CSI_MCLK_VF, cam->csi, false, false);
 	}
 #endif
 	else {
@@ -498,8 +493,7 @@ static int prpvf_stop(void *private)
 		ipu_uninit_channel(CSI_PRP_VF_MEM);
 		ipu_uninit_channel(ADC_SYS2);
 
-		ipu_csi_enable_mclk_if(CSI_MCLK_VF,
-			cam->cam_sensor->csi, false, false);
+		ipu_csi_enable_mclk_if(CSI_MCLK_VF, cam->csi, false, false);
 	}
 
 	if (cam->vf_bufs_vaddr[0]) {
diff --git a/drivers/media/video/mxc/capture/ipu_prp_vf_sdc.c b/drivers/media/video/mxc/capture/ipu_prp_vf_sdc.c
index 367c242..dda0d65 100644
--- a/drivers/media/video/mxc/capture/ipu_prp_vf_sdc.c
+++ b/drivers/media/video/mxc/capture/ipu_prp_vf_sdc.c
@@ -54,12 +54,11 @@ static int prpvf_start(void *private)
 
 	memset(&vf, 0, sizeof(ipu_channel_params_t));
 	ipu_csi_get_window_size(&vf.csi_prp_vf_mem.in_width,
-				&vf.csi_prp_vf_mem.in_height,
-				cam->cam_sensor->csi);
+				&vf.csi_prp_vf_mem.in_height, cam->csi);
 	vf.csi_prp_vf_mem.in_pixel_fmt = IPU_PIX_FMT_UYVY;
 	vf.csi_prp_vf_mem.out_width = cam->win.w.width;
 	vf.csi_prp_vf_mem.out_height = cam->win.w.height;
-	vf.csi_prp_vf_mem.csi = cam->cam_sensor->csi;
+	vf.csi_prp_vf_mem.csi = cam->csi;
 	if (cam->rotation >= IPU_ROTATE_90_RIGHT) {
 		vf.csi_prp_vf_mem.out_width = cam->win.w.height;
 		vf.csi_prp_vf_mem.out_height = cam->win.w.width;
@@ -71,7 +70,7 @@ static int prpvf_start(void *private)
 	if (err != 0)
 		goto out_4;
 
-	ipu_csi_enable_mclk_if(CSI_MCLK_VF, cam->cam_sensor->csi, true, true);
+	ipu_csi_enable_mclk_if(CSI_MCLK_VF, cam->csi, true, true);
 
 	if (cam->vf_bufs_vaddr[0]) {
 		dma_free_coherent(0, cam->vf_bufs_size[0],
@@ -214,7 +213,7 @@ static int prpvf_start(void *private)
 			goto out_2;
 
 		ipu_disp_set_window_pos(MEM_FG_SYNC, cam->win.w.left,
-				       cam->win.w.top);
+					cam->win.w.top);
 
 		err = ipu_init_channel_buffer(MEM_FG_SYNC, IPU_INPUT_BUFFER,
 					      format,
@@ -263,7 +262,7 @@ static int prpvf_start(void *private)
 			goto out_3;
 
 		ipu_disp_set_window_pos(MEM_FG_SYNC, cam->win.w.left,
-				       cam->win.w.top);
+					cam->win.w.top);
 		err = ipu_init_channel_buffer(MEM_FG_SYNC,
 					      IPU_INPUT_BUFFER, format,
 					      cam->win.w.width,
@@ -363,7 +362,7 @@ static int prpvf_stop(void *private)
 	ipu_uninit_channel(MEM_FG_SYNC);
 	ipu_uninit_channel(CSI_PRP_VF_MEM);
 
-	ipu_csi_enable_mclk_if(CSI_MCLK_VF, cam->cam_sensor->csi, false, false);
+	ipu_csi_enable_mclk_if(CSI_MCLK_VF, cam->csi, false, false);
 
 	if (cam->vf_bufs_vaddr[0]) {
 		dma_free_coherent(0, cam->vf_bufs_size[0],
diff --git a/drivers/media/video/mxc/capture/ipu_prp_vf_sdc_bg.c b/drivers/media/video/mxc/capture/ipu_prp_vf_sdc_bg.c
index 2e25619..59b1f40 100644
--- a/drivers/media/video/mxc/capture/ipu_prp_vf_sdc_bg.c
+++ b/drivers/media/video/mxc/capture/ipu_prp_vf_sdc_bg.c
@@ -123,12 +123,11 @@ static int prpvf_start(void *private)
 
 	memset(&vf, 0, sizeof(ipu_channel_params_t));
 	ipu_csi_get_window_size(&vf.csi_prp_vf_mem.in_width,
-				&vf.csi_prp_vf_mem.in_height,
-				cam->cam_sensor->csi);
+				&vf.csi_prp_vf_mem.in_height, cam->csi);
 	vf.csi_prp_vf_mem.in_pixel_fmt = IPU_PIX_FMT_UYVY;
 	vf.csi_prp_vf_mem.out_width = cam->win.w.width;
 	vf.csi_prp_vf_mem.out_height = cam->win.w.height;
-	vf.csi_prp_vf_mem.csi = cam->cam_sensor->csi;
+	vf.csi_prp_vf_mem.csi = cam->csi;
 	if (cam->rotation >= IPU_ROTATE_90_RIGHT) {
 		vf.csi_prp_vf_mem.out_width = cam->win.w.height;
 		vf.csi_prp_vf_mem.out_height = cam->win.w.width;
@@ -140,7 +139,7 @@ static int prpvf_start(void *private)
 	if (err != 0)
 		goto out_4;
 
-	ipu_csi_enable_mclk_if(CSI_MCLK_VF, cam->cam_sensor->csi, true, true);
+	ipu_csi_enable_mclk_if(CSI_MCLK_VF, cam->csi, true, true);
 
 	if (cam->vf_bufs_vaddr[0]) {
 		dma_free_coherent(0, cam->vf_bufs_size[0],
@@ -236,8 +235,7 @@ static int prpvf_start(void *private)
 	err = ipu_request_irq(IPU_IRQ_BG_SF_END, prpvf_sdc_vsync_callback,
 			      0, "Mxc Camera", NULL);
 	if (err != 0) {
-		printk(KERN_ERR
-		       "Error registering IPU_IRQ_BG_SF_END irq.\n");
+		printk(KERN_ERR "Error registering IPU_IRQ_BG_SF_END irq.\n");
 		goto out_1;
 	}
 
@@ -308,7 +306,7 @@ static int prpvf_stop(void *private)
 	ipu_disable_channel(MEM_ROT_VF_MEM, true);
 	ipu_uninit_channel(CSI_PRP_VF_MEM);
 	ipu_uninit_channel(MEM_ROT_VF_MEM);
-	ipu_csi_enable_mclk_if(CSI_MCLK_VF, cam->cam_sensor->csi, false, false);
+	ipu_csi_enable_mclk_if(CSI_MCLK_VF, cam->csi, false, false);
 
 	if (cam->vf_bufs_vaddr[0]) {
 		dma_free_coherent(0, cam->vf_bufs_size[0],
diff --git a/drivers/media/video/mxc/capture/ipu_still.c b/drivers/media/video/mxc/capture/ipu_still.c
index d82a5e6..e89772e 100644
--- a/drivers/media/video/mxc/capture/ipu_still.c
+++ b/drivers/media/video/mxc/capture/ipu_still.c
@@ -112,7 +112,7 @@ static int prp_still_start(void *private)
 	err = ipu_init_channel(CSI_MEM, &params);
 	if (err != 0)
 		return err;
-	ipu_csi_enable_mclk_if(CSI_MCLK_RAW, cam->cam_sensor->csi, true, true);
+	ipu_csi_enable_mclk_if(CSI_MCLK_RAW, cam->csi, true, true);
 
 	err = ipu_init_channel_buffer(CSI_MEM, IPU_OUTPUT_BUFFER,
 				      pixel_fmt, cam->v2f.fmt.pix.width,
@@ -165,8 +165,6 @@ static int prp_still_stop(void *private)
 	cam_data *cam = (cam_data *) private;
 	int err = 0;
 
-	callback_eof_flag = 0;
-
 #ifdef CONFIG_MXC_IPU_V1
 	ipu_free_irq(IPU_IRQ_SENSOR_EOF, NULL);
 	ipu_free_irq(IPU_IRQ_SENSOR_OUT_EOF, cam);
@@ -176,8 +174,7 @@ static int prp_still_stop(void *private)
 
 	ipu_disable_channel(CSI_MEM, true);
 	ipu_uninit_channel(CSI_MEM);
-	ipu_csi_enable_mclk_if(CSI_MCLK_RAW,
-		cam->cam_sensor->csi, false, false);
+	ipu_csi_enable_mclk_if(CSI_MCLK_RAW, cam->csi, false, false);
 
 	return err;
 }
diff --git a/drivers/media/video/mxc/capture/mt9v111.c b/drivers/media/video/mxc/capture/mt9v111.c
index 7e36b47..c95a206 100644
--- a/drivers/media/video/mxc/capture/mt9v111.c
+++ b/drivers/media/video/mxc/capture/mt9v111.c
@@ -18,7 +18,6 @@
  *
  * @ingroup Camera
  */
-
 #include <linux/module.h>
 #include <linux/init.h>
 #include <linux/slab.h>
@@ -28,6 +27,7 @@
 #include <linux/device.h>
 #include <linux/i2c.h>
 #include <linux/clk.h>
+#include <media/v4l2-int-device.h>
 #include "mxc_v4l2_capture.h"
 #include "mt9v111.h"
 
@@ -35,41 +35,56 @@
 static u16 testpattern = 0;
 #endif
 
-static sensor_interface *interface_param = NULL;
 static mt9v111_conf mt9v111_device;
-static int reset_frame_rate = 30;
-
-#define MT9V111_FRAME_RATE_NUM    20
-
-static mt9v111_image_format format[2] = {
-	{
-	 .index = 0,
-	 .width = 640,
-	 .height = 480,
-	 },
-	{
-	 .index = 1,
-	 .width = 352,
-	 .height = 288,
-	 },
+
+/*!
+ * Holds the current frame rate.
+ */
+static int reset_frame_rate = MT9V111_FRAME_RATE;
+
+struct sensor {
+	const struct mt9v111_platform_data *platform_data;
+	struct v4l2_int_device *v4l2_int_device;
+	struct i2c_client *i2c_client;
+	struct v4l2_pix_format pix;
+	struct v4l2_captureparm streamcap;
+	bool on;
+
+	/* control settings */
+	int brightness;
+	int hue;
+	int contrast;
+	int saturation;
+	int red;
+	int green;
+	int blue;
+	int ae_mode;
+
+} mt9v111_data;
+
+extern void gpio_sensor_active(void);
+extern void gpio_sensor_inactive(void);
+
+static int mt9v111_probe(struct i2c_client *client,
+			 const struct i2c_device_id *id);
+static int mt9v111_remove(struct i2c_client *client);
+
+static const struct i2c_device_id mt9v111_id[] = {
+	{"mt9v111", 0},
+	{},
 };
 
-static int mt9v111_attach(struct i2c_adapter *adapter);
-static int mt9v111_detach(struct i2c_client *client);
+MODULE_DEVICE_TABLE(i2c, mt9v111_id);
 
 static struct i2c_driver mt9v111_i2c_driver = {
 	.driver = {
 		   .owner = THIS_MODULE,
-		   .name = "MT9V111 Client",
+		   .name = "mt9v111",
 		   },
-	.attach_adapter = mt9v111_attach,
-	.detach_client = mt9v111_detach,
-};
-
-static struct i2c_client mt9v111_i2c_client = {
-	.name = "mt9v111 I2C dev",
-	.addr = MT9V111_I2C_ADDRESS,
-	.driver = &mt9v111_i2c_driver,
+	.probe = mt9v111_probe,
+	.remove = mt9v111_remove,
+	.id_table = mt9v111_id,
+/* To add power management add .suspend and .resume functions */
 };
 
 /*
@@ -79,18 +94,23 @@ static struct i2c_client mt9v111_i2c_client = {
 #ifdef MT9V111_DEBUG
 static inline int mt9v111_read_reg(u8 reg)
 {
-	int val = i2c_smbus_read_word_data(&mt9v111_i2c_client, reg);
+	int val = i2c_smbus_read_word_data(mt9v111_data.i2c_client, reg);
 	if (val != -1)
 		val = cpu_to_be16(val);
 	return val;
 }
 #endif
 
+/*!
+ * Writes to the register via I2C.
+ */
 static inline int mt9v111_write_reg(u8 reg, u16 val)
 {
-	pr_debug("write reg %x val %x.\n", reg, val);
-	return i2c_smbus_write_word_data(&mt9v111_i2c_client, reg,
-					 cpu_to_be16(val));
+	pr_debug("In mt9v111_write_reg (0x%x, 0x%x)\n", reg, val);
+	pr_debug("   write reg %x val %x.\n", reg, val);
+
+	return i2c_smbus_write_word_data(mt9v111_data.i2c_client,
+					 reg, cpu_to_be16(val));
 }
 
 /*!
@@ -108,6 +128,8 @@ static u8 mt9v111_sensor_lib(mt9v111_coreReg * coreReg, mt9v111_IFPReg * ifpReg)
 	u16 data;
 	u8 error = 0;
 
+	pr_debug("In mt9v111_sensor_lib\n");
+
 	/*
 	 * setup to IFP registers
 	 */
@@ -115,17 +137,17 @@ static u8 mt9v111_sensor_lib(mt9v111_coreReg * coreReg, mt9v111_IFPReg * ifpReg)
 	data = ifpReg->addrSpaceSel;
 	mt9v111_write_reg(reg, data);
 
-	// Operation Mode Control
+	/* Operation Mode Control */
 	reg = MT9V111I_MODE_CONTROL;
 	data = ifpReg->modeControl;
 	mt9v111_write_reg(reg, data);
 
-	// Output format
+	/* Output format */
 	reg = MT9V111I_FORMAT_CONTROL;
-	data = ifpReg->formatControl;	// Set bit 12
+	data = ifpReg->formatControl;	/* Set bit 12 */
 	mt9v111_write_reg(reg, data);
 
-	// AE limit 4
+	/* AE limit 4 */
 	reg = MT9V111I_SHUTTER_WIDTH_LIMIT_AE;
 	data = ifpReg->gainLimitAE;
 	mt9v111_write_reg(reg, data);
@@ -187,32 +209,32 @@ static u8 mt9v111_sensor_lib(mt9v111_coreReg * coreReg, mt9v111_IFPReg * ifpReg)
 	data = coreReg->addressSelect;
 	mt9v111_write_reg(reg, data);
 
-	// enable changes and put the Sync bit on
+	/* enable changes and put the Sync bit on */
 	reg = MT9V111S_OUTPUT_CTRL;
 	data = MT9V111S_OUTCTRL_SYNC | MT9V111S_OUTCTRL_CHIP_ENABLE | 0x3000;
 	mt9v111_write_reg(reg, data);
 
-	// min PIXCLK - Default
+	/* min PIXCLK - Default */
 	reg = MT9V111S_PIXEL_CLOCK_SPEED;
 	data = coreReg->pixelClockSpeed;
 	mt9v111_write_reg(reg, data);
 
-	//Setup image flipping / Dark rows / row/column skip
+	/* Setup image flipping / Dark rows / row/column skip */
 	reg = MT9V111S_READ_MODE;
 	data = coreReg->readMode;
 	mt9v111_write_reg(reg, data);
 
-	//zoom 0
+	/* zoom 0 */
 	reg = MT9V111S_DIGITAL_ZOOM;
 	data = coreReg->digitalZoom;
 	mt9v111_write_reg(reg, data);
 
-	// min H-blank
+	/* min H-blank */
 	reg = MT9V111S_HOR_BLANKING;
 	data = coreReg->horizontalBlanking;
 	mt9v111_write_reg(reg, data);
 
-	// min V-blank
+	/* min V-blank */
 	reg = MT9V111S_VER_BLANKING;
 	data = coreReg->verticalBlanking;
 	mt9v111_write_reg(reg, data);
@@ -225,7 +247,7 @@ static u8 mt9v111_sensor_lib(mt9v111_coreReg * coreReg, mt9v111_IFPReg * ifpReg)
 	data = ifpReg->upperShutterDelayLi;
 	mt9v111_write_reg(reg, data);
 
-	// changes become effective
+	/* changes become effective */
 	reg = MT9V111S_OUTPUT_CTRL;
 	data = MT9V111S_OUTCTRL_CHIP_ENABLE | 0x3000;
 	mt9v111_write_reg(reg, data);
@@ -234,31 +256,6 @@ static u8 mt9v111_sensor_lib(mt9v111_coreReg * coreReg, mt9v111_IFPReg * ifpReg)
 }
 
 /*!
- * mt9v111 sensor interface Initialization
- * @param param            sensor_interface *
- * @param width            u32
- * @param height           u32
- * @return  None
- */
-static void mt9v111_interface(sensor_interface * param, u32 width, u32 height)
-{
-	param->Vsync_pol = 0x0;
-	param->clk_mode = 0x0;	//gated
-	param->pixclk_pol = 0x0;
-	param->data_width = 0x1;
-	param->data_pol = 0x0;
-	param->ext_vsync = 0x0;
-	param->Vsync_pol = 0x0;
-	param->Hsync_pol = 0x0;
-	param->width = width - 1;
-	param->height = height - 1;
-	param->active_width = width;
-	param->active_height = height;
-	param->pixel_fmt = IPU_PIX_FMT_UYVY;
-	param->mclk = 27000000;
-}
-
-/*!
  * MT9V111 frame rate calculate
  *
  * @param frame_rate       int *
@@ -270,35 +267,29 @@ static void mt9v111_rate_cal(int *frame_rate, int mclk)
 	int num_clock_per_row;
 	int max_rate = 0;
 
-	mt9v111_device.coreReg->horizontalBlanking = MT9V111_HORZBLANK_MIN;
+	pr_debug("In mt9v111_rate_cal\n");
 
-	num_clock_per_row = (format[0].width + 114 + MT9V111_HORZBLANK_MIN) * 2;
+	num_clock_per_row = (MT9V111_MAX_WIDTH + 114 + MT9V111_HORZBLANK_MIN)
+			* 2;
 	max_rate = mclk / (num_clock_per_row *
-			   (format[0].height + MT9V111_VERTBLANK_DEFAULT));
+			   (MT9V111_MAX_HEIGHT + MT9V111_VERTBLANK_DEFAULT));
 
 	if ((*frame_rate > max_rate) || (*frame_rate == 0)) {
 		*frame_rate = max_rate;
 	}
 
 	mt9v111_device.coreReg->verticalBlanking
-	    = mclk / (*frame_rate * num_clock_per_row) - format[0].height;
+	    = mclk / (*frame_rate * num_clock_per_row) - MT9V111_MAX_HEIGHT;
 
 	reset_frame_rate = *frame_rate;
 }
 
 /*!
  * MT9V111 sensor configuration
- *
- * @param frame_rate       int *
- * @param high_quality     int
- * @return  sensor_interface *
  */
-sensor_interface *mt9v111_config(int *frame_rate, int high_quality)
+void mt9v111_config(void)
 {
-	u32 out_width, out_height;
-
-	if (interface_param == NULL)
-		return NULL;
+	pr_debug("In mt9v111_config\n");
 
 	mt9v111_device.coreReg->addressSelect = MT9V111I_SEL_SCA;
 	mt9v111_device.ifpReg->addrSpaceSel = MT9V111I_SEL_IFP;
@@ -318,54 +309,42 @@ sensor_interface *mt9v111_config(int *frame_rate, int high_quality)
 	mt9v111_device.ifpReg->gainLimitAE = 0x300;
 	mt9v111_device.ifpReg->AESpeed = 0x80;
 
-	// here is the default value
+	/* here is the default value */
 	mt9v111_device.ifpReg->formatControl = 0xc800;
 	mt9v111_device.ifpReg->modeControl = 0x708e;
 	mt9v111_device.ifpReg->awbSpeed = 0x4514;
 	mt9v111_device.coreReg->shutterWidth = 0xf8;
 
-	out_width = 640;
-	out_height = 480;
-
-	/*output size */
+	/* output size */
 	mt9v111_device.ifpReg->HPan = 0;
-	mt9v111_device.ifpReg->HZoom = 640;
-	mt9v111_device.ifpReg->HSize = out_width;
+	mt9v111_device.ifpReg->HZoom = MT9V111_MAX_WIDTH;
+	mt9v111_device.ifpReg->HSize = MT9V111_MAX_WIDTH;
 	mt9v111_device.ifpReg->VPan = 0;
-	mt9v111_device.ifpReg->VZoom = 480;
-	mt9v111_device.ifpReg->VSize = out_height;
-
-	mt9v111_interface(interface_param, out_width, out_height);
-	set_mclk_rate(&interface_param->mclk);
-	mt9v111_rate_cal(frame_rate, interface_param->mclk);
-	mt9v111_sensor_lib(mt9v111_device.coreReg, mt9v111_device.ifpReg);
-
-	return interface_param;
+	mt9v111_device.ifpReg->VZoom = MT9V111_MAX_HEIGHT;
+	mt9v111_device.ifpReg->VSize = MT9V111_MAX_HEIGHT;
 }
 
 /*!
- * mt9v111 sensor set color configuration
+ * mt9v111 sensor set saturtionn
  *
- * @param bright       int
  * @param saturation   int
- * @param red          int
- * @param green        int
- * @param blue         int
- * @return  None
+
+ * @return  Error code of 0.
  */
-static void
-mt9v111_set_color(int bright, int saturation, int red, int green, int blue)
+static int mt9v111_set_saturation(int saturation)
 {
 	u8 reg;
 	u16 data;
+	pr_debug("In mt9v111_set_saturation(%d)\n",
+		saturation);
 
 	switch (saturation) {
-	case 100:
-		mt9v111_device.ifpReg->awbSpeed = 0x4514;
-		break;
 	case 150:
 		mt9v111_device.ifpReg->awbSpeed = 0x6D14;
 		break;
+	case 100:
+		mt9v111_device.ifpReg->awbSpeed = 0x4514;
+		break;
 	case 75:
 		mt9v111_device.ifpReg->awbSpeed = 0x4D14;
 		break;
@@ -387,67 +366,49 @@ mt9v111_set_color(int bright, int saturation, int red, int green, int blue)
 	data = mt9v111_device.ifpReg->addrSpaceSel;
 	mt9v111_write_reg(reg, data);
 
-	// Operation Mode Control
+	/* Operation Mode Control */
 	reg = MT9V111I_AWB_SPEED;
 	data = mt9v111_device.ifpReg->awbSpeed;
 	mt9v111_write_reg(reg, data);
-}
 
-/*!
- * mt9v111 sensor get color configuration
- *
- * @param bright       int *
- * @param saturation   int *
- * @param red          int *
- * @param green        int *
- * @param blue         int *
- * @return  None
- */
-static void
-mt9v111_get_color(int *bright, int *saturation, int *red, int *green, int *blue)
-{
-	*saturation = (mt9v111_device.ifpReg->awbSpeed & 0x3800) >> 11;
-	switch (*saturation) {
-	case 0:
-		*saturation = 100;
-		break;
-	case 1:
-		*saturation = 75;
-		break;
-	case 2:
-		*saturation = 50;
-		break;
-	case 3:
-		*saturation = 37;
-		break;
-	case 4:
-		*saturation = 25;
-		break;
-	case 5:
-		*saturation = 150;
-		break;
-	case 6:
-		*saturation = 0;
-		break;
-	default:
-		*saturation = 0;
-		break;
-	}
+	return 0;
 }
 
 /*!
- * mt9v111 sensor set AE measurement window mode configuration
+ * mt9v111 sensor set Auto Exposure measurement window mode configuration
  *
  * @param ae_mode      int
- * @return  None
+ * @return  Error code of 0 (no Error)
  */
-static void mt9v111_set_ae_mode(int ae_mode)
+static int mt9v111_set_ae_mode(int ae_mode)
 {
 	u8 reg;
 	u16 data;
 
-	mt9v111_device.ifpReg->modeControl &= 0xfff3;
-	mt9v111_device.ifpReg->modeControl |= (ae_mode & 0x03) << 2;
+	pr_debug("In mt9v111_set_ae_mode(%d)\n",
+		ae_mode);
+
+	/* Currently this driver only supports auto and manual exposure
+	 * modes. */
+	if ((ae_mode > 1) || (ae_mode << 0))
+		return -EPERM;
+
+	/*
+	 * The auto exposure is set in bit 14.
+	 * Other values are set for:
+	 *  -on the fly defect correction is on (bit 13).
+	 *  -aperature correction knee enabled (bit 12).
+	 *  -ITU_R BT656 synchronization codes are embedded in the image (bit 7)
+	 *  -AE measurement window is weighted sum of large and center windows
+	 *     (bits 2-3).
+	 *  -auto white balance is on (bit 1).
+	 *  -normal color processing (bit 4 = 0).
+	 */
+	/* V4L2_EXPOSURE_AUTO = 0; needs register setting of 0x708E */
+	/* V4L2_EXPOSURE_MANUAL = 1 needs register setting of 0x308E */
+	mt9v111_device.ifpReg->modeControl &= 0x3fff;
+	mt9v111_device.ifpReg->modeControl |= (ae_mode & 0x03) << 14;
+	mt9v111_data.ae_mode = ae_mode;
 
 	reg = MT9V111I_ADDR_SPACE_SEL;
 	data = mt9v111_device.ifpReg->addrSpaceSel;
@@ -456,6 +417,8 @@ static void mt9v111_set_ae_mode(int ae_mode)
 	reg = MT9V111I_MODE_CONTROL;
 	data = mt9v111_device.ifpReg->modeControl;
 	mt9v111_write_reg(reg, data);
+
+	return 0;
 }
 
 /*!
@@ -466,30 +429,13 @@ static void mt9v111_set_ae_mode(int ae_mode)
  */
 static void mt9v111_get_ae_mode(int *ae_mode)
 {
+	pr_debug("In mt9v111_get_ae_mode(%d)\n", *ae_mode);
+
 	if (ae_mode != NULL) {
 		*ae_mode = (mt9v111_device.ifpReg->modeControl & 0xc) >> 2;
 	}
 }
 
-/*!
- * mt9v111 Reset function
- *
- * @return  None
- */
-static sensor_interface *mt9v111_reset(void)
-{
-	return mt9v111_config(&reset_frame_rate, 0);
-}
-
-struct camera_sensor camera_sensor_if = {
-	.set_color = mt9v111_set_color,
-	.get_color = mt9v111_get_color,
-	.set_ae_mode = mt9v111_set_ae_mode,
-	.get_ae_mode = mt9v111_get_ae_mode,
-	.config = mt9v111_config,
-	.reset = mt9v111_reset,
-};
-
 #ifdef MT9V111_DEBUG
 /*!
  * Set sensor to test mode, which will generate test pattern.
@@ -500,7 +446,7 @@ static void mt9v111_test_pattern(bool flag)
 {
 	u16 data;
 
-	// switch to sensor registers
+	/* switch to sensor registers */
 	mt9v111_write_reg(MT9V111I_ADDR_SPACE_SEL, MT9V111I_SEL_SCA);
 
 	if (flag == true) {
@@ -511,7 +457,7 @@ static void mt9v111_test_pattern(bool flag)
 
 		mt9v111_write_reg(MT9V111S_TEST_DATA, 0);
 
-		// changes take effect
+		/* changes take effect */
 		data = MT9V111S_OUTCTRL_CHIP_ENABLE | testpattern | 0x3000;
 		mt9v111_write_reg(MT9V111S_OUTPUT_CTRL, data);
 	} else {
@@ -520,100 +466,547 @@ static void mt9v111_test_pattern(bool flag)
 		data = mt9v111_read_reg(MT9V111S_ROW_NOISE_CTRL) | 0x40;
 		mt9v111_write_reg(MT9V111S_ROW_NOISE_CTRL, data);
 
-		// changes take effect
+		/* changes take effect */
 		data = MT9V111S_OUTCTRL_CHIP_ENABLE | testpattern | 0x3000;
 		mt9v111_write_reg(MT9V111S_OUTPUT_CTRL, data);
 	}
 }
 #endif
 
+
+/* --------------- IOCTL functions from v4l2_int_ioctl_desc --------------- */
+
 /*!
- * mt9v111 I2C detect_client function
+ * ioctl_g_ifparm - V4L2 sensor interface handler for vidioc_int_g_ifparm_num
+ * s: pointer to standard V4L2 device structure
+ * p: pointer to standard V4L2 vidioc_int_g_ifparm_num ioctl structure
  *
- * @param adapter            struct i2c_adapter *
- * @param address            int
- * @param kind               int
+ * Gets slave interface parameters.
+ * Calculates the required xclk value to support the requested
+ * clock parameters in p.  This value is returned in the p
+ * parameter.
  *
- * @return  Error code indicating success or failure
+ * vidioc_int_g_ifparm returns platform-specific information about the
+ * interface settings used by the sensor.
+ *
+ * Given the image capture format in pix, the nominal frame period in
+ * timeperframe, calculate the required xclk frequency.
+ *
+ * Called on open.
  */
-static int mt9v111_detect_client(struct i2c_adapter *adapter, int address,
-				 int kind)
+static int ioctl_g_ifparm(struct v4l2_int_device *s, struct v4l2_ifparm *p)
 {
-	mt9v111_i2c_client.adapter = adapter;
-	if (i2c_attach_client(&mt9v111_i2c_client)) {
-		mt9v111_i2c_client.adapter = NULL;
-		printk(KERN_ERR "mt9v111_attach: i2c_attach_client failed\n");
+	pr_debug("In mt9v111:ioctl_g_ifparm\n");
+
+	if (s == NULL) {
+		pr_err("   ERROR!! no slave device set!\n");
 		return -1;
 	}
 
-	interface_param = (sensor_interface *)
-	    kmalloc(sizeof(sensor_interface), GFP_KERNEL);
-	if (!interface_param) {
-		printk(KERN_ERR "mt9v111_attach: kmalloc failed \n");
-		return -1;
+	memset(p, 0, sizeof(*p));
+	p->u.bt656.clock_curr = MT9V111_MCLK;
+	p->if_type = V4L2_IF_TYPE_BT656;
+	p->u.bt656.mode = V4L2_IF_TYPE_BT656_MODE_NOBT_8BIT;
+	p->u.bt656.clock_min = MT9V111_CLK_MIN;
+	p->u.bt656.clock_max = MT9V111_CLK_MAX;
+
+	return 0;
+}
+
+/*!
+ * Sets the camera power.
+ *
+ * s  pointer to the camera device
+ * on if 1, power is to be turned on.  0 means power is to be turned off
+ *
+ * ioctl_s_power - V4L2 sensor interface handler for vidioc_int_s_power_num
+ * @s: pointer to standard V4L2 device structure
+ * @on: power state to which device is to be set
+ *
+ * Sets devices power state to requrested state, if possible.
+ * This is called on suspend and resume.
+ */
+static int ioctl_s_power(struct v4l2_int_device *s, int on)
+{
+	struct sensor *sensor = s->priv;
+
+	pr_debug("In mt9v111:ioctl_s_power\n");
+
+	sensor->on = on;
+
+	if (on)
+		gpio_sensor_active();
+	else
+		gpio_sensor_inactive();
+
+	return 0;
+}
+
+/*!
+ * ioctl_g_parm - V4L2 sensor interface handler for VIDIOC_G_PARM ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @a: pointer to standard V4L2 VIDIOC_G_PARM ioctl structure
+ *
+ * Returns the sensor's video CAPTURE parameters.
+ */
+static int ioctl_g_parm(struct v4l2_int_device *s, struct v4l2_streamparm *a)
+{
+	int ret = 0;
+	struct v4l2_captureparm *cparm = &a->parm.capture;
+	/* s->priv points to mt9v111_data */
+
+	pr_debug("In mt9v111:ioctl_g_parm\n");
+
+	switch (a->type) {
+	/* This is the only case currently handled. */
+	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
+		pr_debug("   type is V4L2_BUF_TYPE_VIDEO_CAPTURE\n");
+		memset(a, 0, sizeof(*a));
+		a->type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+		cparm->capability = mt9v111_data.streamcap.capability;
+		cparm->timeperframe =
+				mt9v111_data.streamcap.timeperframe;
+		cparm->capturemode = mt9v111_data.streamcap.capturemode;
+		ret = 0;
+		break;
+
+	/* These are all the possible cases. */
+	case V4L2_BUF_TYPE_VIDEO_OUTPUT:
+	case V4L2_BUF_TYPE_VIDEO_OVERLAY:
+	case V4L2_BUF_TYPE_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_VBI_OUTPUT:
+	case V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:
+		pr_err("   type is not V4L2_BUF_TYPE_VIDEO_CAPTURE " \
+			"but %d\n", a->type);
+		ret = -EINVAL;
+		break;
+
+	default:
+		pr_err("   type is unknown - %d\n", a->type);
+		ret = -EINVAL;
+		break;
 	}
 
-	printk(KERN_INFO "MT9V111 Detected\n");
+	return ret;
+}
+
+/*!
+ * ioctl_s_parm - V4L2 sensor interface handler for VIDIOC_S_PARM ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @a: pointer to standard V4L2 VIDIOC_S_PARM ioctl structure
+ *
+ * Configures the sensor to use the input parameters, if possible.  If
+ * not possible, reverts to the old parameters and returns the
+ * appropriate error code.
+ */
+static int ioctl_s_parm(struct v4l2_int_device *s, struct v4l2_streamparm *a)
+{
+	int ret = 0;
+	struct v4l2_captureparm *cparm = &a->parm.capture;
+	/* s->priv points to mt9v111_data */
+
+	pr_debug("In mt9v111:ioctl_s_parm\n");
+
+	switch (a->type) {
+	/* This is the only case currently handled. */
+	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
+		pr_debug("   type is V4L2_BUF_TYPE_VIDEO_CAPTURE\n");
+
+		/* Check that the new frame rate is allowed.
+		 * Changing the frame rate is not allowed on this
+		 *camera. */
+		if (cparm->timeperframe.denominator !=
+		    mt9v111_data.streamcap.timeperframe.denominator) {
+			pr_err("ERROR: mt9v111: ioctl_s_parm: " \
+			       "This camera does not allow frame rate "
+			       "changes.\n");
+			ret = -EINVAL;
+		} else {
+			mt9v111_data.streamcap.timeperframe =
+						cparm->timeperframe;
+		      /* Call any camera functions to match settings. */
+		}
+
+		/* Check that new capture mode is supported. */
+		if ((cparm->capturemode != 0) &&
+		    !(cparm->capturemode & V4L2_MODE_HIGHQUALITY)) {
+			pr_err("ERROR: mt9v111: ioctl_s_parm: " \
+				"unsupported capture mode\n");
+			ret  = -EINVAL;
+		} else {
+			mt9v111_data.streamcap.capturemode =
+						cparm->capturemode;
+		      /* Call any camera functions to match settings. */
+		      /* Right now this camera only supports 1 mode. */
+		}
+		break;
+
+	/* These are all the possible cases. */
+	case V4L2_BUF_TYPE_VIDEO_OUTPUT:
+	case V4L2_BUF_TYPE_VIDEO_OVERLAY:
+	case V4L2_BUF_TYPE_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_VBI_OUTPUT:
+	case V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:
+		pr_err("   type is not V4L2_BUF_TYPE_VIDEO_CAPTURE " \
+			"but %d\n", a->type);
+		ret = -EINVAL;
+		break;
+
+	default:
+		pr_err("   type is unknown - %d\n", a->type);
+		ret = -EINVAL;
+		break;
+	}
 
 	return 0;
 }
 
-static unsigned short normal_i2c[] = { MT9V111_I2C_ADDRESS, I2C_CLIENT_END };
+/*!
+ * ioctl_g_fmt_cap - V4L2 sensor interface handler for ioctl_g_fmt_cap
+ * @s: pointer to standard V4L2 device structure
+ * @f: pointer to standard V4L2 v4l2_format structure
+ *
+ * Returns the sensor's current pixel format in the v4l2_format
+ * parameter.
+ */
+static int ioctl_g_fmt_cap(struct v4l2_int_device *s, struct v4l2_format *f)
+{
+	struct sensor *sensor = s->priv;
+	/* s->priv points to mt9v111_data */
+
+	pr_debug("In mt9v111:ioctl_g_fmt_cap.\n");
+	pr_debug("   Returning size of %dx%d\n",
+		sensor->pix.width, sensor->pix.height);
+
+	f->fmt.pix = sensor->pix;
 
-/* Magic definition of all other variables and things */
-I2C_CLIENT_INSMOD;
+	return 0;
+}
 
 /*!
- * mt9v111 I2C attach function
+ * ioctl_queryctrl - V4L2 sensor interface handler for VIDIOC_QUERYCTRL ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @qc: standard V4L2 VIDIOC_QUERYCTRL ioctl structure
  *
- * @param adapter            struct i2c_adapter *
- * @return  Error code indicating success or failure
+ * If the requested control is supported, returns the control information
+ * from the video_control[] array.  Otherwise, returns -EINVAL if the
+ * control is not supported.
  */
-static int mt9v111_attach(struct i2c_adapter *adap)
+static int ioctl_queryctrl(struct v4l2_int_device *s, struct v4l2_queryctrl *qc)
 {
-	uint32_t mclk = 27000000;
-	struct clk *clk;
-	int err;
+	pr_debug("In mt9v111:ioctl_queryctrl\n");
 
-	clk = clk_get(NULL, "csi_clk");
-	clk_enable(clk);
-	set_mclk_rate(&mclk);
+	return 0;
+}
 
-	err = i2c_probe(adap, &addr_data, &mt9v111_detect_client);
+/*!
+ * ioctl_g_ctrl - V4L2 sensor interface handler for VIDIOC_G_CTRL ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @vc: standard V4L2 VIDIOC_G_CTRL ioctl structure
+ *
+ * If the requested control is supported, returns the control's current
+ * value from the video_control[] array.  Otherwise, returns -EINVAL
+ * if the control is not supported.
+ */
+static int ioctl_g_ctrl(struct v4l2_int_device *s, struct v4l2_control *vc)
+{
+	pr_debug("In mt9v111:ioctl_g_ctrl\n");
 
-	clk_disable(clk);
-	clk_put(clk);
+	switch (vc->id) {
+	case V4L2_CID_BRIGHTNESS:
+		pr_debug("   V4L2_CID_BRIGHTNESS\n");
+		vc->value = mt9v111_data.brightness;
+		break;
+	case V4L2_CID_CONTRAST:
+		pr_debug("   V4L2_CID_CONTRAST\n");
+		vc->value = mt9v111_data.contrast;
+		break;
+	case V4L2_CID_SATURATION:
+		pr_debug("   V4L2_CID_SATURATION\n");
+		vc->value = mt9v111_data.saturation;
+		break;
+	case V4L2_CID_HUE:
+		pr_debug("   V4L2_CID_HUE\n");
+		vc->value = mt9v111_data.hue;
+		break;
+	case V4L2_CID_AUTO_WHITE_BALANCE:
+		pr_debug(
+			"   V4L2_CID_AUTO_WHITE_BALANCE\n");
+		vc->value = 0;
+		break;
+	case V4L2_CID_DO_WHITE_BALANCE:
+		pr_debug(
+			"   V4L2_CID_DO_WHITE_BALANCE\n");
+		vc->value = 0;
+		break;
+	case V4L2_CID_RED_BALANCE:
+		pr_debug("   V4L2_CID_RED_BALANCE\n");
+		vc->value = mt9v111_data.red;
+		break;
+	case V4L2_CID_BLUE_BALANCE:
+		pr_debug("   V4L2_CID_BLUE_BALANCE\n");
+		vc->value = mt9v111_data.blue;
+		break;
+	case V4L2_CID_GAMMA:
+		pr_debug("   V4L2_CID_GAMMA\n");
+		vc->value = 0;
+		break;
+	case V4L2_CID_EXPOSURE:
+		pr_debug("   V4L2_CID_EXPOSURE\n");
+		vc->value = mt9v111_data.ae_mode;
+		break;
+	case V4L2_CID_AUTOGAIN:
+		pr_debug("   V4L2_CID_AUTOGAIN\n");
+		vc->value = 0;
+		break;
+	case V4L2_CID_GAIN:
+		pr_debug("   V4L2_CID_GAIN\n");
+		vc->value = 0;
+		break;
+	case V4L2_CID_HFLIP:
+		pr_debug("   V4L2_CID_HFLIP\n");
+		vc->value = 0;
+		break;
+	case V4L2_CID_VFLIP:
+		pr_debug("   V4L2_CID_VFLIP\n");
+		vc->value = 0;
+		break;
+	default:
+		pr_debug("   Default case\n");
+		return -EPERM;
+		break;
+	}
 
-	return err;
+	return 0;
 }
 
 /*!
- * mt9v111 I2C detach function
+ * ioctl_s_ctrl - V4L2 sensor interface handler for VIDIOC_S_CTRL ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @vc: standard V4L2 VIDIOC_S_CTRL ioctl structure
  *
- * @param client            struct i2c_client *
- * @return  Error code indicating success or failure
+ * If the requested control is supported, sets the control's current
+ * value in HW (and updates the video_control[] array).  Otherwise,
+ * returns -EINVAL if the control is not supported.
  */
-static int mt9v111_detach(struct i2c_client *client)
+static int ioctl_s_ctrl(struct v4l2_int_device *s, struct v4l2_control *vc)
 {
-	int err;
+	int retval = 0;
 
-	if (!mt9v111_i2c_client.adapter)
-		return -1;
+	pr_debug("In mt9v111:ioctl_s_ctrl %d\n",
+		vc->id);
+
+	switch (vc->id) {
+	case V4L2_CID_BRIGHTNESS:
+		pr_debug("   V4L2_CID_BRIGHTNESS\n");
+		break;
+	case V4L2_CID_CONTRAST:
+		pr_debug("   V4L2_CID_CONTRAST\n");
+		break;
+	case V4L2_CID_SATURATION:
+		pr_debug("   V4L2_CID_SATURATION\n");
+		retval = mt9v111_set_saturation(vc->value);
+		break;
+	case V4L2_CID_HUE:
+		pr_debug("   V4L2_CID_HUE\n");
+		break;
+	case V4L2_CID_AUTO_WHITE_BALANCE:
+		pr_debug(
+			"   V4L2_CID_AUTO_WHITE_BALANCE\n");
+		break;
+	case V4L2_CID_DO_WHITE_BALANCE:
+		pr_debug(
+			"   V4L2_CID_DO_WHITE_BALANCE\n");
+		break;
+	case V4L2_CID_RED_BALANCE:
+		pr_debug("   V4L2_CID_RED_BALANCE\n");
+		break;
+	case V4L2_CID_BLUE_BALANCE:
+		pr_debug("   V4L2_CID_BLUE_BALANCE\n");
+		break;
+	case V4L2_CID_GAMMA:
+		pr_debug("   V4L2_CID_GAMMA\n");
+		break;
+	case V4L2_CID_EXPOSURE:
+		pr_debug("   V4L2_CID_EXPOSURE\n");
+		retval = mt9v111_set_ae_mode(vc->value);
+		break;
+	case V4L2_CID_AUTOGAIN:
+		pr_debug("   V4L2_CID_AUTOGAIN\n");
+		break;
+	case V4L2_CID_GAIN:
+		pr_debug("   V4L2_CID_GAIN\n");
+		break;
+	case V4L2_CID_HFLIP:
+		pr_debug("   V4L2_CID_HFLIP\n");
+		break;
+	case V4L2_CID_VFLIP:
+		pr_debug("   V4L2_CID_VFLIP\n");
+		break;
+	default:
+		pr_debug("   Default case\n");
+		retval = -EPERM;
+		break;
+	}
 
-	err = i2c_detach_client(&mt9v111_i2c_client);
-	mt9v111_i2c_client.adapter = NULL;
+	return retval;
+}
 
-	if (interface_param)
-		kfree(interface_param);
-	interface_param = NULL;
+/*!
+ * ioctl_init - V4L2 sensor interface handler for VIDIOC_INT_INIT
+ * @s: pointer to standard V4L2 device structure
+ */
+static int ioctl_init(struct v4l2_int_device *s)
+{
+	pr_debug("In mt9v111:ioctl_init\n");
 
-	return err;
+	return 0;
 }
 
-extern void gpio_sensor_active(void);
+/*!
+ * ioctl_dev_init - V4L2 sensor interface handler for vidioc_int_dev_init_num
+ * @s: pointer to standard V4L2 device structure
+ *
+ * Initialise the device when slave attaches to the master.
+ */
+static int ioctl_dev_init(struct v4l2_int_device *s)
+{
+	uint32_t clock_rate = MT9V111_MCLK;
+
+	pr_debug("In mt9v111:ioctl_dev_init\n");
+
+	gpio_sensor_active();
+
+	set_mclk_rate(&clock_rate);
+	mt9v111_rate_cal(&reset_frame_rate, clock_rate);
+	mt9v111_sensor_lib(mt9v111_device.coreReg, mt9v111_device.ifpReg);
+
+	return 0;
+}
 
 /*!
- * MT9V111 init function
+ * This structure defines all the ioctls for this module and links them to the
+ * enumeration.
+ */
+static struct v4l2_int_ioctl_desc mt9v111_ioctl_desc[] = {
+
+	{vidioc_int_dev_init_num, (v4l2_int_ioctl_func *)ioctl_dev_init},
+
+	/*!
+	 * Delinitialise the dev. at slave detach.
+	 * The complement of ioctl_dev_init.
+	 */
+/*	{vidioc_int_dev_exit_num, (v4l2_int_ioctl_func *) ioctl_dev_exit}, */
+
+	{vidioc_int_s_power_num, (v4l2_int_ioctl_func *) ioctl_s_power},
+	{vidioc_int_g_ifparm_num, (v4l2_int_ioctl_func *) ioctl_g_ifparm},
+/*	{vidioc_int_g_needs_reset_num,
+				(v4l2_int_ioctl_func *) ioctl_g_needs_reset}, */
+/*	{vidioc_int_reset_num, (v4l2_int_ioctl_func *) ioctl_reset}, */
+	{vidioc_int_init_num, (v4l2_int_ioctl_func *) ioctl_init},
+
+	/*!
+	 * VIDIOC_ENUM_FMT ioctl for the CAPTURE buffer type.
+	 */
+/*	{vidioc_int_enum_fmt_cap_num,
+				(v4l2_int_ioctl_func *) ioctl_enum_fmt_cap}, */
+
+	/*!
+	 * VIDIOC_TRY_FMT ioctl for the CAPTURE buffer type.
+	 * This ioctl is used to negotiate the image capture size and
+	 * pixel format without actually making it take effect.
+	 */
+/*	{vidioc_int_try_fmt_cap_num,
+				(v4l2_int_ioctl_func *) ioctl_try_fmt_cap}, */
+
+	{vidioc_int_g_fmt_cap_num, (v4l2_int_ioctl_func *) ioctl_g_fmt_cap},
+
+	/*!
+	 * If the requested format is supported, configures the HW to use that
+	 * format, returns error code if format not supported or HW can't be
+	 * correctly configured.
+	 */
+/*	{vidioc_int_s_fmt_cap_num, (v4l2_int_ioctl_func *)ioctl_s_fmt_cap}, */
+
+	{vidioc_int_g_parm_num, (v4l2_int_ioctl_func *) ioctl_g_parm},
+	{vidioc_int_s_parm_num, (v4l2_int_ioctl_func *) ioctl_s_parm},
+/*	{vidioc_int_queryctrl_num, (v4l2_int_ioctl_func *) ioctl_queryctrl}, */
+	{vidioc_int_g_ctrl_num, (v4l2_int_ioctl_func *) ioctl_g_ctrl},
+	{vidioc_int_s_ctrl_num, (v4l2_int_ioctl_func *) ioctl_s_ctrl},
+};
+
+static struct v4l2_int_slave mt9v111_slave = {
+	.ioctls = mt9v111_ioctl_desc,
+	.num_ioctls = ARRAY_SIZE(mt9v111_ioctl_desc),
+};
+
+static struct v4l2_int_device mt9v111_int_device = {
+	.module = THIS_MODULE,
+	.name = "mt9v111",
+	.type = v4l2_int_type_slave,
+	.u = {
+		.slave = &mt9v111_slave,
+		},
+};
+
+/*!
+ * mt9v111 I2C probe function
+ * Function set in i2c_driver struct.
+ * Called by insmod mt9v111_camera.ko.
+ *
+ * @return  Error code indicating success or failure
+ */
+static int mt9v111_probe(struct i2c_client *client,
+			 const struct i2c_device_id *id)
+{
+	int retval;
+
+	pr_debug("In mt9v111_probe  device id is %s\n", id->name);
+
+	/* Set initial values for the sensor struct. */
+	memset(&mt9v111_data, 0, sizeof(mt9v111_data));
+	mt9v111_data.i2c_client = client;
+	pr_debug("   client name is %s\n", client->name);
+	mt9v111_data.pix.pixelformat = V4L2_PIX_FMT_UYVY;
+	mt9v111_data.pix.width = MT9V111_MAX_WIDTH;
+	mt9v111_data.pix.height = MT9V111_MAX_HEIGHT;
+	mt9v111_data.streamcap.capability = 0; /* No higher resolution or frame
+						* frame rate changes supported.
+						*/
+	mt9v111_data.streamcap.timeperframe.denominator = MT9V111_FRAME_RATE;
+	mt9v111_data.streamcap.timeperframe.numerator = 1;
+
+	mt9v111_int_device.priv = &mt9v111_data;
+
+	pr_debug("   type is %d (expect %d)\n",
+		mt9v111_int_device.type, v4l2_int_type_slave);
+	pr_debug("   num ioctls is %d\n",
+		mt9v111_int_device.u.slave->num_ioctls);
+
+	/* This function attaches this structure to the /dev/video0 device.
+	 * The pointer in priv points to the mt9v111_data structure here.*/
+	retval = v4l2_int_device_register(&mt9v111_int_device);
+
+	return retval;
+}
+
+/*!
+ * Function set in i2c_driver struct.
+ * Called on rmmod mt9v111_camera.ko
+ */
+static int mt9v111_remove(struct i2c_client *client)
+{
+	pr_debug("In mt9v111_remove\n");
+
+	v4l2_int_device_unregister(&mt9v111_int_device);
+	return 0;
+}
+
+/*!
+ * MT9V111 init function.
+ * Called by insmod mt9v111_camera.ko.
  *
  * @return  Error code indicating success or failure
  */
@@ -621,38 +1014,49 @@ static __init int mt9v111_init(void)
 {
 	u8 err;
 
-	gpio_sensor_active();
+	pr_debug("In mt9v111_init\n");
 
+	/* Allocate memory for state structures. */
 	mt9v111_device.coreReg = (mt9v111_coreReg *)
-	    kmalloc(sizeof(mt9v111_coreReg), GFP_KERNEL);
+				kmalloc(sizeof(mt9v111_coreReg), GFP_KERNEL);
 	if (!mt9v111_device.coreReg)
 		return -1;
-
 	memset(mt9v111_device.coreReg, 0, sizeof(mt9v111_coreReg));
 
 	mt9v111_device.ifpReg = (mt9v111_IFPReg *)
-	    kmalloc(sizeof(mt9v111_IFPReg), GFP_KERNEL);
+				kmalloc(sizeof(mt9v111_IFPReg), GFP_KERNEL);
 	if (!mt9v111_device.ifpReg) {
 		kfree(mt9v111_device.coreReg);
 		mt9v111_device.coreReg = NULL;
 		return -1;
 	}
-
 	memset(mt9v111_device.ifpReg, 0, sizeof(mt9v111_IFPReg));
 
+	/* Set contents of the just created structures. */
+	mt9v111_config();
+
+	/* Tells the i2c driver what functions to call for this driver. */
 	err = i2c_add_driver(&mt9v111_i2c_driver);
+	if (err != 0)
+		pr_err("%s:driver registration failed, error=%d \n",
+		       __func__, err);
 
 	return err;
 }
 
-extern void gpio_sensor_inactive(void);
 /*!
- * MT9V111 cleanup function
+ * MT9V111 cleanup function.
+ * Called on rmmod mt9v111_camera.ko
  *
  * @return  Error code indicating success or failure
  */
 static void __exit mt9v111_clean(void)
 {
+	pr_debug("In mt9v111_clean()\n");
+
+	i2c_del_driver(&mt9v111_i2c_driver);
+	gpio_sensor_inactive();
+
 	if (mt9v111_device.coreReg) {
 		kfree(mt9v111_device.coreReg);
 		mt9v111_device.coreReg = NULL;
@@ -662,18 +1066,11 @@ static void __exit mt9v111_clean(void)
 		kfree(mt9v111_device.ifpReg);
 		mt9v111_device.ifpReg = NULL;
 	}
-
-	i2c_del_driver(&mt9v111_i2c_driver);
-
-	gpio_sensor_inactive();
 }
 
 module_init(mt9v111_init);
 module_exit(mt9v111_clean);
 
-/* Exported symbols for modules. */
-EXPORT_SYMBOL(camera_sensor_if);
-
 MODULE_AUTHOR("Freescale Semiconductor, Inc.");
 MODULE_DESCRIPTION("Mt9v111 Camera Driver");
 MODULE_LICENSE("GPL");
diff --git a/drivers/media/video/mxc/capture/mt9v111.h b/drivers/media/video/mxc/capture/mt9v111.h
index 21a16f1..cf38cec 100644
--- a/drivers/media/video/mxc/capture/mt9v111.h
+++ b/drivers/media/video/mxc/capture/mt9v111.h
@@ -1,5 +1,5 @@
 /*
- * Copyright 2004-2007 Freescale Semiconductor, Inc. All Rights Reserved.
+ * Copyright 2004-2008 Freescale Semiconductor, Inc. All Rights Reserved.
  */
 
 /*
@@ -20,8 +20,8 @@
  *
  * @brief MT9V111 Camera Header file
  *
- * It include all the defines for bitmaps operations, also two main structure
- * one for IFP interface structure, other for sensor core registers.
+ * This header file contains defines and structures for the iMagic mi8012
+ * aka the Micron mt9v111 camera.
  *
  * @ingroup Camera
  */
@@ -30,6 +30,16 @@
 #define MT9V111_H_
 
 /*!
+ * Basic camera values
+ */
+#define MT9V111_FRAME_RATE        30
+#define MT9V111_MCLK              27000000 /* Desired clock rate */
+#define MT9V111_CLK_MIN           12000000 /* This clock rate yields 15 fps */
+#define MT9V111_CLK_MAX           27000000
+#define MT9V111_MAX_WIDTH         640      /* Max width for this camera */
+#define MT9V111_MAX_HEIGHT        480      /* Max height for this camera */
+
+/*!
  * mt9v111 IFP REGISTER BANK MAP
  */
 #define MT9V111I_ADDR_SPACE_SEL           0x1
@@ -191,12 +201,12 @@
 #define MT9V111S_CHIP_ENABLE              0xF1
 #define MT9V111S_CHIP_VERSION             0xFF
 
-// OUTPUT_CTRL
+/* OUTPUT_CTRL */
 #define MT9V111S_OUTCTRL_SYNC             0x1
 #define MT9V111S_OUTCTRL_CHIP_ENABLE      0x2
 #define MT9V111S_OUTCTRL_TEST_MODE        0x40
 
-// READ_MODE
+/* READ_MODE */
 #define MT9V111S_RM_NOBADFRAME            0x1
 #define MT9V111S_RM_NODESTRUCT            0x2
 #define MT9V111S_RM_COLUMNSKIP            0x4
@@ -418,4 +428,4 @@ typedef struct {
 	u16 height;
 } mt9v111_image_format;
 
-#endif				// MT9V111_H_
+#endif				/* MT9V111_H_  */
diff --git a/drivers/media/video/mxc/capture/mx27_v4l2_capture.c b/drivers/media/video/mxc/capture/mx27_v4l2_capture.c
deleted file mode 100644
index e9bd171..0000000
--- a/drivers/media/video/mxc/capture/mx27_v4l2_capture.c
+++ /dev/null
@@ -1,2076 +0,0 @@
-/*
- * Copyright 2004-2007 Freescale Semiconductor, Inc. All Rights Reserved.
- */
-
-/*
- * The code contained herein is licensed under the GNU General Public
- * License. You may obtain a copy of the GNU General Public License
- * Version 2 or later at the following locations:
- *
- * http://www.opensource.org/licenses/gpl-license.html
- * http://www.gnu.org/copyleft/gpl.html
- */
-
-/*!
- * @file mx27_v4l2_capture.c
- *
- * @brief MX27 Video For Linux 2 driver
- *
- * @ingroup MXC_V4L2_CAPTURE
- */
-
-#include <linux/module.h>
-#include <linux/init.h>
-#include <linux/fs.h>
-#include <linux/slab.h>
-#include <linux/ctype.h>
-#include <linux/pagemap.h>
-#include <linux/vmalloc.h>
-#include <linux/types.h>
-#include <linux/fb.h>
-#include <linux/pci.h>
-#include <linux/platform_device.h>
-#include <linux/version.h>
-#include <media/v4l2-dev.h>
-#include <asm/io.h>
-#include <asm/semaphore.h>
-
-#include "mxc_v4l2_capture.h"
-#include "mx27_prp.h"
-#include "mx27_csi.h"
-
-static int csi_mclk_flag_backup;
-static int video_nr = -1;
-static cam_data *g_cam;
-
-/*!
- * Free frame buffers
- *
- * @param cam      Structure cam_data *
- *
- * @return status  0 success.
- */
-static int mxc_free_frame_buf(cam_data * cam)
-{
-	int i;
-
-	for (i = 0; i < FRAME_NUM; i++) {
-		if (cam->frame[i].vaddress != 0) {
-			dma_free_coherent(0,
-					  cam->frame[i].buffer.length,
-					  cam->frame[i].vaddress,
-					  cam->frame[i].paddress);
-			cam->frame[i].vaddress = 0;
-		}
-	}
-
-	return 0;
-}
-
-/*!
- * Allocate frame buffers
- *
- * @param cam      Structure cam_data *
- *
- * @param count    int number of buffer need to allocated
- *
- * @return status  -0 Successfully allocated a buffer, -ENOBUFS	failed.
- */
-static int mxc_allocate_frame_buf(cam_data * cam, int count)
-{
-	int i;
-
-	for (i = 0; i < count; i++) {
-		cam->frame[i].vaddress = dma_alloc_coherent(0,
-							    PAGE_ALIGN(cam->v2f.
-								       fmt.pix.
-								       sizeimage),
-							    &cam->frame[i].
-							    paddress,
-							    GFP_DMA |
-							    GFP_KERNEL);
-		if (cam->frame[i].vaddress == 0) {
-			pr_debug("mxc_allocate_frame_buf failed.\n");
-			mxc_free_frame_buf(cam);
-			return -ENOBUFS;
-		}
-		cam->frame[i].buffer.index = i;
-		cam->frame[i].buffer.flags = V4L2_BUF_FLAG_MAPPED;
-		cam->frame[i].buffer.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
-		cam->frame[i].buffer.length =
-		    PAGE_ALIGN(cam->v2f.fmt.pix.sizeimage);
-		cam->frame[i].buffer.memory = V4L2_MEMORY_MMAP;
-		cam->frame[i].buffer.m.offset = cam->frame[i].paddress;
-		cam->frame[i].index = i;
-	}
-
-	return 0;
-}
-
-/*!
- * Free frame buffers status
- *
- * @param cam    Structure cam_data *
- *
- * @return none
- */
-static void mxc_free_frames(cam_data * cam)
-{
-	int i;
-
-	for (i = 0; i < FRAME_NUM; i++) {
-		cam->frame[i].buffer.flags = V4L2_BUF_FLAG_MAPPED;
-	}
-
-	cam->enc_counter = 0;
-	cam->skip_frame = 0;
-	INIT_LIST_HEAD(&cam->ready_q);
-	INIT_LIST_HEAD(&cam->working_q);
-	INIT_LIST_HEAD(&cam->done_q);
-}
-
-/*!
- * Return the buffer status
- *
- * @param cam 	   Structure cam_data *
- * @param buf      Structure v4l2_buffer *
- *
- * @return status  0 success, EINVAL failed.
- */
-static int mxc_v4l2_buffer_status(cam_data * cam, struct v4l2_buffer *buf)
-{
-	/* check range */
-	if (buf->index < 0 || buf->index >= FRAME_NUM) {
-		pr_debug("mxc_v4l2_buffer_status buffers not allocated\n");
-		return -EINVAL;
-	}
-
-	memcpy(buf, &(cam->frame[buf->index].buffer), sizeof(*buf));
-	return 0;
-}
-
-/*!
- * start the encoder job
- *
- * @param cam      structure cam_data *
- *
- * @return status  0 Success
- */
-static int mxc_streamon(cam_data * cam)
-{
-	struct mxc_v4l_frame *frame;
-	int err = 0;
-
-	if (!cam)
-		return -EIO;
-
-	if (list_empty(&cam->ready_q)) {
-		printk(KERN_ERR "mxc_streamon buffer not been queued yet\n");
-		return -EINVAL;
-	}
-
-	cam->capture_pid = current->pid;
-
-	if (cam->enc_enable) {
-		err = cam->enc_enable(cam);
-		if (err != 0) {
-			return err;
-		}
-	}
-
-	cam->ping_pong_csi = 0;
-	if (cam->enc_update_eba) {
-		frame =
-		    list_entry(cam->ready_q.next, struct mxc_v4l_frame, queue);
-		list_del(cam->ready_q.next);
-		list_add_tail(&frame->queue, &cam->working_q);
-		err = cam->enc_update_eba(frame->paddress, &cam->ping_pong_csi);
-
-		frame =
-		    list_entry(cam->ready_q.next, struct mxc_v4l_frame, queue);
-		list_del(cam->ready_q.next);
-		list_add_tail(&frame->queue, &cam->working_q);
-		err |=
-		    cam->enc_update_eba(frame->paddress, &cam->ping_pong_csi);
-	} else {
-		return -EINVAL;
-	}
-
-	return err;
-}
-
-/*!
- * Shut down the encoder job
- *
- * @param cam      structure cam_data *
- *
- * @return status  0 Success
- */
-static int mxc_streamoff(cam_data * cam)
-{
-	int err = 0;
-
-	if (!cam)
-		return -EIO;
-
-	if (cam->enc_disable) {
-		err = cam->enc_disable(cam);
-	}
-	mxc_free_frames(cam);
-	return err;
-}
-
-/*!
- * Valid whether the palette is supported
- *
- * @param palette pixel format
- *
- * @return 0 if failed
- */
-static inline int valid_mode(u32 palette)
-{
-	/*
-	 * MX27 PrP channel 2 supports YUV444, but YUV444 is not
-	 * defined by V4L2 :(
-	 */
-	return ((palette == V4L2_PIX_FMT_YUYV) ||
-		(palette == V4L2_PIX_FMT_YUV420));
-}
-
-/*!
- * Valid and adjust the overlay window size, position
- *
- * @param cam      structure cam_data *
- * @param win      struct v4l2_window  *
- *
- * @return 0
- */
-static int verify_preview(cam_data * cam, struct v4l2_window *win)
-{
-	if (cam->output >= num_registered_fb) {
-		pr_debug("verify_preview No matched.\n");
-		return -1;
-	}
-	cam->overlay_fb = (struct fb_info *)registered_fb[cam->output];
-
-	/* TODO: suppose 16bpp, 4 bytes alignment */
-	win->w.left &= ~0x1;
-
-	if (win->w.width + win->w.left > cam->overlay_fb->var.xres)
-		win->w.width = cam->overlay_fb->var.xres - win->w.left;
-	if (win->w.height + win->w.top > cam->overlay_fb->var.yres)
-		win->w.height = cam->overlay_fb->var.yres - win->w.top;
-
-	/*
-	 * TODO: suppose 16bpp. Rounded down to a multiple of 2 pixels for
-	 * width according to PrP limitations.
-	 */
-	if ((cam->rotation == V4L2_MXC_ROTATE_90_RIGHT)
-	    || (cam->rotation == V4L2_MXC_ROTATE_90_RIGHT_VFLIP)
-	    || (cam->rotation == V4L2_MXC_ROTATE_90_RIGHT_HFLIP)
-	    || (cam->rotation == V4L2_MXC_ROTATE_90_LEFT))
-		win->w.height &= ~0x1;
-	else
-		win->w.width &= ~0x1;
-
-	return 0;
-}
-
-/*!
- * start the viewfinder job
- *
- * @param cam      structure cam_data *
- *
- * @return status  0 Success
- */
-static int start_preview(cam_data * cam)
-{
-	int err = 0;
-
-	err = prp_vf_select(cam);
-	if (err != 0)
-		return err;
-
-	cam->overlay_pid = current->pid;
-	err = cam->vf_start_sdc(cam);
-
-	return err;
-}
-
-/*!
- * shut down the viewfinder job
- *
- * @param cam      structure cam_data *
- *
- * @return status  0 Success
- */
-static int stop_preview(cam_data * cam)
-{
-	int err = 0;
-
-	err = prp_vf_deselect(cam);
-	return err;
-}
-
-/*!
- * V4L2 - mxc_v4l2_g_fmt function
- *
- * @param cam         structure cam_data *
- *
- * @param f           structure v4l2_format *
- *
- * @return  status    0 success, EINVAL failed
- */
-static int mxc_v4l2_g_fmt(cam_data * cam, struct v4l2_format *f)
-{
-	int retval = 0;
-
-	switch (f->type) {
-	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
-		f->fmt.pix.width = cam->v2f.fmt.pix.width;
-		f->fmt.pix.height = cam->v2f.fmt.pix.height;
-		f->fmt.pix.sizeimage = cam->v2f.fmt.pix.sizeimage;
-		f->fmt.pix.pixelformat = cam->v2f.fmt.pix.pixelformat;
-		f->fmt.pix.bytesperline = cam->v2f.fmt.pix.bytesperline;
-		f->fmt.pix.colorspace = V4L2_COLORSPACE_JPEG;
-		retval = 0;
-		break;
-	case V4L2_BUF_TYPE_VIDEO_OVERLAY:
-		f->fmt.win = cam->win;
-		break;
-	default:
-		retval = -EINVAL;
-	}
-	return retval;
-}
-
-/*!
- * V4L2 - mxc_v4l2_s_fmt function
- *
- * @param cam         structure cam_data *
- *
- * @param f           structure v4l2_format *
- *
- * @return  status    0 success, EINVAL failed
- */
-static int mxc_v4l2_s_fmt(cam_data * cam, struct v4l2_format *f)
-{
-	int retval = 0;
-	int size = 0;
-	int bytesperline = 0;
-
-	switch (f->type) {
-	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
-		if (!valid_mode(f->fmt.pix.pixelformat)) {
-			pr_debug("mxc_v4l2_s_fmt: format not supported\n");
-			retval = -EINVAL;
-		}
-
-		if (cam->rotation != V4L2_MXC_ROTATE_NONE)
-			pr_debug("mxc_v4l2_s_fmt: capture rotation ignored\n");
-
-		switch (f->fmt.pix.pixelformat) {
-		case V4L2_PIX_FMT_YUYV:
-			f->fmt.pix.width &= ~0x1;	/* Multiple of 2 */
-			size = f->fmt.pix.width * f->fmt.pix.height * 2;
-			bytesperline = f->fmt.pix.width * 2;
-			break;
-		case V4L2_PIX_FMT_YUV420:
-			f->fmt.pix.width &= ~0x7;	/* Multiple of 8 */
-			f->fmt.pix.height &= ~0x1;	/* Multiple of 2 */
-			size = f->fmt.pix.width * f->fmt.pix.height * 3 / 2;
-			bytesperline = f->fmt.pix.width * 3 / 2;
-			break;
-		default:
-			/* Suppose it's YUV444 or 32bpp */
-			size = f->fmt.pix.width * f->fmt.pix.height * 4;
-			bytesperline = f->fmt.pix.width * 4;
-			pr_info("mxc_v4l2_s_fmt: default assume"
-				" to be YUV444 interleaved.\n");
-			break;
-		}
-
-		if (f->fmt.pix.bytesperline < bytesperline) {
-			f->fmt.pix.bytesperline = bytesperline;
-		} else {
-			bytesperline = f->fmt.pix.bytesperline;
-		}
-
-		if (f->fmt.pix.sizeimage > size) {
-			pr_debug("mxc_v4l2_s_fmt: sizeimage bigger than"
-				 " needed.\n");
-			size = f->fmt.pix.sizeimage;
-		}
-		f->fmt.pix.sizeimage = size;
-
-		cam->v2f.fmt.pix.sizeimage = size;
-		cam->v2f.fmt.pix.bytesperline = bytesperline;
-		cam->v2f.fmt.pix.width = f->fmt.pix.width;
-		cam->v2f.fmt.pix.height = f->fmt.pix.height;
-		cam->v2f.fmt.pix.pixelformat = f->fmt.pix.pixelformat;
-		retval = 0;
-		break;
-	case V4L2_BUF_TYPE_VIDEO_OVERLAY:
-		retval = verify_preview(cam, &f->fmt.win);
-		cam->win = f->fmt.win;
-		break;
-	default:
-		retval = -EINVAL;
-	}
-	return retval;
-}
-
-/*!
- * get control param
- *
- * @param cam         structure cam_data *
- *
- * @param c           structure v4l2_control *
- *
- * @return  status    0 success, EINVAL failed
- */
-static int mxc_get_v42l_control(cam_data * cam, struct v4l2_control *c)
-{
-	int status = 0;
-
-	switch (c->id) {
-	case V4L2_CID_HFLIP:
-		c->value = cam->rotation;
-		break;
-	case V4L2_CID_VFLIP:
-		c->value = cam->rotation;
-		break;
-	case V4L2_CID_MXC_ROT:
-		c->value = cam->rotation;
-		break;
-	case V4L2_CID_BRIGHTNESS:
-		c->value = cam->bright;
-		break;
-	case V4L2_CID_HUE:
-		c->value = cam->hue;
-		break;
-	case V4L2_CID_CONTRAST:
-		c->value = cam->contrast;
-		break;
-	case V4L2_CID_SATURATION:
-		c->value = cam->saturation;
-		break;
-	case V4L2_CID_RED_BALANCE:
-		c->value = cam->red;
-		break;
-	case V4L2_CID_BLUE_BALANCE:
-		c->value = cam->blue;
-		break;
-	case V4L2_CID_BLACK_LEVEL:
-		c->value = cam->ae_mode;
-		break;
-	default:
-		status = -EINVAL;
-	}
-	return status;
-}
-
-/*!
- * V4L2 - set_control function
- * V4L2_CID_MXC_ROT is the extention for rotation/mirroring.
- *
- * @param cam         structure cam_data *
- *
- * @param c           structure v4l2_control *
- *
- * @return  status    0 success, EINVAL failed
- */
-static int mxc_set_v42l_control(cam_data * cam, struct v4l2_control *c)
-{
-	switch (c->id) {
-	case V4L2_CID_HFLIP:
-		if (c->value == 1) {
-			if ((cam->rotation != V4L2_MXC_ROTATE_VERT_FLIP) &&
-			    (cam->rotation != V4L2_MXC_ROTATE_180))
-				cam->rotation = V4L2_MXC_ROTATE_HORIZ_FLIP;
-			else
-				cam->rotation = V4L2_MXC_ROTATE_180;
-		} else {
-			if (cam->rotation == V4L2_MXC_ROTATE_HORIZ_FLIP)
-				cam->rotation = V4L2_MXC_ROTATE_NONE;
-			else if (cam->rotation == V4L2_MXC_ROTATE_180)
-				cam->rotation = V4L2_MXC_ROTATE_VERT_FLIP;
-		}
-		break;
-	case V4L2_CID_VFLIP:
-		if (c->value == 1) {
-			if ((cam->rotation != V4L2_MXC_ROTATE_HORIZ_FLIP) &&
-			    (cam->rotation != V4L2_MXC_ROTATE_180))
-				cam->rotation = V4L2_MXC_ROTATE_VERT_FLIP;
-			else
-				cam->rotation = V4L2_MXC_ROTATE_180;
-		} else {
-			if (cam->rotation == V4L2_MXC_ROTATE_VERT_FLIP)
-				cam->rotation = V4L2_MXC_ROTATE_NONE;
-			if (cam->rotation == V4L2_MXC_ROTATE_180)
-				cam->rotation = V4L2_MXC_ROTATE_HORIZ_FLIP;
-		}
-		break;
-	case V4L2_CID_MXC_ROT:
-		switch (c->value) {
-		case V4L2_MXC_ROTATE_NONE:
-		case V4L2_MXC_ROTATE_VERT_FLIP:
-		case V4L2_MXC_ROTATE_HORIZ_FLIP:
-		case V4L2_MXC_ROTATE_180:
-		case V4L2_MXC_ROTATE_90_RIGHT:
-		case V4L2_MXC_ROTATE_90_RIGHT_VFLIP:
-		case V4L2_MXC_ROTATE_90_RIGHT_HFLIP:
-		case V4L2_MXC_ROTATE_90_LEFT:
-			cam->rotation = c->value;
-			break;
-		default:
-			return -EINVAL;
-		}
-		break;
-	case V4L2_CID_HUE:
-		cam->hue = c->value;
-		break;
-	case V4L2_CID_CONTRAST:
-		cam->contrast = c->value;
-		break;
-	case V4L2_CID_BRIGHTNESS:
-		cam->bright = c->value;
-	case V4L2_CID_SATURATION:
-		cam->saturation = c->value;
-	case V4L2_CID_RED_BALANCE:
-		cam->red = c->value;
-	case V4L2_CID_BLUE_BALANCE:
-		cam->blue = c->value;
-		csi_enable_mclk(CSI_MCLK_I2C, true, true);
-		cam->cam_sensor->set_color(cam->bright, cam->saturation,
-					   cam->red, cam->green, cam->blue);
-		csi_enable_mclk(CSI_MCLK_I2C, false, false);
-		break;
-	case V4L2_CID_BLACK_LEVEL:
-		cam->ae_mode = c->value & 0x03;
-		csi_enable_mclk(CSI_MCLK_I2C, true, true);
-		if (cam->cam_sensor->set_ae_mode)
-			cam->cam_sensor->set_ae_mode(cam->ae_mode);
-		csi_enable_mclk(CSI_MCLK_I2C, false, false);
-		break;
-	case V4L2_CID_MXC_FLASH:
-		break;
-	default:
-		return -EINVAL;
-	}
-	return 0;
-}
-
-/*!
- * V4L2 - mxc_v4l2_s_param function
- *
- * @param cam         structure cam_data *
- *
- * @param parm        structure v4l2_streamparm *
- *
- * @return  status    0 success, EINVAL failed
- */
-static int mxc_v4l2_s_param(cam_data * cam, struct v4l2_streamparm *parm)
-{
-	sensor_interface *param;
-	csi_signal_cfg_t csi_param;
-
-	if (parm->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) {
-		pr_debug("mxc_v4l2_s_param invalid type\n");
-		return -EINVAL;
-	}
-
-	if (parm->parm.capture.timeperframe.denominator >
-	    cam->standard.frameperiod.denominator) {
-		pr_debug("mxc_v4l2_s_param frame rate %d larger "
-			 "than standard supported %d\n",
-			 parm->parm.capture.timeperframe.denominator,
-			 cam->standard.frameperiod.denominator);
-		return -EINVAL;
-	}
-
-	cam->streamparm.parm.capture.capability = V4L2_CAP_TIMEPERFRAME;
-
-	csi_enable_mclk(CSI_MCLK_I2C, true, true);
-	param = cam->cam_sensor->config
-	    (&parm->parm.capture.timeperframe.denominator,
-	     parm->parm.capture.capturemode);
-	csi_enable_mclk(CSI_MCLK_I2C, false, false);
-
-	cam->streamparm.parm.capture.timeperframe =
-	    parm->parm.capture.timeperframe;
-
-	if ((parm->parm.capture.capturemode != 0) &&
-	    (parm->parm.capture.capturemode != V4L2_MODE_HIGHQUALITY)) {
-		pr_debug("mxc_v4l2_s_param frame un-supported capture mode\n");
-		return -EINVAL;
-	}
-
-	if (parm->parm.capture.capturemode ==
-	    cam->streamparm.parm.capture.capturemode) {
-		return 0;
-	}
-
-	/* resolution changed, so need to re-program the CSI */
-	csi_param.sens_clksrc = 0;
-	csi_param.clk_mode = param->clk_mode;
-	csi_param.pixclk_pol = param->pixclk_pol;
-	csi_param.data_width = param->data_width;
-	csi_param.data_pol = param->data_pol;
-	csi_param.ext_vsync = param->ext_vsync;
-	csi_param.Vsync_pol = param->Vsync_pol;
-	csi_param.Hsync_pol = param->Hsync_pol;
-	csi_init_interface(param->width, param->height, param->pixel_fmt,
-			   csi_param);
-
-	if (parm->parm.capture.capturemode != V4L2_MODE_HIGHQUALITY) {
-		cam->streamparm.parm.capture.capturemode = 0;
-	} else {
-		cam->streamparm.parm.capture.capturemode =
-		    V4L2_MODE_HIGHQUALITY;
-		cam->streamparm.parm.capture.extendedmode =
-		    parm->parm.capture.extendedmode;
-		cam->streamparm.parm.capture.readbuffers = 1;
-	}
-	return 0;
-}
-
-/*!
- * Dequeue one V4L capture buffer
- *
- * @param cam         structure cam_data *
- * @param buf         structure v4l2_buffer *
- *
- * @return  status    0 success, EINVAL invalid frame number,
- *                    ETIME timeout, ERESTARTSYS interrupted by user
- */
-static int mxc_v4l_dqueue(cam_data * cam, struct v4l2_buffer *buf)
-{
-	int retval = 0;
-	struct mxc_v4l_frame *frame;
-
-	if (!wait_event_interruptible_timeout(cam->enc_queue,
-					      cam->enc_counter != 0, 10 * HZ)) {
-		printk(KERN_ERR "mxc_v4l_dqueue timeout enc_counter %x\n",
-		       cam->enc_counter);
-		return -ETIME;
-	} else if (signal_pending(current)) {
-		printk(KERN_ERR "mxc_v4l_dqueue() interrupt received\n");
-		return -ERESTARTSYS;
-	}
-
-	cam->enc_counter--;
-
-	frame = list_entry(cam->done_q.next, struct mxc_v4l_frame, queue);
-	list_del(cam->done_q.next);
-	if (frame->buffer.flags & V4L2_BUF_FLAG_DONE) {
-		frame->buffer.flags &= ~V4L2_BUF_FLAG_DONE;
-	} else if (frame->buffer.flags & V4L2_BUF_FLAG_QUEUED) {
-		printk(KERN_ERR "VIDIOC_DQBUF: Buffer not filled.\n");
-		frame->buffer.flags &= ~V4L2_BUF_FLAG_QUEUED;
-		retval = -EINVAL;
-	} else if ((frame->buffer.flags & 0x7) == V4L2_BUF_FLAG_MAPPED) {
-		printk(KERN_ERR "VIDIOC_DQBUF: Buffer not queued.\n");
-		retval = -EINVAL;
-	}
-
-	buf->bytesused = cam->v2f.fmt.pix.sizeimage;
-	buf->index = frame->index;
-	buf->flags = frame->buffer.flags;
-
-	return retval;
-}
-
-/*!
- * V4L interface - open function
- *
- * @param inode        structure inode *
- * @param file         structure file *
- *
- * @return  status    0 success, ENODEV invalid device instance,
- *                    ENODEV timeout, ERESTARTSYS interrupted by user
- */
-static int mxc_v4l_open(struct inode *inode, struct file *file)
-{
-	sensor_interface *param;
-	csi_signal_cfg_t csi_param;
-	struct video_device *dev = video_devdata(file);
-	cam_data *cam = dev->priv;
-	int err = 0;
-
-	if (!cam) {
-		pr_info("Internal error, cam_data not found!\n");
-		return -ENODEV;
-	}
-
-	if (down_interruptible(&cam->busy_lock))
-		return -EINTR;
-
-	if (signal_pending(current))
-		goto oops;
-
-	if (cam->open_count++ == 0) {
-		wait_event_interruptible(cam->power_queue,
-					 cam->low_power == false);
-
-		err = prp_enc_select(cam);
-
-		cam->enc_counter = 0;
-		cam->skip_frame = 0;
-		INIT_LIST_HEAD(&cam->ready_q);
-		INIT_LIST_HEAD(&cam->working_q);
-		INIT_LIST_HEAD(&cam->done_q);
-
-		csi_enable_mclk(CSI_MCLK_I2C, true, true);
-		param = cam->cam_sensor->reset();
-		if (param == NULL) {
-			cam->open_count--;
-			csi_enable_mclk(CSI_MCLK_I2C, false, false);
-			err = -ENODEV;
-			goto oops;
-		}
-		csi_param.sens_clksrc = 0;
-		csi_param.clk_mode = param->clk_mode;
-		csi_param.pixclk_pol = param->pixclk_pol;
-		csi_param.data_width = param->data_width;
-		csi_param.data_pol = param->data_pol;
-		csi_param.ext_vsync = param->ext_vsync;
-		csi_param.Vsync_pol = param->Vsync_pol;
-		csi_param.Hsync_pol = param->Hsync_pol;
-		csi_init_interface(param->width, param->height,
-				   param->pixel_fmt, csi_param);
-		cam->cam_sensor->get_color(&cam->bright, &cam->saturation,
-					   &cam->red, &cam->green, &cam->blue);
-		if (cam->cam_sensor->get_ae_mode)
-			cam->cam_sensor->get_ae_mode(&cam->ae_mode);
-		csi_enable_mclk(CSI_MCLK_I2C, false, false);
-		prp_init(cam);
-
-	}
-
-	file->private_data = dev;
-      oops:
-	up(&cam->busy_lock);
-	return err;
-}
-
-/*!
- * V4L interface - close function
- *
- * @param inode    struct inode *
- * @param file     struct file *
- *
- * @return         0 success
- */
-static int mxc_v4l_close(struct inode *inode, struct file *file)
-{
-	struct video_device *dev = video_devdata(file);
-	int err = 0;
-	cam_data *cam = dev->priv;
-
-	/* for the case somebody hit the ctrl C */
-	if (cam->overlay_pid == current->pid) {
-		err = stop_preview(cam);
-		cam->overlay_on = false;
-	}
-	if (cam->capture_pid == current->pid) {
-		err |= mxc_streamoff(cam);
-		cam->capture_on = false;
-		wake_up_interruptible(&cam->enc_queue);
-	}
-
-	if (--cam->open_count == 0) {
-		wait_event_interruptible(cam->power_queue,
-					 cam->low_power == false);
-		pr_debug("mxc_v4l_close: release resource\n");
-
-		err |= prp_enc_deselect(cam);
-
-		mxc_free_frame_buf(cam);
-		file->private_data = NULL;
-
-		/* capture off */
-		wake_up_interruptible(&cam->enc_queue);
-		mxc_free_frames(cam);
-		cam->enc_counter++;
-		prp_exit(cam);
-	}
-
-	return err;
-}
-
-#ifdef CONFIG_VIDEO_MXC_CSI_DMA
-#include <asm/arch/dma.h>
-
-#define CSI_DMA_STATUS_IDLE	0	/* DMA is not started */
-#define CSI_DMA_STATUS_WORKING	1	/* DMA is transfering the data */
-#define CSI_DMA_STATUS_DONE	2	/* One frame completes successfully */
-#define CSI_DMA_STATUS_ERROR	3	/* Error occurs during the DMA */
-
-/*
- * Sometimes the start of the DMA is not synchronized with the CSI
- * SOF (Start of Frame) interrupt which will lead to incorrect
- * captured image. In this case the driver will re-try capturing
- * another frame. The following macro defines the maximum re-try
- * times.
- */
-#define CSI_DMA_RETRY		8
-
-/*
- * Size of the physical contiguous memory area used to hold image data
- * transfered by DMA. It can be less than the size of the image data.
- */
-#define CSI_MEM_SIZE		(1024 * 600)
-
-/* Number of bytes for one DMA transfer */
-#define CSI_DMA_LENGTH		(1024 * 200)
-
-static int g_dma_channel = 0;
-static int g_dma_status = CSI_DMA_STATUS_DONE;
-static volatile int g_dma_completed;	/* number of completed DMA transfers */
-static volatile int g_dma_copied;	/* number of copied DMA transfers */
-static struct tasklet_struct g_dma_tasklet;
-static char *g_user_buf;	/* represents the buf passed by read() */
-static int g_user_count;	/* represents the count passed by read() */
-
-/*!
- * @brief setup the DMA to transfer data
- *	  There may be more than one DMA to transfer the whole image. Those
- *	  DMAs work like chain. This function is used to setup the DMA in
- *	  case there is enough space to hold the data.
- * @param	data	pointer to the cam structure
- */
-static void mxc_csi_dma_chaining(void *data)
-{
-	cam_data *cam = (cam_data *) data;
-	int count, chained = 0;
-	int max_dma = CSI_MEM_SIZE / CSI_DMA_LENGTH;
-	mxc_dma_requestbuf_t dma_request;
-
-	while (chained * CSI_DMA_LENGTH < g_user_count) {
-		/*
-		 * Calculate how many bytes the DMA should transfer. It may
-		 * be less than CSI_DMA_LENGTH if the DMA is the last one.
-		 */
-		if ((chained + 1) * CSI_DMA_LENGTH > g_user_count)
-			count = g_user_count - chained * CSI_DMA_LENGTH;
-		else
-			count = CSI_DMA_LENGTH;
-		pr_debug("%s() DMA chained count = %d\n", __FUNCTION__, count);
-
-		/* Config DMA */
-		memset(&dma_request, 0, sizeof(mxc_dma_requestbuf_t));
-		dma_request.dst_addr = cam->still_buf
-		    + (chained % max_dma) * CSI_DMA_LENGTH;
-		dma_request.src_addr = (dma_addr_t) CSI_CSIRXFIFO_PHYADDR;
-		dma_request.num_of_bytes = count;
-		mxc_dma_config(g_dma_channel, &dma_request, 1,
-			       MXC_DMA_MODE_READ);
-
-		chained++;
-	}
-}
-
-/*!
- * @brief Copy image data from physical contiguous memory to user space buffer
- *	  Once the data are copied, there will be more spare space in the
- *	  physical contiguous memory to receive data from DMA.
- * @param	data	pointer to the cam structure
- */
-static void mxc_csi_dma_task(unsigned long data)
-{
-	cam_data *cam = (cam_data *) data;
-	int count;
-	int max_dma = CSI_MEM_SIZE / CSI_DMA_LENGTH;
-
-	while (g_dma_copied < g_dma_completed) {
-		/*
-		 * Calculate how many bytes the DMA has transfered. It may
-		 * be less than CSI_DMA_LENGTH if the DMA is the last one.
-		 */
-		if ((g_dma_copied + 1) * CSI_DMA_LENGTH > g_user_count)
-			count = g_user_count - g_dma_copied * CSI_DMA_LENGTH;
-		else
-			count = CSI_DMA_LENGTH;
-		if (copy_to_user(g_user_buf + g_dma_copied * CSI_DMA_LENGTH,
-				 cam->still_buf_vaddr + (g_dma_copied % max_dma)
-				 * CSI_DMA_LENGTH, count))
-			pr_debug("Warning: some bytes not copied\n");
-
-		g_dma_copied++;
-	}
-
-	/* If the whole image has been captured */
-	if (g_dma_copied * CSI_DMA_LENGTH >= g_user_count) {
-		cam->still_counter++;
-		wake_up_interruptible(&cam->still_queue);
-	}
-
-	pr_debug("%s() DMA completed = %d copied = %d\n",
-		 __FUNCTION__, g_dma_completed, g_dma_copied);
-}
-
-/*!
- * @brief DMA interrupt callback function
- * @param	data	pointer to the cam structure
- * @param	error	DMA error flag
- * @param	count	number of bytes transfered by the DMA
- */
-static void mxc_csi_dma_callback(void *data, int error, unsigned int count)
-{
-	cam_data *cam = (cam_data *) data;
-	int max_dma = CSI_MEM_SIZE / CSI_DMA_LENGTH;
-	unsigned long lock_flags;
-
-	spin_lock_irqsave(&cam->int_lock, lock_flags);
-
-	g_dma_completed++;
-
-	if (error != MXC_DMA_DONE) {
-		g_dma_status = CSI_DMA_STATUS_ERROR;
-		pr_debug("%s() DMA error\n", __FUNCTION__);
-	}
-
-	/* If the whole image has been captured */
-	if ((g_dma_status != CSI_DMA_STATUS_ERROR)
-	    && (g_dma_completed * CSI_DMA_LENGTH >= g_user_count))
-		g_dma_status = CSI_DMA_STATUS_DONE;
-
-	if ((g_dma_status == CSI_DMA_STATUS_WORKING) &&
-	    (g_dma_completed >= g_dma_copied + max_dma)) {
-		g_dma_status = CSI_DMA_STATUS_ERROR;
-		pr_debug("%s() Previous buffer over written\n", __FUNCTION__);
-	}
-
-	/* Schedule the tasklet */
-	tasklet_schedule(&g_dma_tasklet);
-
-	spin_unlock_irqrestore(&cam->int_lock, lock_flags);
-
-	pr_debug("%s() count = %d bytes\n", __FUNCTION__, count);
-}
-
-/*!
- * @brief CSI interrupt callback function
- * @param	data	pointer to the cam structure
- * @param	status	CSI interrupt status
- */
-static void mxc_csi_irq_callback(void *data, unsigned long status)
-{
-	cam_data *cam = (cam_data *) data;
-	unsigned long lock_flags;
-
-	spin_lock_irqsave(&cam->int_lock, lock_flags);
-
-	/* Wait for SOF (Start of Frame) interrupt to sync the image */
-	if (status & BIT_SOF_INT) {
-		if (g_dma_status == CSI_DMA_STATUS_IDLE) {
-			/* Start DMA transfer to capture image */
-			mxc_dma_enable(g_dma_channel);
-			g_dma_status = CSI_DMA_STATUS_WORKING;
-			pr_debug("%s() DMA started.\n", __FUNCTION__);
-		} else if (g_dma_status == CSI_DMA_STATUS_WORKING) {
-			/*
-			 * Another SOF occurs during DMA transfer. In this
-			 * case the image is not synchronized so need to
-			 * report error and probably try again.
-			 */
-			g_dma_status = CSI_DMA_STATUS_ERROR;
-			pr_debug("%s() Image is not synchronized with DMA - "
-				 "SOF before DMA completes\n", __FUNCTION__);
-		}
-	}
-
-	spin_unlock_irqrestore(&cam->int_lock, lock_flags);
-
-	pr_debug("%s() g_dma_status = %d\n", __FUNCTION__, g_dma_status);
-}
-
-/*!
- * V4L interface - read function
- *
- * @param file       struct file *
- * @param read buf   char *
- * @param count      size_t
- * @param ppos       structure loff_t *
- *
- * @return           bytes read
- */
-static ssize_t
-mxc_v4l_read(struct file *file, char *buf, size_t count, loff_t * ppos)
-{
-	int err = 0;
-	struct video_device *dev = video_devdata(file);
-	cam_data *cam = dev->priv;
-	int retry = CSI_DMA_RETRY;
-
-	g_user_buf = buf;
-
-	if (down_interruptible(&cam->busy_lock))
-		return -EINTR;
-
-	/* Video capture and still image capture are exclusive */
-	if (cam->capture_on == true) {
-		err = -EBUSY;
-		goto exit0;
-	}
-
-	/* The CSI-DMA can not do CSC */
-	if (cam->v2f.fmt.pix.pixelformat != V4L2_PIX_FMT_YUYV) {
-		pr_info("mxc_v4l_read support YUYV pixel format only\n");
-		err = -EINVAL;
-		goto exit0;
-	}
-
-	/* The CSI-DMA can not do resize or crop */
-	if ((cam->v2f.fmt.pix.width != cam->crop_bounds.width)
-	    || (cam->v2f.fmt.pix.height != cam->crop_bounds.height)) {
-		pr_info("mxc_v4l_read resize is not supported\n");
-		pr_info("supported image size width = %d height = %d\n",
-			cam->crop_bounds.width, cam->crop_bounds.height);
-		err = -EINVAL;
-		goto exit0;
-	}
-	if ((cam->crop_current.left != cam->crop_bounds.left)
-	    || (cam->crop_current.width != cam->crop_bounds.width)
-	    || (cam->crop_current.top != cam->crop_bounds.top)
-	    || (cam->crop_current.height != cam->crop_bounds.height)) {
-		pr_info("mxc_v4l_read cropping is not supported\n");
-		err = -EINVAL;
-		goto exit0;
-	}
-
-	cam->still_buf_vaddr = dma_alloc_coherent(0,
-						  PAGE_ALIGN(CSI_MEM_SIZE),
-						  &cam->still_buf,
-						  GFP_DMA | GFP_KERNEL);
-
-	if (!cam->still_buf_vaddr) {
-		pr_info("mxc_v4l_read failed at allocate still_buf\n");
-		err = -ENOBUFS;
-		goto exit0;
-	}
-
-	/* Initialize DMA */
-	g_dma_channel = mxc_dma_request(MXC_DMA_CSI_RX, "CSI RX DMA");
-	if (g_dma_channel < 0) {
-		pr_debug("mxc_v4l_read failed to request DMA channel\n");
-		err = -EIO;
-		goto exit1;
-	}
-
-	err = mxc_dma_callback_set(g_dma_channel,
-				   (mxc_dma_callback_t) mxc_csi_dma_callback,
-				   (void *)cam);
-	if (err != 0) {
-		pr_debug("mxc_v4l_read failed to set DMA callback\n");
-		err = -EIO;
-		goto exit2;
-	}
-
-	g_user_buf = buf;
-	if (cam->v2f.fmt.pix.sizeimage < count)
-		g_user_count = cam->v2f.fmt.pix.sizeimage;
-	else
-		g_user_count = count & ~0x3;
-
-	tasklet_init(&g_dma_tasklet, mxc_csi_dma_task, (unsigned long)cam);
-	g_dma_status = CSI_DMA_STATUS_DONE;
-	csi_set_callback(mxc_csi_irq_callback, cam);
-	csi_enable_prpif(0);
-
-	/* clear current SOF first */
-	csi_clear_status(BIT_SOF_INT);
-	csi_enable_mclk(CSI_MCLK_RAW, true, true);
-
-	do {
-		g_dma_completed = g_dma_copied = 0;
-		mxc_csi_dma_chaining(cam);
-		cam->still_counter = 0;
-		g_dma_status = CSI_DMA_STATUS_IDLE;
-
-		if (!wait_event_interruptible_timeout(cam->still_queue,
-						      cam->still_counter != 0,
-						      10 * HZ)) {
-			pr_info("mxc_v4l_read timeout counter %x\n",
-				cam->still_counter);
-			err = -ETIME;
-			goto exit3;
-		}
-
-		if (g_dma_status == CSI_DMA_STATUS_DONE)
-			break;
-
-		if (retry-- == 0)
-			break;
-
-		pr_debug("Now retry image capture\n");
-	} while (1);
-
-	if (g_dma_status != CSI_DMA_STATUS_DONE)
-		err = -EIO;
-
-      exit3:
-	csi_enable_prpif(1);
-	g_dma_status = CSI_DMA_STATUS_DONE;
-	csi_set_callback(0, 0);
-	csi_enable_mclk(CSI_MCLK_RAW, false, false);
-	tasklet_kill(&g_dma_tasklet);
-
-      exit2:
-	mxc_dma_free(g_dma_channel);
-
-      exit1:
-	dma_free_coherent(0, PAGE_ALIGN(CSI_MEM_SIZE),
-			  cam->still_buf_vaddr, cam->still_buf);
-	cam->still_buf = 0;
-
-      exit0:
-	up(&cam->busy_lock);
-	if (err < 0)
-		return err;
-	else
-		return g_user_count;
-}
-#else
-/*!
- * V4L interface - read function
- *
- * @param file       struct file *
- * @param read buf   char *
- * @param count      size_t
- * @param ppos       structure loff_t *
- *
- * @return           bytes read
- */
-static ssize_t
-mxc_v4l_read(struct file *file, char *buf, size_t count, loff_t * ppos)
-{
-	int err = 0;
-	u8 *v_address;
-	struct video_device *dev = video_devdata(file);
-	cam_data *cam = dev->priv;
-
-	if (down_interruptible(&cam->busy_lock))
-		return -EINTR;
-
-	/* Video capture and still image capture are exclusive */
-	if (cam->capture_on == true) {
-		err = -EBUSY;
-		goto exit0;
-	}
-
-	v_address = dma_alloc_coherent(0,
-				       PAGE_ALIGN(cam->v2f.fmt.pix.sizeimage),
-				       &cam->still_buf, GFP_DMA | GFP_KERNEL);
-
-	if (!v_address) {
-		pr_info("mxc_v4l_read failed at allocate still_buf\n");
-		err = -ENOBUFS;
-		goto exit0;
-	}
-
-	if (prp_still_select(cam)) {
-		err = -EIO;
-		goto exit1;
-	}
-
-	cam->still_counter = 0;
-	if (cam->csi_start(cam)) {
-		err = -EIO;
-		goto exit2;
-	}
-
-	if (!wait_event_interruptible_timeout(cam->still_queue,
-					      cam->still_counter != 0,
-					      10 * HZ)) {
-		pr_info("mxc_v4l_read timeout counter %x\n",
-			cam->still_counter);
-		err = -ETIME;
-		goto exit2;
-	}
-	err = copy_to_user(buf, v_address, cam->v2f.fmt.pix.sizeimage);
-
-      exit2:
-	prp_still_deselect(cam);
-
-      exit1:
-	dma_free_coherent(0, cam->v2f.fmt.pix.sizeimage, v_address,
-			  cam->still_buf);
-	cam->still_buf = 0;
-
-      exit0:
-	up(&cam->busy_lock);
-	if (err < 0)
-		return err;
-	else
-		return (cam->v2f.fmt.pix.sizeimage - err);
-}
-#endif				/* CONFIG_VIDEO_MXC_CSI_DMA */
-
-/*!
- * V4L interface - ioctl function
- *
- * @param inode      struct inode *
- *
- * @param file       struct file *
- *
- * @param ioctlnr    unsigned int
- *
- * @param arg        void *
- *
- * @return           0 success, ENODEV for invalid device instance,
- *                   -1 for other errors.
- */
-static int
-mxc_v4l_do_ioctl(struct inode *inode, struct file *file,
-		 unsigned int ioctlnr, void *arg)
-{
-	struct video_device *dev = video_devdata(file);
-	cam_data *cam = dev->priv;
-	int retval = 0;
-	unsigned long lock_flags;
-
-	if (!cam)
-		return -EBADF;
-
-	wait_event_interruptible(cam->power_queue, cam->low_power == false);
-	/* make this _really_ smp-safe */
-	if (down_interruptible(&cam->busy_lock))
-		return -EBUSY;
-
-	switch (ioctlnr) {
-		/*!
-		 * V4l2 VIDIOC_QUERYCAP ioctl
-		 */
-	case VIDIOC_QUERYCAP:{
-			struct v4l2_capability *cap = arg;
-			strcpy(cap->driver, "mxc_v4l2");
-			cap->version = KERNEL_VERSION(0, 1, 11);
-			cap->capabilities = V4L2_CAP_VIDEO_CAPTURE |
-			    V4L2_CAP_VIDEO_OVERLAY | V4L2_CAP_STREAMING
-			    | V4L2_CAP_READWRITE;
-			cap->card[0] = '\0';
-			cap->bus_info[0] = '\0';
-			retval = 0;
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_G_FMT ioctl
-		 */
-	case VIDIOC_G_FMT:{
-			struct v4l2_format *gf = arg;
-			retval = mxc_v4l2_g_fmt(cam, gf);
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_S_FMT ioctl
-		 */
-	case VIDIOC_S_FMT:{
-			struct v4l2_format *sf = arg;
-			retval = mxc_v4l2_s_fmt(cam, sf);
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_REQBUFS ioctl
-		 */
-	case VIDIOC_REQBUFS:{
-			struct v4l2_requestbuffers *req = arg;
-			if (req->count > FRAME_NUM) {
-				pr_info("VIDIOC_REQBUFS: not enough buffer\n");
-				req->count = FRAME_NUM;
-			}
-
-			if ((req->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) ||
-			    (req->memory != V4L2_MEMORY_MMAP)) {
-				pr_debug("VIDIOC_REQBUFS: wrong buffer type\n");
-				retval = -EINVAL;
-				break;
-			}
-
-			mxc_streamoff(cam);
-			mxc_free_frame_buf(cam);
-
-			retval = mxc_allocate_frame_buf(cam, req->count);
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_QUERYBUF ioctl
-		 */
-	case VIDIOC_QUERYBUF:{
-			struct v4l2_buffer *buf = arg;
-			int index = buf->index;
-
-			if (buf->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) {
-				pr_debug
-				    ("VIDIOC_QUERYBUFS: wrong buffer type\n");
-				retval = -EINVAL;
-				break;
-			}
-
-			memset(buf, 0, sizeof(buf));
-			buf->index = index;
-
-			down(&cam->param_lock);
-			retval = mxc_v4l2_buffer_status(cam, buf);
-			up(&cam->param_lock);
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_QBUF ioctl
-		 */
-	case VIDIOC_QBUF:{
-			struct v4l2_buffer *buf = arg;
-			int index = buf->index;
-
-			pr_debug("VIDIOC_QBUF: %d\n", buf->index);
-
-			spin_lock_irqsave(&cam->int_lock, lock_flags);
-			if ((cam->frame[index].buffer.flags & 0x7) ==
-			    V4L2_BUF_FLAG_MAPPED) {
-				cam->frame[index].buffer.flags |=
-				    V4L2_BUF_FLAG_QUEUED;
-				if (cam->skip_frame > 0) {
-					list_add_tail(&cam->frame[index].queue,
-						      &cam->working_q);
-					retval =
-					    cam->enc_update_eba(cam->
-								frame[index].
-								paddress,
-								&cam->
-								ping_pong_csi);
-					cam->skip_frame = 0;
-				} else {
-					list_add_tail(&cam->frame[index].queue,
-						      &cam->ready_q);
-				}
-			} else if (cam->frame[index].buffer.flags &
-				   V4L2_BUF_FLAG_QUEUED) {
-				pr_debug
-				    ("VIDIOC_QBUF: buffer already queued\n");
-			} else if (cam->frame[index].buffer.
-				   flags & V4L2_BUF_FLAG_DONE) {
-				pr_debug
-				    ("VIDIOC_QBUF: overwrite done buffer.\n");
-				cam->frame[index].buffer.flags &=
-				    ~V4L2_BUF_FLAG_DONE;
-				cam->frame[index].buffer.flags |=
-				    V4L2_BUF_FLAG_QUEUED;
-			}
-			buf->flags = cam->frame[index].buffer.flags;
-			spin_unlock_irqrestore(&cam->int_lock, lock_flags);
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_DQBUF ioctl
-		 */
-	case VIDIOC_DQBUF:{
-			struct v4l2_buffer *buf = arg;
-
-			retval = mxc_v4l_dqueue(cam, buf);
-
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_STREAMON ioctl
-		 */
-	case VIDIOC_STREAMON:{
-			cam->capture_on = true;
-			retval = mxc_streamon(cam);
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_STREAMOFF ioctl
-		 */
-	case VIDIOC_STREAMOFF:{
-			retval = mxc_streamoff(cam);
-			cam->capture_on = false;
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_G_CTRL ioctl
-		 */
-	case VIDIOC_G_CTRL:{
-			retval = mxc_get_v42l_control(cam, arg);
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_S_CTRL ioctl
-		 */
-	case VIDIOC_S_CTRL:{
-			retval = mxc_set_v42l_control(cam, arg);
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_CROPCAP ioctl
-		 */
-	case VIDIOC_CROPCAP:{
-			struct v4l2_cropcap *cap = arg;
-
-			if (cap->type != V4L2_BUF_TYPE_VIDEO_CAPTURE &&
-			    cap->type != V4L2_BUF_TYPE_VIDEO_OVERLAY) {
-				retval = -EINVAL;
-				break;
-			}
-			cap->bounds = cam->crop_bounds;
-			cap->defrect = cam->crop_defrect;
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_G_CROP ioctl
-		 */
-	case VIDIOC_G_CROP:{
-			struct v4l2_crop *crop = arg;
-
-			if (crop->type != V4L2_BUF_TYPE_VIDEO_CAPTURE &&
-			    crop->type != V4L2_BUF_TYPE_VIDEO_OVERLAY) {
-				retval = -EINVAL;
-				break;
-			}
-			crop->c = cam->crop_current;
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_S_CROP ioctl
-		 */
-	case VIDIOC_S_CROP:{
-			struct v4l2_crop *crop = arg;
-			struct v4l2_rect *b = &cam->crop_bounds;
-			int i;
-
-			if (crop->type != V4L2_BUF_TYPE_VIDEO_CAPTURE &&
-			    crop->type != V4L2_BUF_TYPE_VIDEO_OVERLAY) {
-				retval = -EINVAL;
-				break;
-			}
-
-			crop->c.top = (crop->c.top < b->top) ? b->top
-			    : crop->c.top;
-			if (crop->c.top > b->top + b->height)
-				crop->c.top = b->top + b->height - 1;
-			if (crop->c.height > b->top + b->height - crop->c.top)
-				crop->c.height =
-				    b->top + b->height - crop->c.top;
-
-			crop->c.left = (crop->c.left < b->left) ? b->left
-			    : crop->c.left;
-			if (crop->c.left > b->left + b->width)
-				crop->c.left = b->left + b->width - 1;
-			if (crop->c.width > b->left - crop->c.left + b->width)
-				crop->c.width =
-				    b->left - crop->c.left + b->width;
-
-			crop->c.width &= ~0x1;
-
-			/*
-			 * MX27 PrP limitation:
-			 * The right spare space (CSI_FRAME_X_SIZE
-			 *  - SOURCE_LINE_STRIDE - PICTURE_X_SIZE)) must be
-			 * multiple of 32.
-			 * So we tune the crop->c.left value to the closest
-			 * desired cropping value and meet the PrP requirement.
-			 */
-			i = ((b->left + b->width)
-			     - (crop->c.left + crop->c.width)) % 32;
-			if (i <= 16) {
-				if (crop->c.left + crop->c.width + i
-				    <= b->left + b->width)
-					crop->c.left += i;
-				else if (crop->c.left - (32 - i) >= b->left)
-					crop->c.left -= 32 - i;
-				else {
-					retval = -EINVAL;
-					break;
-				}
-			} else {
-				if (crop->c.left - (32 - i) >= b->left)
-					crop->c.left -= 32 - i;
-				else if (crop->c.left + crop->c.width + i
-					 <= b->left + b->width)
-					crop->c.left += i;
-				else {
-					retval = -EINVAL;
-					break;
-				}
-			}
-
-			cam->crop_current = crop->c;
-
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_OVERLAY ioctl
-		 */
-	case VIDIOC_OVERLAY:{
-			int *on = arg;
-			if (*on) {
-				cam->overlay_on = true;
-				retval = start_preview(cam);
-			}
-			if (!*on) {
-				retval = stop_preview(cam);
-				cam->overlay_on = false;
-			}
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_G_FBUF ioctl
-		 */
-	case VIDIOC_G_FBUF:{
-			struct v4l2_framebuffer *fb = arg;
-			struct fb_var_screeninfo *var;
-
-			if (cam->output >= num_registered_fb) {
-				retval = -EINVAL;
-				break;
-			}
-
-			var = &registered_fb[cam->output]->var;
-			cam->v4l2_fb.fmt.width = var->xres;
-			cam->v4l2_fb.fmt.height = var->yres;
-			cam->v4l2_fb.fmt.bytesperline =
-			    var->xres_virtual * var->bits_per_pixel;
-			cam->v4l2_fb.fmt.colorspace = V4L2_COLORSPACE_SRGB;
-			*fb = cam->v4l2_fb;
-			break;
-		}
-
-		/*!
-		 * V4l2 VIDIOC_S_FBUF ioctl
-		 */
-	case VIDIOC_S_FBUF:{
-			struct v4l2_framebuffer *fb = arg;
-			cam->v4l2_fb.flags = fb->flags;
-			cam->v4l2_fb.fmt.pixelformat = fb->fmt.pixelformat;
-			break;
-		}
-
-	case VIDIOC_G_PARM:{
-			struct v4l2_streamparm *parm = arg;
-			if (parm->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) {
-				pr_debug("VIDIOC_G_PARM invalid type\n");
-				retval = -EINVAL;
-				break;
-			}
-			parm->parm.capture = cam->streamparm.parm.capture;
-			break;
-		}
-	case VIDIOC_S_PARM:{
-			struct v4l2_streamparm *parm = arg;
-			retval = mxc_v4l2_s_param(cam, parm);
-			break;
-		}
-
-		/* linux v4l2 bug, kernel c0485619 user c0405619 */
-	case VIDIOC_ENUMSTD:{
-			struct v4l2_standard *e = arg;
-			*e = cam->standard;
-			pr_debug("VIDIOC_ENUMSTD call\n");
-			retval = 0;
-			break;
-		}
-
-	case VIDIOC_G_STD:{
-			v4l2_std_id *e = arg;
-			*e = cam->standard.id;
-			break;
-		}
-
-	case VIDIOC_S_STD:{
-			break;
-		}
-
-	case VIDIOC_ENUMOUTPUT:
-		{
-			struct v4l2_output *output = arg;
-
-			if (output->index >= num_registered_fb) {
-				retval = -EINVAL;
-				break;
-			}
-
-			strncpy(output->name,
-				registered_fb[output->index]->fix.id, 31);
-			output->type = V4L2_OUTPUT_TYPE_ANALOG;
-			output->audioset = 0;
-			output->modulator = 0;
-			output->std = V4L2_STD_UNKNOWN;
-
-			break;
-		}
-	case VIDIOC_G_OUTPUT:
-		{
-			int *p_output_num = arg;
-
-			*p_output_num = cam->output;
-			break;
-		}
-	case VIDIOC_S_OUTPUT:
-		{
-			int *p_output_num = arg;
-
-			if (*p_output_num >= num_registered_fb) {
-				retval = -EINVAL;
-				break;
-			}
-
-			cam->output = *p_output_num;
-			break;
-		}
-
-	case VIDIOC_ENUM_FMT:
-	case VIDIOC_TRY_FMT:
-	case VIDIOC_QUERYCTRL:
-	case VIDIOC_ENUMINPUT:
-	case VIDIOC_G_INPUT:
-	case VIDIOC_S_INPUT:
-	case VIDIOC_G_TUNER:
-	case VIDIOC_S_TUNER:
-	case VIDIOC_G_FREQUENCY:
-	case VIDIOC_S_FREQUENCY:
-	default:
-		retval = -EINVAL;
-		break;
-	}
-
-	up(&cam->busy_lock);
-	return retval;
-}
-
-/*
- * V4L interface - ioctl function
- *
- * @return  None
- */
-static int
-mxc_v4l_ioctl(struct inode *inode, struct file *file,
-	      unsigned int cmd, unsigned long arg)
-{
-	return video_usercopy(inode, file, cmd, arg, mxc_v4l_do_ioctl);
-}
-
-/*!
- * V4L interface - mmap function
- *
- * @param file        structure file *
- *
- * @param vma         structure vm_area_struct *
- *
- * @return status     0 Success, EINTR busy lock error, ENOBUFS remap_page error
- */
-static int mxc_mmap(struct file *file, struct vm_area_struct *vma)
-{
-	struct video_device *dev = video_devdata(file);
-	unsigned long size;
-	int res = 0;
-	cam_data *cam = dev->priv;
-
-	pr_debug("pgoff=0x%lx, start=0x%lx, end=0x%lx\n",
-		 vma->vm_pgoff, vma->vm_start, vma->vm_end);
-
-	/* make this _really_ smp-safe */
-	if (down_interruptible(&cam->busy_lock))
-		return -EINTR;
-
-	size = vma->vm_end - vma->vm_start;
-	vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
-
-	if (remap_pfn_range(vma, vma->vm_start,
-			    vma->vm_pgoff, size, vma->vm_page_prot)) {
-		pr_debug("mxc_mmap: remap_pfn_range failed\n");
-		res = -ENOBUFS;
-		goto mxc_mmap_exit;
-	}
-
-	vma->vm_flags &= ~VM_IO;	/* using shared anonymous pages */
-
-      mxc_mmap_exit:
-	up(&cam->busy_lock);
-	return res;
-}
-
-/*!
- * V4L interface - poll function
- *
- * @param file       structure file *
- *
- * @param wait       structure poll_table *
- *
- * @return  status   POLLIN | POLLRDNORM
- */
-static unsigned int mxc_poll(struct file *file, poll_table * wait)
-{
-	struct video_device *dev = video_devdata(file);
-	cam_data *cam = dev->priv;
-	wait_queue_head_t *queue = NULL;
-	int res = POLLIN | POLLRDNORM;
-
-	if (down_interruptible(&cam->busy_lock))
-		return -EINTR;
-
-	queue = &cam->enc_queue;
-	poll_wait(file, queue, wait);
-
-	up(&cam->busy_lock);
-	return res;
-}
-
-static struct
-file_operations mxc_v4l_fops = {
-	.owner = THIS_MODULE,
-	.open = mxc_v4l_open,
-	.release = mxc_v4l_close,
-	.read = mxc_v4l_read,
-	.ioctl = mxc_v4l_ioctl,
-	.mmap = mxc_mmap,
-	.poll = mxc_poll,
-};
-
-static struct video_device mxc_v4l_template = {
-	.owner = THIS_MODULE,
-	.name = "Mxc Camera",
-	.type = 0,
-	.type2 = VID_TYPE_CAPTURE,
-	.fops = &mxc_v4l_fops,
-	.release = video_device_release,
-};
-
-static void camera_platform_release(struct device *device)
-{
-}
-
-/*! Device Definition for Mt9v111 devices */
-static struct platform_device mxc_v4l2_devices = {
-	.name = "mxc_v4l2",
-	.dev = {
-		.release = camera_platform_release,
-		},
-	.id = 0,
-};
-
-extern struct camera_sensor camera_sensor_if;
-
-/*!
-* Camera V4l2 callback function.
-*
-* @return status
-*/
-static void camera_callback(u32 mask, void *dev)
-{
-	struct mxc_v4l_frame *done_frame;
-	struct mxc_v4l_frame *ready_frame;
-
-	cam_data *cam = (cam_data *) dev;
-	if (cam == NULL)
-		return;
-
-	if (list_empty(&cam->working_q)) {
-		printk(KERN_ERR "camera_callback: working queue empty\n");
-		return;
-	}
-
-	done_frame =
-	    list_entry(cam->working_q.next, struct mxc_v4l_frame, queue);
-	if (done_frame->buffer.flags & V4L2_BUF_FLAG_QUEUED) {
-		done_frame->buffer.flags |= V4L2_BUF_FLAG_DONE;
-		done_frame->buffer.flags &= ~V4L2_BUF_FLAG_QUEUED;
-
-		if (list_empty(&cam->ready_q)) {
-			cam->skip_frame++;
-		} else {
-			ready_frame =
-			    list_entry(cam->ready_q.next, struct mxc_v4l_frame,
-				       queue);
-			list_del(cam->ready_q.next);
-			list_add_tail(&ready_frame->queue, &cam->working_q);
-			cam->enc_update_eba(ready_frame->paddress,
-					    &cam->ping_pong_csi);
-		}
-
-		/* Added to the done queue */
-		list_del(cam->working_q.next);
-		list_add_tail(&done_frame->queue, &cam->done_q);
-
-		/* Wake up the queue */
-		cam->enc_counter++;
-		wake_up_interruptible(&cam->enc_queue);
-	} else {
-		printk(KERN_ERR "camera_callback :buffer not queued\n");
-	}
-}
-
-/*!
- * initialize cam_data structure
- *
- * @param cam      structure cam_data *
- *
- * @return status  0 Success
- */
-static void init_camera_struct(cam_data * cam)
-{
-	int i;
-
-	/* Default everything to 0 */
-	memset(cam, 0, sizeof(cam_data));
-
-	init_MUTEX(&cam->param_lock);
-	init_MUTEX(&cam->busy_lock);
-
-	cam->video_dev = video_device_alloc();
-	if (cam->video_dev == NULL)
-		return;
-
-	*(cam->video_dev) = mxc_v4l_template;
-
-	video_set_drvdata(cam->video_dev, cam);
-	dev_set_drvdata(&mxc_v4l2_devices.dev, (void *)cam);
-	cam->video_dev->minor = -1;
-
-	for (i = 0; i < FRAME_NUM; i++) {
-		cam->frame[i].width = 0;
-		cam->frame[i].height = 0;
-		cam->frame[i].paddress = 0;
-	}
-
-	init_waitqueue_head(&cam->enc_queue);
-	init_waitqueue_head(&cam->still_queue);
-
-	/* setup cropping */
-	cam->crop_bounds.left = 0;
-	cam->crop_bounds.width = 640;
-	cam->crop_bounds.top = 0;
-	cam->crop_bounds.height = 480;
-	cam->crop_current = cam->crop_defrect = cam->crop_bounds;
-	cam->streamparm.parm.capture.capturemode = 0;
-
-	cam->standard.index = 0;
-	cam->standard.id = V4L2_STD_UNKNOWN;
-	cam->standard.frameperiod.denominator = 30;
-	cam->standard.frameperiod.numerator = 1;
-	cam->standard.framelines = 480;
-	cam->streamparm.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
-	cam->streamparm.parm.capture.timeperframe = cam->standard.frameperiod;
-	cam->streamparm.parm.capture.capability = V4L2_CAP_TIMEPERFRAME;
-	cam->overlay_on = false;
-	cam->capture_on = false;
-	cam->skip_frame = 0;
-	cam->v4l2_fb.capability = V4L2_FBUF_CAP_EXTERNOVERLAY;
-	cam->v4l2_fb.flags = V4L2_FBUF_FLAG_PRIMARY;
-
-	cam->v2f.fmt.pix.sizeimage = 352 * 288 * 3 / 2;
-	cam->v2f.fmt.pix.bytesperline = 288 * 3 / 2;
-	cam->v2f.fmt.pix.width = 288;
-	cam->v2f.fmt.pix.height = 352;
-	cam->v2f.fmt.pix.pixelformat = V4L2_PIX_FMT_YUV420;
-	cam->win.w.width = 160;
-	cam->win.w.height = 160;
-	cam->win.w.left = 0;
-	cam->win.w.top = 0;
-
-	cam->cam_sensor = &camera_sensor_if;
-	cam->enc_callback = camera_callback;
-
-	init_waitqueue_head(&cam->power_queue);
-	cam->int_lock = SPIN_LOCK_UNLOCKED;
-	spin_lock_init(&cam->int_lock);
-}
-
-extern void gpio_sensor_active(void);
-extern void gpio_sensor_inactive(void);
-
-/*!
- * camera_power function
- *    Turn Sensor power On/Off
- *
- * @param       cameraOn      true to turn camera on, otherwise shut down
- *
- * @return status
- */
-static u8 camera_power(bool cameraOn)
-{
-	if (cameraOn == true) {
-		gpio_sensor_active();
-		csi_enable_mclk(csi_mclk_flag_backup, true, true);
-	} else {
-		csi_mclk_flag_backup = csi_read_mclk_flag();
-		csi_enable_mclk(csi_mclk_flag_backup, false, false);
-		gpio_sensor_inactive();
-	}
-	return 0;
-}
-
-/*!
- * This function is called to put the sensor in a low power state. Refer to the
- * document driver-model/driver.txt in the kernel source tree for more
- * information.
- *
- * @param   pdev  the device structure used to give information on which I2C
- *                to suspend
- * @param   state the power state the device is entering
- *
- * @return  The function returns 0 on success and -1 on failure.
- */
-static int mxc_v4l2_suspend(struct platform_device *pdev, pm_message_t state)
-{
-	cam_data *cam = platform_get_drvdata(pdev);
-
-	if (cam == NULL) {
-		return -1;
-	}
-
-	cam->low_power = true;
-
-	if (cam->overlay_on == true)
-		stop_preview(cam);
-	if ((cam->capture_on == true) && cam->enc_disable) {
-		cam->enc_disable(cam);
-	}
-	camera_power(false);
-
-	return 0;
-}
-
-/*!
- * This function is called to bring the sensor back from a low power state.Refer
- * to the document driver-model/driver.txt in the kernel source tree for more
- * information.
- *
- * @param   pdev  the device structure
- *
- * @return  The function returns 0 on success and -1 on failure
- */
-static int mxc_v4l2_resume(struct platform_device *pdev)
-{
-	cam_data *cam = platform_get_drvdata(pdev);
-
-	if (cam == NULL) {
-		return -1;
-	}
-
-	cam->low_power = false;
-	wake_up_interruptible(&cam->power_queue);
-
-	if (cam->overlay_on == true)
-		start_preview(cam);
-	if (cam->capture_on == true)
-		mxc_streamon(cam);
-	camera_power(true);
-
-	return 0;
-}
-
-/*!
- * This structure contains pointers to the power management callback functions.
- */
-static struct platform_driver mxc_v4l2_driver = {
-	.driver = {
-		   .name = "mxc_v4l2",
-		   .owner = THIS_MODULE,
-		   .bus = &platform_bus_type,
-		   },
-	.probe = NULL,
-	.remove = NULL,
-	.suspend = mxc_v4l2_suspend,
-	.resume = mxc_v4l2_resume,
-	.shutdown = NULL,
-};
-
-/*!
- * Entry point for the V4L2
- *
- * @return  Error code indicating success or failure
- */
-static __init int camera_init(void)
-{
-	u8 err = 0;
-	cam_data *cam;
-
-	if ((g_cam = cam = kmalloc(sizeof(cam_data), GFP_KERNEL)) == NULL) {
-		pr_debug("failed to mxc_v4l_register_camera\n");
-		return -1;
-	}
-
-	init_camera_struct(cam);
-
-	/* Register the I2C device */
-	err = platform_device_register(&mxc_v4l2_devices);
-	if (err != 0) {
-		pr_debug("camera_init: platform_device_register failed.\n");
-		video_device_release(cam->video_dev);
-		kfree(cam);
-		g_cam = NULL;
-	}
-
-	/* Register the device driver structure. */
-	err = platform_driver_register(&mxc_v4l2_driver);
-	if (err != 0) {
-		platform_device_unregister(&mxc_v4l2_devices);
-		pr_debug("camera_init: driver_register failed.\n");
-		video_device_release(cam->video_dev);
-		kfree(cam);
-		g_cam = NULL;
-		return err;
-	}
-
-	/* register v4l device */
-	if (video_register_device(cam->video_dev, VFL_TYPE_GRABBER, video_nr)
-	    == -1) {
-		platform_driver_unregister(&mxc_v4l2_driver);
-		platform_device_unregister(&mxc_v4l2_devices);
-		video_device_release(cam->video_dev);
-		kfree(cam);
-		g_cam = NULL;
-		pr_debug("video_register_device failed\n");
-		return -1;
-	}
-
-	return err;
-}
-
-/*!
- * Exit and cleanup for the V4L2
- *
- */
-static void __exit camera_exit(void)
-{
-	pr_debug("unregistering video\n");
-
-	video_unregister_device(g_cam->video_dev);
-
-	platform_driver_unregister(&mxc_v4l2_driver);
-	platform_device_unregister(&mxc_v4l2_devices);
-
-	if (g_cam->open_count) {
-		pr_debug("camera open -- setting ops to NULL\n");
-	} else {
-		pr_debug("freeing camera\n");
-		mxc_free_frame_buf(g_cam);
-		kfree(g_cam);
-		g_cam = NULL;
-	}
-}
-
-module_init(camera_init);
-module_exit(camera_exit);
-
-module_param(video_nr, int, 0444);
-
-MODULE_AUTHOR("Freescale Semiconductor, Inc.");
-MODULE_DESCRIPTION("V4L2 capture driver for Mxc based cameras");
-MODULE_LICENSE("GPL");
-MODULE_SUPPORTED_DEVICE("video");
diff --git a/drivers/media/video/mxc/capture/mxc_v4l2_capture.c b/drivers/media/video/mxc/capture/mxc_v4l2_capture.c
index 462c445..cfba56a 100644
--- a/drivers/media/video/mxc/capture/mxc_v4l2_capture.c
+++ b/drivers/media/video/mxc/capture/mxc_v4l2_capture.c
@@ -18,7 +18,6 @@
  *
  * @ingroup MXC_V4L2_CAPTURE
  */
-
 #include <linux/version.h>
 #include <linux/module.h>
 #include <linux/init.h>
@@ -33,17 +32,15 @@
 #include <linux/types.h>
 #include <linux/fb.h>
 #include <linux/dma-mapping.h>
-
+#include <media/v4l2-int-device.h>
 #include <asm/arch/mxcfb.h>
 #include "mxc_v4l2_capture.h"
 #include "ipu_prp_sw.h"
 
-#ifdef CONFIG_MXC_IPU_V1
-static int csi_mclk_flag_backup;
-#endif
 static int video_nr = -1;
 static cam_data *g_cam;
 
+/*! This data is used for the output to the display. */
 #define MXC_V4L2_CAPTURE_NUM_OUTPUTS        2
 static struct v4l2_output mxc_capture_outputs[MXC_V4L2_CAPTURE_NUM_OUTPUTS] = {
 	{
@@ -64,6 +61,97 @@ static struct v4l2_output mxc_capture_outputs[MXC_V4L2_CAPTURE_NUM_OUTPUTS] = {
 	 }
 };
 
+/*! List of TV input video formats supported. The video formats is corresponding
+ * to the v4l2_id in video_fmt_t.
+ * Currently, only PAL and NTSC is supported. Needs to be expanded in the
+ * future.
+ */
+typedef enum {
+	TV_NTSC = 0,		/*!< Locked on (M) NTSC video signal. */
+	TV_PAL,			/*!< (B, G, H, I, N)PAL video signal. */
+	TV_NOT_LOCKED,		/*!< Not locked on a signal. */
+} video_fmt_idx;
+
+/*! Number of video standards supported (including 'not locked' signal). */
+#define TV_STD_MAX		(TV_NOT_LOCKED + 1)
+
+/*! Video format structure. */
+typedef struct {
+	int v4l2_id;		/*!< Video for linux ID. */
+	char name[16];		/*!< Name (e.g., "NTSC", "PAL", etc.) */
+	u16 raw_width;		/*!< Raw width. */
+	u16 raw_height;		/*!< Raw height. */
+	u16 active_width;	/*!< Active width. */
+	u16 active_height;	/*!< Active height. */
+	u16 active_top;		/*!< Active top. */
+	u16 active_left;	/*!< Active left. */
+} video_fmt_t;
+
+/*!
+ * Description of video formats supported.
+ *
+ *  PAL: raw=720x625, active=720x576.
+ *  NTSC: raw=720x525, active=720x480.
+ */
+static video_fmt_t video_fmts[] = {
+	{			/*! NTSC */
+	 .v4l2_id = V4L2_STD_NTSC,
+	 .name = "NTSC",
+	 .raw_width = 720,		/* SENS_FRM_WIDTH */
+	 .raw_height = 288,		/* SENS_FRM_HEIGHT */
+	 .active_width = 720,		/* ACT_FRM_WIDTH */
+	 .active_height = (480 / 2),	/* ACT_FRM_HEIGHT */
+	 .active_top = 12,
+	 .active_left = 0,
+	 },
+	{			/*! (B, G, H, I, N) PAL */
+	 .v4l2_id = V4L2_STD_PAL,
+	 .name = "PAL",
+	 .raw_width = 720,
+	 .raw_height = (576 / 2) + 24 * 2,
+	 .active_width = 720,
+	 .active_height = (576 / 2),
+	 .active_top = 0,
+	 .active_left = 0,
+	 },
+	{			/*! Unlocked standard */
+	 .v4l2_id = V4L2_STD_ALL,
+	 .name = "Autodetect",
+	 .raw_width = 720,
+	 .raw_height = (576 / 2) + 24 * 2,
+	 .active_width = 720,
+	 .active_height = (576 / 2),
+	 .active_top = 0,
+	 .active_left = 0,
+	 },
+};
+
+/*!* Standard index of TV. */
+static video_fmt_idx video_index = TV_NOT_LOCKED;
+
+static int mxc_v4l2_master_attach(struct v4l2_int_device *slave);
+static void mxc_v4l2_master_detach(struct v4l2_int_device *slave);
+static u8 camera_power(cam_data *cam, bool cameraOn);
+
+/*! Information about this driver. */
+static struct v4l2_int_master mxc_v4l2_master = {
+	.attach = mxc_v4l2_master_attach,
+	.detach = mxc_v4l2_master_detach,
+};
+
+static struct v4l2_int_device mxc_v4l2_int_device = {
+	.module = THIS_MODULE,
+	.name = "mxc_v4l2_cap",
+	.type = v4l2_int_type_master,
+	.u = {
+		.master = &mxc_v4l2_master,
+		},
+};
+
+/***************************************************************************
+ * Functions for handling Frame buffers.
+ **************************************************************************/
+
 /*!
  * Free frame buffers
  *
@@ -71,10 +159,12 @@ static struct v4l2_output mxc_capture_outputs[MXC_V4L2_CAPTURE_NUM_OUTPUTS] = {
  *
  * @return status  0 success.
  */
-static int mxc_free_frame_buf(cam_data * cam)
+static int mxc_free_frame_buf(cam_data *cam)
 {
 	int i;
 
+	pr_debug("MVC: In mxc_free_frame_buf\n");
+
 	for (i = 0; i < FRAME_NUM; i++) {
 		if (cam->frame[i].vaddress != 0) {
 			dma_free_coherent(0, cam->frame[i].buffer.length,
@@ -90,16 +180,18 @@ static int mxc_free_frame_buf(cam_data * cam)
 /*!
  * Allocate frame buffers
  *
- * @param cam      Structure cam_data *
- *
+ * @param cam      Structure cam_data*
  * @param count    int number of buffer need to allocated
  *
  * @return status  -0 Successfully allocated a buffer, -ENOBUFS	failed.
  */
-static int mxc_allocate_frame_buf(cam_data * cam, int count)
+static int mxc_allocate_frame_buf(cam_data *cam, int count)
 {
 	int i;
 
+	pr_debug("In MVC:mxc_allocate_frame_buf - size=%d\n",
+		cam->v2f.fmt.pix.sizeimage);
+
 	for (i = 0; i < count; i++) {
 		cam->frame[i].vaddress =
 		    dma_alloc_coherent(0,
@@ -107,7 +199,8 @@ static int mxc_allocate_frame_buf(cam_data * cam, int count)
 				       &cam->frame[i].paddress,
 				       GFP_DMA | GFP_KERNEL);
 		if (cam->frame[i].vaddress == 0) {
-			printk(KERN_ERR "mxc_allocate_frame_buf failed.\n");
+			pr_err("ERROR: v4l2 capture: "
+				"mxc_allocate_frame_buf failed.\n");
 			mxc_free_frame_buf(cam);
 			return -ENOBUFS;
 		}
@@ -131,10 +224,12 @@ static int mxc_allocate_frame_buf(cam_data * cam, int count)
  *
  * @return none
  */
-static void mxc_free_frames(cam_data * cam)
+static void mxc_free_frames(cam_data *cam)
 {
 	int i;
 
+	pr_debug("In MVC:mxc_free_frames\n");
+
 	for (i = 0; i < FRAME_NUM; i++) {
 		cam->frame[i].buffer.flags = V4L2_BUF_FLAG_MAPPED;
 	}
@@ -154,11 +249,13 @@ static void mxc_free_frames(cam_data * cam)
  *
  * @return status  0 success, EINVAL failed.
  */
-static int mxc_v4l2_buffer_status(cam_data * cam, struct v4l2_buffer *buf)
+static int mxc_v4l2_buffer_status(cam_data *cam, struct v4l2_buffer *buf)
 {
+	pr_debug("In MVC:mxc_v4l2_buffer_status\n");
+
 	if (buf->index < 0 || buf->index >= FRAME_NUM) {
-		printk(KERN_ERR
-		       "mxc_v4l2_buffer_status buffers not allocated\n");
+		pr_err("ERROR: v4l2 capture: mxc_v4l2_buffer_status buffers "
+		       "not allocated\n");
 		return -EINVAL;
 	}
 
@@ -166,20 +263,51 @@ static int mxc_v4l2_buffer_status(cam_data * cam, struct v4l2_buffer *buf)
 	return 0;
 }
 
+/***************************************************************************
+ * Functions for handling the video stream.
+ **************************************************************************/
+
+/*!
+ * Indicates whether the palette is supported.
+ *
+ * @param palette V4L2_PIX_FMT_RGB565, V4L2_PIX_FMT_BGR24 or V4L2_PIX_FMT_BGR32
+ *
+ * @return 0 if failed
+ */
+static inline int valid_mode(u32 palette)
+{
+	return ((palette == V4L2_PIX_FMT_RGB565) ||
+		(palette == V4L2_PIX_FMT_BGR24) ||
+		(palette == V4L2_PIX_FMT_RGB24) ||
+		(palette == V4L2_PIX_FMT_BGR32) ||
+		(palette == V4L2_PIX_FMT_RGB32) ||
+		(palette == V4L2_PIX_FMT_YUV422P) ||
+		(palette == V4L2_PIX_FMT_UYVY) ||
+		(palette == V4L2_PIX_FMT_YUV420));
+}
+
 /*!
- * start the encoder job
+ * Start the encoder job
  *
  * @param cam      structure cam_data *
  *
  * @return status  0 Success
  */
-static int mxc_streamon(cam_data * cam)
+static int mxc_streamon(cam_data *cam)
 {
 	struct mxc_v4l_frame *frame;
 	int err = 0;
 
+	pr_debug("In MVC:mxc_streamon\n");
+
+	if (NULL == cam) {
+		pr_err("ERROR! cam parameter is NULL\n");
+		return -1;
+	}
+
 	if (list_empty(&cam->ready_q)) {
-		printk(KERN_ERR "mxc_streamon buffer not been queued yet\n");
+		pr_err("ERROR: v4l2 capture: mxc_streamon buffer has not been "
+			"queued yet\n");
 		return -EINVAL;
 	}
 
@@ -198,22 +326,21 @@ static int mxc_streamon(cam_data * cam)
 		    list_entry(cam->ready_q.next, struct mxc_v4l_frame, queue);
 		list_del(cam->ready_q.next);
 		list_add_tail(&frame->queue, &cam->working_q);
-		err =
-		    cam->enc_update_eba(frame->buffer.m.offset,
-					&cam->ping_pong_csi);
+		err = cam->enc_update_eba(frame->buffer.m.offset,
+					  &cam->ping_pong_csi);
 
 		frame =
 		    list_entry(cam->ready_q.next, struct mxc_v4l_frame, queue);
 		list_del(cam->ready_q.next);
 		list_add_tail(&frame->queue, &cam->working_q);
-		err |=
-		    cam->enc_update_eba(frame->buffer.m.offset,
-					&cam->ping_pong_csi);
+		err |= cam->enc_update_eba(frame->buffer.m.offset,
+					   &cam->ping_pong_csi);
 	} else {
 		return -EINVAL;
 	}
 
 	cam->capture_on = true;
+
 	return err;
 }
 
@@ -224,10 +351,12 @@ static int mxc_streamon(cam_data * cam)
  *
  * @return status  0 Success
  */
-static int mxc_streamoff(cam_data * cam)
+static int mxc_streamoff(cam_data *cam)
 {
 	int err = 0;
 
+	pr_debug("In MVC:mxc_streamoff\n");
+
 	if (cam->capture_on == false)
 		return 0;
 
@@ -240,25 +369,6 @@ static int mxc_streamoff(cam_data * cam)
 }
 
 /*!
- * Valid whether the palette is supported
- *
- * @param palette V4L2_PIX_FMT_RGB565, V4L2_PIX_FMT_BGR24 or V4L2_PIX_FMT_BGR32
- *
- * @return 0 if failed
- */
-static inline int valid_mode(u32 palette)
-{
-	return ((palette == V4L2_PIX_FMT_RGB565) ||
-		(palette == V4L2_PIX_FMT_BGR24) ||
-		(palette == V4L2_PIX_FMT_RGB24) ||
-		(palette == V4L2_PIX_FMT_BGR32) ||
-		(palette == V4L2_PIX_FMT_RGB32) ||
-		(palette == V4L2_PIX_FMT_YUV422P) ||
-		(palette == V4L2_PIX_FMT_UYVY) ||
-		(palette == V4L2_PIX_FMT_YUV420));
-}
-
-/*!
  * Valid and adjust the overlay window size, position
  *
  * @param cam      structure cam_data *
@@ -266,15 +376,17 @@ static inline int valid_mode(u32 palette)
  *
  * @return 0
  */
-static int verify_preview(cam_data * cam, struct v4l2_window *win)
+static int verify_preview(cam_data *cam, struct v4l2_window *win)
 {
 	int i = 0;
 	int *width, *height;
 
+	pr_debug("In MVC: verify_preview\n");
+
 	do {
 		cam->overlay_fb = (struct fb_info *)registered_fb[i];
 		if (cam->overlay_fb == NULL) {
-			printk(KERN_ERR "verify_preview No matched.\n");
+			pr_err("ERROR: verify_preview frame buffer NULL.\n");
 			return -1;
 		}
 		if (strncmp(cam->overlay_fb->fix.id,
@@ -314,10 +426,13 @@ static int verify_preview(cam_data * cam, struct v4l2_window *win)
 		if (*width % 8)
 			*width += 8 - *width % 8;
 		if (*width + win->w.left > cam->overlay_fb->var.xres) {
-			printk(KERN_ERR "width exceed resize limit.\n");
+			pr_err("ERROR: v4l2 capture: width exceeds "
+				"resize limit.\n");
 			return -1;
 		}
-		printk(KERN_ERR "width exceed limit resize to %d.\n", *width);
+		pr_err("ERROR: v4l2 capture: width exceeds limit. "
+			"Resize to %d.\n",
+			*width);
 	}
 
 	if ((cam->crop_bounds.height / *height > 8) ||
@@ -327,10 +442,13 @@ static int verify_preview(cam_data * cam, struct v4l2_window *win)
 		if (*height % 8)
 			*height += 8 - *height % 8;
 		if (*height + win->w.top > cam->overlay_fb->var.yres) {
-			printk(KERN_ERR "height exceed resize limit.\n");
+			pr_err("ERROR: v4l2 capture: height exceeds "
+				"resize limit.\n");
 			return -1;
 		}
-		printk(KERN_ERR "height exceed limit resize to %d.\n", *height);
+		pr_err("ERROR: v4l2 capture: height exceeds limit "
+			"resize to %d.\n",
+			*height);
 	}
 
 	return 0;
@@ -343,10 +461,14 @@ static int verify_preview(cam_data * cam, struct v4l2_window *win)
  *
  * @return status  0 Success
  */
-static int start_preview(cam_data * cam)
+static int start_preview(cam_data *cam)
 {
 	int err = 0;
+
+	pr_debug("MVC: start_preview\n");
+
 #if defined(CONFIG_MXC_IPU_PRP_VF_SDC) || defined(CONFIG_MXC_IPU_PRP_VF_SDC_MODULE)
+	pr_debug("   This is an SDC display\n");
 	if (cam->output == 0) {
 		if (cam->v4l2_fb.flags == V4L2_FBUF_FLAG_OVERLAY)
 			err = prp_vf_sdc_select(cam);
@@ -360,6 +482,7 @@ static int start_preview(cam_data * cam)
 #endif
 
 #if defined(CONFIG_MXC_IPU_PRP_VF_ADC) || defined(CONFIG_MXC_IPU_PRP_VF_ADC_MODULE)
+	pr_debug("   This is an ADC display\n");
 	if (cam->output == 1) {
 		err = prp_vf_adc_select(cam);
 		if (err != 0)
@@ -369,6 +492,19 @@ static int start_preview(cam_data * cam)
 	}
 #endif
 
+	pr_debug("End of %s: v2f pix widthxheight %d x %d\n",
+		 __func__,
+		 cam->v2f.fmt.pix.width, cam->v2f.fmt.pix.height);
+	pr_debug("End of %s: crop_bounds widthxheight %d x %d\n",
+		 __func__,
+		 cam->crop_bounds.width, cam->crop_bounds.height);
+	pr_debug("End of %s: crop_defrect widthxheight %d x %d\n",
+		 __func__,
+		 cam->crop_defrect.width, cam->crop_defrect.height);
+	pr_debug("End of %s: crop_current widthxheight %d x %d\n",
+		 __func__,
+		 cam->crop_current.width, cam->crop_current.height);
+
 	return err;
 }
 
@@ -379,10 +515,12 @@ static int start_preview(cam_data * cam)
  *
  * @return status  0 Success
  */
-static int stop_preview(cam_data * cam)
+static int stop_preview(cam_data *cam)
 {
 	int err = 0;
 
+	pr_debug("MVC: stop preview\n");
+
 #if defined(CONFIG_MXC_IPU_PRP_VF_ADC) || defined(CONFIG_MXC_IPU_PRP_VF_ADC_MODULE)
 	if (cam->output == 1) {
 		err = prp_vf_adc_deselect(cam);
@@ -401,6 +539,10 @@ static int stop_preview(cam_data * cam)
 	return err;
 }
 
+/***************************************************************************
+ * VIDIOC Functions.
+ **************************************************************************/
+
 /*!
  * V4L2 - mxc_v4l2_g_fmt function
  *
@@ -410,21 +552,39 @@ static int stop_preview(cam_data * cam)
  *
  * @return  status    0 success, EINVAL failed
  */
-static int mxc_v4l2_g_fmt(cam_data * cam, struct v4l2_format *f)
+static int mxc_v4l2_g_fmt(cam_data *cam, struct v4l2_format *f)
 {
 	int retval = 0;
 
+	pr_debug("In MVC: mxc_v4l2_g_fmt type=%d\n", f->type);
+
 	switch (f->type) {
 	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
+		pr_debug("   type is V4L2_BUF_TYPE_VIDEO_CAPTURE\n");
 		f->fmt.pix = cam->v2f.fmt.pix;
-		retval = 0;
 		break;
 	case V4L2_BUF_TYPE_VIDEO_OVERLAY:
+		pr_debug("   type is V4L2_BUF_TYPE_VIDEO_OVERLAY\n");
 		f->fmt.win = cam->win;
 		break;
 	default:
+		pr_debug("   type is invalid\n");
 		retval = -EINVAL;
 	}
+
+	pr_debug("End of %s: v2f pix widthxheight %d x %d\n",
+		 __func__,
+		 cam->v2f.fmt.pix.width, cam->v2f.fmt.pix.height);
+	pr_debug("End of %s: crop_bounds widthxheight %d x %d\n",
+		 __func__,
+		 cam->crop_bounds.width, cam->crop_bounds.height);
+	pr_debug("End of %s: crop_defrect widthxheight %d x %d\n",
+		 __func__,
+		 cam->crop_defrect.width, cam->crop_defrect.height);
+	pr_debug("End of %s: crop_current widthxheight %d x %d\n",
+		 __func__,
+		 cam->crop_current.width, cam->crop_current.height);
+
 	return retval;
 }
 
@@ -437,18 +597,31 @@ static int mxc_v4l2_g_fmt(cam_data * cam, struct v4l2_format *f)
  *
  * @return  status    0 success, EINVAL failed
  */
-static int mxc_v4l2_s_fmt(cam_data * cam, struct v4l2_format *f)
+static int mxc_v4l2_s_fmt(cam_data *cam, struct v4l2_format *f)
 {
 	int retval = 0;
 	int size = 0;
 	int bytesperline = 0;
 	int *width, *height;
 
+	pr_debug("In MVC: mxc_v4l2_s_fmt\n");
+
 	switch (f->type) {
 	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
+		pr_debug("   type=V4L2_BUF_TYPE_VIDEO_CAPTURE\n");
 		if (!valid_mode(f->fmt.pix.pixelformat)) {
-			printk(KERN_ERR
-			       "mxc_v4l2_s_fmt: format not supported\n");
+			pr_err("ERROR: v4l2 capture: mxc_v4l2_s_fmt: format "
+			       "not supported\n");
+			return -EINVAL;
+		}
+
+		/* Handle case where size requested is larger than cuurent
+		 * camera setting. */
+		if ((f->fmt.pix.width > cam->crop_bounds.width)
+			|| (f->fmt.pix.height > cam->crop_bounds.height)) {
+			/* Need the logic here, calling vidioc_s_param if
+			 * camera can change. */
+			/* For the moment, just return an error. */
 			return -EINVAL;
 		}
 
@@ -470,7 +643,8 @@ static int mxc_v4l2_s_fmt(cam_data * cam, struct v4l2_format *f)
 			*width = cam->crop_bounds.width / 8;
 			if (*width % 8)
 				*width += 8 - *width % 8;
-			printk(KERN_ERR "width exceed limit resize to %d.\n",
+			pr_err("ERROR: v4l2 capture: width exceeds limit "
+				"resize to %d.\n",
 			       *width);
 		}
 
@@ -480,7 +654,8 @@ static int mxc_v4l2_s_fmt(cam_data * cam, struct v4l2_format *f)
 			*height = cam->crop_bounds.height / 8;
 			if (*height % 8)
 				*height += 8 - *height % 8;
-			printk(KERN_ERR "height exceed limit resize to %d.\n",
+			pr_err("ERROR: v4l2 capture: height exceeds limit "
+			       "resize to %d.\n",
 			       *height);
 		}
 
@@ -543,15 +718,29 @@ static int mxc_v4l2_s_fmt(cam_data * cam, struct v4l2_format *f)
 				break;
 			}
 		}
-		retval = 0;
 		break;
 	case V4L2_BUF_TYPE_VIDEO_OVERLAY:
+		pr_debug("   type=V4L2_BUF_TYPE_VIDEO_OVERLAY\n");
 		retval = verify_preview(cam, &f->fmt.win);
 		cam->win = f->fmt.win;
 		break;
 	default:
 		retval = -EINVAL;
 	}
+
+	pr_debug("End of %s: v2f pix widthxheight %d x %d\n",
+		 __func__,
+		 cam->v2f.fmt.pix.width, cam->v2f.fmt.pix.height);
+	pr_debug("End of %s: crop_bounds widthxheight %d x %d\n",
+		 __func__,
+		 cam->crop_bounds.width, cam->crop_bounds.height);
+	pr_debug("End of %s: crop_defrect widthxheight %d x %d\n",
+		 __func__,
+		 cam->crop_defrect.width, cam->crop_defrect.height);
+	pr_debug("End of %s: crop_current widthxheight %d x %d\n",
+		 __func__,
+		 cam->crop_current.width, cam->crop_current.height);
+
 	return retval;
 }
 
@@ -564,46 +753,68 @@ static int mxc_v4l2_s_fmt(cam_data * cam, struct v4l2_format *f)
  *
  * @return  status    0 success, EINVAL failed
  */
-static int mxc_get_v42l_control(cam_data * cam, struct v4l2_control *c)
+static int mxc_v4l2_g_ctrl(cam_data *cam, struct v4l2_control *c)
 {
 	int status = 0;
 
+	pr_debug("In MVC:mxc_v4l2_g_ctrl\n");
+
+	/* probably don't need to store the values that can be retrieved,
+	 * locally, but they are for now. */
 	switch (c->id) {
 	case V4L2_CID_HFLIP:
+		/* This is handled in the ipu. */
 		if (cam->rotation == IPU_ROTATE_HORIZ_FLIP)
 			c->value = 1;
 		break;
 	case V4L2_CID_VFLIP:
+		/* This is handled in the ipu. */
 		if (cam->rotation == IPU_ROTATE_VERT_FLIP)
 			c->value = 1;
 		break;
 	case V4L2_CID_MXC_ROT:
+		/* This is handled in the ipu. */
 		c->value = cam->rotation;
 		break;
 	case V4L2_CID_BRIGHTNESS:
 		c->value = cam->bright;
+		status = vidioc_int_g_ctrl(cam->sensor, c);
+		cam->bright = c->value;
 		break;
 	case V4L2_CID_HUE:
 		c->value = cam->hue;
+		status = vidioc_int_g_ctrl(cam->sensor, c);
+		cam->hue = c->value;
 		break;
 	case V4L2_CID_CONTRAST:
 		c->value = cam->contrast;
+		status = vidioc_int_g_ctrl(cam->sensor, c);
+		cam->contrast = c->value;
 		break;
 	case V4L2_CID_SATURATION:
 		c->value = cam->saturation;
+		status = vidioc_int_g_ctrl(cam->sensor, c);
+		cam->saturation = c->value;
 		break;
 	case V4L2_CID_RED_BALANCE:
 		c->value = cam->red;
+		status = vidioc_int_g_ctrl(cam->sensor, c);
+		cam->red = c->value;
 		break;
 	case V4L2_CID_BLUE_BALANCE:
 		c->value = cam->blue;
+		status = vidioc_int_g_ctrl(cam->sensor, c);
+		cam->blue = c->value;
 		break;
 	case V4L2_CID_BLACK_LEVEL:
 		c->value = cam->ae_mode;
+		status = vidioc_int_g_ctrl(cam->sensor, c);
+		cam->ae_mode = c->value;
 		break;
 	default:
-		status = -EINVAL;
+		status = vidioc_int_g_ctrl(cam->sensor, c);
 	}
+
 	return status;
 }
 
@@ -621,10 +832,15 @@ static int mxc_get_v42l_control(cam_data * cam, struct v4l2_control *c)
  *
  * @return  status    0 success, EINVAL failed
  */
-static int mxc_set_v42l_control(cam_data * cam, struct v4l2_control *c)
+static int mxc_v4l2_s_ctrl(cam_data *cam, struct v4l2_control *c)
 {
+	int ret = 0;
+
+	pr_debug("In MVC:mxc_v4l2_s_ctrl\n");
+
 	switch (c->id) {
 	case V4L2_CID_HFLIP:
+		/* This is done by the IPU */
 		if (c->value == 1) {
 			if ((cam->rotation != IPU_ROTATE_VERT_FLIP) &&
 			    (cam->rotation != IPU_ROTATE_180))
@@ -639,6 +855,7 @@ static int mxc_set_v42l_control(cam_data * cam, struct v4l2_control *c)
 		}
 		break;
 	case V4L2_CID_VFLIP:
+		/* This is done by the IPU */
 		if (c->value == 1) {
 			if ((cam->rotation != IPU_ROTATE_HORIZ_FLIP) &&
 			    (cam->rotation != IPU_ROTATE_180))
@@ -653,6 +870,7 @@ static int mxc_set_v42l_control(cam_data * cam, struct v4l2_control *c)
 		}
 		break;
 	case V4L2_CID_MXC_ROT:
+		/* This is done by the IPU */
 		switch (c->value) {
 		case V4L2_MXC_ROTATE_NONE:
 			cam->rotation = IPU_ROTATE_NONE;
@@ -679,39 +897,50 @@ static int mxc_set_v42l_control(cam_data * cam, struct v4l2_control *c)
 			cam->rotation = IPU_ROTATE_90_LEFT;
 			break;
 		default:
-			return -EINVAL;
+			ret = -EINVAL;
 		}
 		break;
 	case V4L2_CID_HUE:
 		cam->hue = c->value;
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, true, true);
+		ret = vidioc_int_s_ctrl(cam->sensor, c);
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, false, false);
 		break;
 	case V4L2_CID_CONTRAST:
 		cam->contrast = c->value;
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, true, true);
+		ret = vidioc_int_s_ctrl(cam->sensor, c);
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, false, false);
 		break;
 	case V4L2_CID_BRIGHTNESS:
 		cam->bright = c->value;
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, true, true);
+		ret = vidioc_int_s_ctrl(cam->sensor, c);
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, false, false);
+		break;
 	case V4L2_CID_SATURATION:
 		cam->saturation = c->value;
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, true, true);
+		ret = vidioc_int_s_ctrl(cam->sensor, c);
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, false, false);
+		break;
 	case V4L2_CID_RED_BALANCE:
 		cam->red = c->value;
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, true, true);
+		ret = vidioc_int_s_ctrl(cam->sensor, c);
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, false, false);
+		break;
 	case V4L2_CID_BLUE_BALANCE:
 		cam->blue = c->value;
-		ipu_csi_enable_mclk_if(CSI_MCLK_I2C,
-			cam->cam_sensor->csi, true, true);
-		cam->cam_sensor->set_color(cam->bright, cam->saturation,
-					   cam->red, cam->green, cam->blue);
-		ipu_csi_enable_mclk_if(CSI_MCLK_I2C,
-			cam->cam_sensor->csi, false, false);
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, true, true);
+		ret = vidioc_int_s_ctrl(cam->sensor, c);
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, false, false);
 		break;
-	case V4L2_CID_BLACK_LEVEL:
-		cam->ae_mode = c->value & 0x03;
-		ipu_csi_enable_mclk_if(CSI_MCLK_I2C,
-			cam->cam_sensor->csi, true, true);
-		if (cam->cam_sensor->set_ae_mode)
-			cam->cam_sensor->set_ae_mode(cam->ae_mode);
-
-		ipu_csi_enable_mclk_if(CSI_MCLK_I2C,
-			cam->cam_sensor->csi, false, false);
+	case V4L2_CID_EXPOSURE:
+		cam->ae_mode = c->value;
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, true, true);
+		ret = vidioc_int_s_ctrl(cam->sensor, c);
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, false, false);
 		break;
 	case V4L2_CID_MXC_FLASH:
 #ifdef CONFIG_MXC_IPU_V1
@@ -719,37 +948,35 @@ static int mxc_set_v42l_control(cam_data * cam, struct v4l2_control *c)
 #endif
 		break;
 	default:
-		return -EINVAL;
+		pr_debug("   default case\n");
+		ret = -EINVAL;
+		break;
 	}
-	return 0;
+
+	return ret;
 }
 
 /*!
  * V4L2 - mxc_v4l2_s_param function
+ * Allows setting of capturemode and frame rate.
  *
  * @param cam         structure cam_data *
- *
  * @param parm        structure v4l2_streamparm *
  *
  * @return  status    0 success, EINVAL failed
  */
-static int mxc_v4l2_s_param(cam_data * cam, struct v4l2_streamparm *parm)
+static int mxc_v4l2_s_param(cam_data *cam, struct v4l2_streamparm *parm)
 {
-	sensor_interface *param;
+	struct v4l2_ifparm ifparm;
+	struct v4l2_format cam_fmt;
+	struct v4l2_streamparm currentparm;
 	ipu_csi_signal_cfg_t csi_param;
 	int err = 0;
 
-	if (parm->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) {
-		printk(KERN_ERR "mxc_v4l2_s_param invalid type\n");
-		return -EINVAL;
-	}
+	pr_debug("In mxc_v4l2_s_param\n");
 
-	if (parm->parm.capture.timeperframe.denominator >
-	    cam->standard.frameperiod.denominator) {
-		printk(KERN_ERR "mxc_v4l2_s_param frame rate %d larger "
-		       "than standard supported %d\n",
-		       parm->parm.capture.timeperframe.denominator,
-		       cam->standard.frameperiod.denominator);
+	if (parm->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) {
+		pr_err(KERN_ERR "mxc_v4l2_s_param invalid type\n");
 		return -EINVAL;
 	}
 
@@ -758,72 +985,200 @@ static int mxc_v4l2_s_param(cam_data * cam, struct v4l2_streamparm *parm)
 		stop_preview(cam);
 	}
 
-	cam->streamparm.parm.capture.capability = V4L2_CAP_TIMEPERFRAME;
-
-	ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->cam_sensor->csi, true, true);
-
-	param = cam->cam_sensor->config
-	    (&parm->parm.capture.timeperframe.denominator,
-	     parm->parm.capture.capturemode);
-
-	ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->cam_sensor->csi,
-			false, false);
+	currentparm.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
 
-	cam->streamparm.parm.capture.timeperframe =
-	    parm->parm.capture.timeperframe;
-
-	if ((parm->parm.capture.capturemode != 0) &&
-	    (parm->parm.capture.capturemode != V4L2_MODE_HIGHQUALITY)) {
-		printk(KERN_ERR
-		       "mxc_v4l2_s_param frame un-supported capture mode\n");
-		err = -EINVAL;
+	/* First check that this device can support the changes requested. */
+	err = vidioc_int_g_parm(cam->sensor, &currentparm);
+	if (err) {
+		pr_err("%s: vidioc_int_g_parm returned an error %d\n",
+			__func__, err);
 		goto exit;
 	}
 
-	if (parm->parm.capture.capturemode ==
-	    cam->streamparm.parm.capture.capturemode) {
+	pr_debug("   Current capabilities are %x\n",
+			currentparm.parm.capture.capability);
+	pr_debug("   Current capturemode is %d  change to %d\n",
+			currentparm.parm.capture.capturemode,
+			parm->parm.capture.capturemode);
+	pr_debug("   Current framerate is %d  change to %d\n",
+			currentparm.parm.capture.timeperframe.denominator,
+			parm->parm.capture.timeperframe.denominator);
+
+	/* This will change any camera settings needed. */
+	ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, true, true);
+	err = vidioc_int_s_parm(cam->sensor, parm);
+	ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, false, false);
+	if (err) {
+		pr_err("%s: vidioc_int_s_parm returned an error %d\n",
+			__func__, err);
 		goto exit;
 	}
 
-	/* resolution changed, so need to re-program the CSI */
+	/* If resolution changed, need to re-program the CSI */
+	/* Get new values. */
+	vidioc_int_g_ifparm(cam->sensor, &ifparm);
+
+	csi_param.data_width = 0;
+	csi_param.clk_mode = 0;
+	csi_param.ext_vsync = 0;
+	csi_param.Vsync_pol = 0;
+	csi_param.Hsync_pol = 0;
+	csi_param.pixclk_pol = 0;
+	csi_param.data_pol = 0;
 	csi_param.sens_clksrc = 0;
-	csi_param.clk_mode = param->clk_mode;
-	csi_param.pixclk_pol = param->pixclk_pol;
-	csi_param.data_width = param->data_width;
-	csi_param.data_pol = param->data_pol;
-	csi_param.ext_vsync = param->ext_vsync;
-	csi_param.Vsync_pol = param->Vsync_pol;
-	csi_param.Hsync_pol = param->Hsync_pol;
-	csi_param.data_fmt = param->pixel_fmt;
-	csi_param.pack_tight = param->pack_tight;
-	csi_param.force_eof = param->force_eof;
-	csi_param.data_en_pol = param->data_en_pol;
-	csi_param.csi = cam->cam_sensor->csi;
-	ipu_csi_init_interface(param->width, param->height,
-			       param->pixel_fmt, csi_param);
-
-	ipu_csi_set_window_size(param->active_width,
-		param->active_height, cam->cam_sensor->csi);
-
-	if (parm->parm.capture.capturemode != V4L2_MODE_HIGHQUALITY) {
-		cam->streamparm.parm.capture.capturemode = 0;
+	csi_param.pack_tight = 0;
+	csi_param.force_eof = 0;
+	csi_param.data_en_pol = 0;
+	csi_param.data_fmt = 0;
+	csi_param.csi = 0;
+	csi_param.mclk = 0;
+
+	/* This may not work on other platforms. Check when adding a new one.*/
+	pr_debug("   clock_curr=mclk=%d\n", ifparm.u.bt656.clock_curr);
+	if (ifparm.u.bt656.clock_curr == 0) {
+		csi_param.clk_mode = IPU_CSI_CLK_MODE_CCIR656_PROGRESSIVE;
 	} else {
-		cam->streamparm.parm.capture.capturemode =
-		    V4L2_MODE_HIGHQUALITY;
-		cam->streamparm.parm.capture.extendedmode =
-		    parm->parm.capture.extendedmode;
-		cam->streamparm.parm.capture.readbuffers = 1;
+		csi_param.clk_mode = IPU_CSI_CLK_MODE_GATED_CLK;
 	}
 
-      exit:
-	if (cam->overlay_on == true) {
-		start_preview(cam);
+	csi_param.pixclk_pol = ifparm.u.bt656.latch_clk_inv;
+
+	if (ifparm.u.bt656.mode == V4L2_IF_TYPE_BT656_MODE_NOBT_8BIT) {
+		csi_param.data_width = IPU_CSI_DATA_WIDTH_8;
+	} else if (ifparm.u.bt656.mode
+				== V4L2_IF_TYPE_BT656_MODE_NOBT_10BIT) {
+		csi_param.data_width = IPU_CSI_DATA_WIDTH_10;
+	} else {
+		csi_param.data_width = IPU_CSI_DATA_WIDTH_8;
 	}
 
+	csi_param.Vsync_pol = ifparm.u.bt656.nobt_vs_inv;
+	csi_param.Hsync_pol = ifparm.u.bt656.nobt_hs_inv;
+	csi_param.ext_vsync = ifparm.u.bt656.bt_sync_correct;
+
+	/* if the capturemode changed, the size bounds will have changed. */
+	cam_fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	vidioc_int_g_fmt_cap(cam->sensor, &cam_fmt);
+	pr_debug("   g_fmt_cap returns widthxheight of input as %d x %d\n",
+			cam_fmt.fmt.pix.width, cam_fmt.fmt.pix.height);
+
+	csi_param.data_fmt = cam_fmt.fmt.pix.pixelformat;
+
+	cam->crop_bounds.top = cam->crop_bounds.left = 0;
+	cam->crop_bounds.width = cam_fmt.fmt.pix.width;
+	cam->crop_bounds.height = cam_fmt.fmt.pix.height;
+
+	/* This essentially loses the data at the left and bottom of the image
+	 * giving a digital zoom image, if crop_current is less than the full
+	 * size of the image. */
+	ipu_csi_set_window_size(cam->crop_current.width,
+				cam->crop_current.height, cam->csi);
+	ipu_csi_set_window_pos(cam->crop_current.left,
+			       cam->crop_current.top,
+			       cam->csi);
+	ipu_csi_init_interface(cam->crop_bounds.width,
+			       cam->crop_bounds.height,
+			       cam_fmt.fmt.pix.pixelformat, csi_param);
+
+
+exit:
+	if (cam->overlay_on == true)
+		start_preview(cam);
+
 	return err;
 }
 
 /*!
+ * V4L2 - mxc_v4l2_s_std function
+ *
+ * Sets the TV standard to be used.
+ *
+ * @param cam	      structure cam_data *
+ * @param parm	      structure v4l2_streamparm *
+ *
+ * @return  status    0 success, EINVAL failed
+ */
+static int mxc_v4l2_s_std(cam_data *cam, v4l2_std_id e)
+{
+	bool change = false;
+
+	if (e != cam->standard.id) {
+		change = true;
+	}
+
+	pr_debug("In mxc_v4l2_s_std %Lx\n", e);
+	if (e == V4L2_STD_PAL) {
+		pr_debug("   Setting standard to PAL %Lx\n", V4L2_STD_PAL);
+		cam->standard.id = V4L2_STD_PAL;
+		video_index = TV_PAL;
+		cam->crop_current.top = 0;
+	} else if (e == V4L2_STD_NTSC) {
+		pr_debug("   Setting standard to NTSC %Lx\n",
+				V4L2_STD_NTSC);
+		/* Get rid of the white dot line in NTSC signal input */
+		cam->standard.id = V4L2_STD_NTSC;
+		video_index = TV_NTSC;
+		cam->crop_current.top = 12;
+	} else {
+		cam->standard.id = V4L2_STD_ALL;
+		video_index = TV_NOT_LOCKED;
+		cam->crop_current.top = 0;
+		pr_err("ERROR: unrecognized std! %Lx (PAL=%Lx, NTSC=%Lx\n",
+			e, V4L2_STD_PAL, V4L2_STD_NTSC);
+	}
+
+	cam->standard.index = video_index;
+	strcpy(cam->standard.name, video_fmts[video_index].name);
+	cam->crop_bounds.width = video_fmts[video_index].raw_width;
+	cam->crop_bounds.height = video_fmts[video_index].raw_height;
+	cam->crop_current.width = video_fmts[video_index].active_width;
+	cam->crop_current.height = video_fmts[video_index].active_height;
+	cam->crop_current.left = 0;
+
+	return 0;
+}
+
+/*!
+ * V4L2 - mxc_v4l2_g_std function
+ *
+ * Gets the TV standard from the TV input device.
+ *
+ * @param cam	      structure cam_data *
+ *
+ * @param e	      structure v4l2_streamparm *
+ *
+ * @return  status    0 success, EINVAL failed
+ */
+static int mxc_v4l2_g_std(cam_data *cam, v4l2_std_id *e)
+{
+	struct v4l2_format tv_fmt;
+
+	pr_debug("In mxc_v4l2_g_std\n");
+
+	if (cam->device_type == 1) {
+		/* Use this function to get what the TV-In device detects the
+		 * format to be. pixelformat is used to return the std value
+		 * since the interface has no vidioc_g_std.*/
+		tv_fmt.type = V4L2_BUF_TYPE_PRIVATE;
+		vidioc_int_g_fmt_cap(cam->sensor, &tv_fmt);
+
+		/* If the TV-in automatically detects the standard, then if it
+		 * changes, the settings need to change. */
+		if (cam->standard_autodetect) {
+			if (cam->standard.id != tv_fmt.fmt.pix.pixelformat) {
+				pr_debug("MVC: mxc_v4l2_g_std: "
+					"Changing standard\n");
+				mxc_v4l2_s_std(cam, tv_fmt.fmt.pix.pixelformat);
+			}
+		}
+
+		*e = tv_fmt.fmt.pix.pixelformat;
+	}
+
+	return 0;
+}
+
+/*!
  * Dequeue one V4L capture buffer
  *
  * @param cam         structure cam_data *
@@ -832,18 +1187,22 @@ static int mxc_v4l2_s_param(cam_data * cam, struct v4l2_streamparm *parm)
  * @return  status    0 success, EINVAL invalid frame number,
  *                    ETIME timeout, ERESTARTSYS interrupted by user
  */
-static int mxc_v4l_dqueue(cam_data * cam, struct v4l2_buffer *buf)
+static int mxc_v4l_dqueue(cam_data *cam, struct v4l2_buffer *buf)
 {
 	int retval = 0;
 	struct mxc_v4l_frame *frame;
 
+	pr_debug("In MVC:mxc_v4l_dqueue\n");
+
 	if (!wait_event_interruptible_timeout(cam->enc_queue,
 					      cam->enc_counter != 0, 10 * HZ)) {
-		printk(KERN_ERR "mxc_v4l_dqueue timeout enc_counter %x\n",
+		pr_err("ERROR: v4l2 capture: mxc_v4l_dqueue timeout "
+			"enc_counter %x\n",
 		       cam->enc_counter);
 		return -ETIME;
 	} else if (signal_pending(current)) {
-		printk(KERN_ERR "mxc_v4l_dqueue() interrupt received\n");
+		pr_err("ERROR: v4l2 capture: mxc_v4l_dqueue() "
+			"interrupt received\n");
 		return -ERESTARTSYS;
 	}
 
@@ -854,11 +1213,13 @@ static int mxc_v4l_dqueue(cam_data * cam, struct v4l2_buffer *buf)
 	if (frame->buffer.flags & V4L2_BUF_FLAG_DONE) {
 		frame->buffer.flags &= ~V4L2_BUF_FLAG_DONE;
 	} else if (frame->buffer.flags & V4L2_BUF_FLAG_QUEUED) {
-		printk(KERN_ERR "VIDIOC_DQBUF: Buffer not filled.\n");
+		pr_err("ERROR: v4l2 capture: VIDIOC_DQBUF: "
+			"Buffer not filled.\n");
 		frame->buffer.flags &= ~V4L2_BUF_FLAG_QUEUED;
 		retval = -EINVAL;
 	} else if ((frame->buffer.flags & 0x7) == V4L2_BUF_FLAG_MAPPED) {
-		printk(KERN_ERR "VIDIOC_DQBUF: Buffer not queued.\n");
+		pr_err("ERROR: v4l2 capture: VIDIOC_DQBUF: "
+			"Buffer not queued.\n");
 		retval = -EINVAL;
 	}
 
@@ -881,19 +1242,23 @@ static int mxc_v4l_dqueue(cam_data * cam, struct v4l2_buffer *buf)
  */
 static int mxc_v4l_open(struct inode *inode, struct file *file)
 {
-	sensor_interface *param;
+	struct v4l2_ifparm ifparm;
+	struct v4l2_format cam_fmt;
 	ipu_csi_signal_cfg_t csi_param;
 	struct video_device *dev = video_devdata(file);
 	cam_data *cam = dev->priv;
 	int err = 0;
 
+	pr_debug("\nIn MVC: mxc_v4l_open\n");
+	pr_debug("   device name is %s\n", dev->name);
+
 	if (!cam) {
-		printk(KERN_ERR "Internal error, cam_data not found!\n");
+		pr_err("ERROR: v4l2 capture: Internal error, "
+			"cam_data not found!\n");
 		return -EBADF;
 	}
 
 	down(&cam->busy_lock);
-
 	err = 0;
 	if (signal_pending(current))
 		goto oops;
@@ -912,46 +1277,95 @@ static int mxc_v4l_open(struct inode *inode, struct file *file)
 		INIT_LIST_HEAD(&cam->working_q);
 		INIT_LIST_HEAD(&cam->done_q);
 
-		ipu_csi_enable_mclk_if(CSI_MCLK_I2C,
-			cam->cam_sensor->csi, true, true);
-		param = cam->cam_sensor->reset();
-		if (param == NULL) {
-			cam->open_count--;
-			ipu_csi_enable_mclk_if(CSI_MCLK_I2C,
-				cam->cam_sensor->csi, false, false);
-			err = -ENODEV;
-			goto oops;
-		}
+		vidioc_int_g_ifparm(cam->sensor, &ifparm);
 
 		csi_param.sens_clksrc = 0;
-		csi_param.clk_mode = param->clk_mode;
-		csi_param.pixclk_pol = param->pixclk_pol;
-		csi_param.data_width = param->data_width;
-		csi_param.data_pol = param->data_pol;
-		csi_param.ext_vsync = param->ext_vsync;
-		csi_param.Vsync_pol = param->Vsync_pol;
-		csi_param.Hsync_pol = param->Hsync_pol;
-		csi_param.data_fmt = param->pixel_fmt;
-		csi_param.pack_tight = param->pack_tight;
-		csi_param.force_eof = param->force_eof;
-		csi_param.data_en_pol = param->data_en_pol;
-		csi_param.csi = cam->cam_sensor->csi;
-		ipu_csi_init_interface(param->width, param->height,
-				       param->pixel_fmt, csi_param);
-
-		cam->cam_sensor->get_color(&cam->bright, &cam->saturation,
-					   &cam->red, &cam->green, &cam->blue);
-		if (cam->cam_sensor->get_ae_mode)
-			cam->cam_sensor->get_ae_mode(&cam->ae_mode);
-
-		/* pr_info("mxc_v4l_open saturation %x ae_mode %x\n",
-		   cam->saturation, cam->ae_mode); */
-
-		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->cam_sensor->csi,
-				false, false);
-	}
+
+		csi_param.clk_mode = 0;
+		csi_param.data_pol = 0;
+		csi_param.ext_vsync = 0;
+
+		csi_param.pack_tight = 0;
+		csi_param.force_eof = 0;
+		csi_param.data_en_pol = 0;
+		csi_param.mclk = ifparm.u.bt656.clock_curr;
+
+		csi_param.pixclk_pol = ifparm.u.bt656.latch_clk_inv;
+
+		/* Once we handle multiple inputs this will need to change. */
+		csi_param.csi = 0;
+
+		if (ifparm.u.bt656.mode
+				== V4L2_IF_TYPE_BT656_MODE_NOBT_8BIT)
+			csi_param.data_width = IPU_CSI_DATA_WIDTH_8;
+		else if (ifparm.u.bt656.mode
+				== V4L2_IF_TYPE_BT656_MODE_NOBT_10BIT)
+			csi_param.data_width = IPU_CSI_DATA_WIDTH_10;
+		else
+			csi_param.data_width = IPU_CSI_DATA_WIDTH_8;
+
+
+		csi_param.Vsync_pol = ifparm.u.bt656.nobt_vs_inv;
+		csi_param.Hsync_pol = ifparm.u.bt656.nobt_hs_inv;
+
+		csi_param.csi = cam->csi;
+
+		cam_fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+		vidioc_int_g_fmt_cap(cam->sensor, &cam_fmt);
+
+		/* Reset the sizes.  Needed to prevent carryover of last
+		 * operation.*/
+		cam->crop_bounds.top = cam->crop_bounds.left = 0;
+		cam->crop_bounds.width = cam_fmt.fmt.pix.width;
+		cam->crop_bounds.height = cam_fmt.fmt.pix.height;
+
+		/* This also is the max crop size for this device. */
+		cam->crop_defrect.top = cam->crop_defrect.left = 0;
+		cam->crop_defrect.width = cam_fmt.fmt.pix.width;
+		cam->crop_defrect.height = cam_fmt.fmt.pix.height;
+
+		/* At this point, this is also the current image size. */
+		cam->crop_current.top = cam->crop_current.left = 0;
+		cam->crop_current.width = cam_fmt.fmt.pix.width;
+		cam->crop_current.height = cam_fmt.fmt.pix.height;
+
+		pr_debug("End of %s: v2f pix widthxheight %d x %d\n",
+			__func__,
+			cam->v2f.fmt.pix.width, cam->v2f.fmt.pix.height);
+		pr_debug("End of %s: crop_bounds widthxheight %d x %d\n",
+			__func__,
+			cam->crop_bounds.width, cam->crop_bounds.height);
+		pr_debug("End of %s: crop_defrect widthxheight %d x %d\n",
+			__func__,
+			cam->crop_defrect.width, cam->crop_defrect.height);
+		pr_debug("End of %s: crop_current widthxheight %d x %d\n",
+			__func__,
+			cam->crop_current.width, cam->crop_current.height);
+
+		csi_param.data_fmt = cam_fmt.fmt.pix.pixelformat;
+		pr_debug("On Open: Input to ipu size is %d x %d\n",
+				cam_fmt.fmt.pix.width, cam_fmt.fmt.pix.height);
+		ipu_csi_set_window_size(cam->crop_current.width,
+					cam->crop_current.width,
+					cam->csi);
+		ipu_csi_set_window_pos(cam->crop_current.left,
+					cam->crop_current.top,
+					cam->csi);
+		ipu_csi_init_interface(cam->crop_bounds.width,
+					cam->crop_bounds.height,
+					cam_fmt.fmt.pix.pixelformat,
+					csi_param);
+
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi,
+				       true, true);
+		vidioc_int_init(cam->sensor);
+
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi,
+				       false, false);
+}
 
 	file->private_data = dev;
+
       oops:
 	up(&cam->busy_lock);
 	return err;
@@ -971,8 +1385,11 @@ static int mxc_v4l_close(struct inode *inode, struct file *file)
 	int err = 0;
 	cam_data *cam = dev->priv;
 
+	pr_debug("In MVC:mxc_v4l_close\n");
+
 	if (!cam) {
-		printk(KERN_ERR "Internal error, cam_data not found!\n");
+		pr_err("ERROR: v4l2 capture: Internal error, "
+			"cam_data not found!\n");
 		return -EBADF;
 	}
 
@@ -1002,6 +1419,7 @@ static int mxc_v4l_close(struct inode *inode, struct file *file)
 		mxc_free_frames(cam);
 		cam->enc_counter++;
 	}
+
 	return err;
 }
 
@@ -1016,8 +1434,8 @@ static int mxc_v4l_close(struct inode *inode, struct file *file)
  *
  * @return           bytes read
  */
-static ssize_t
-mxc_v4l_read(struct file *file, char *buf, size_t count, loff_t * ppos)
+static ssize_t mxc_v4l_read(struct file *file, char *buf, size_t count,
+			    loff_t *ppos)
 {
 	int err = 0;
 	u8 *v_address;
@@ -1056,7 +1474,7 @@ mxc_v4l_read(struct file *file, char *buf, size_t count, loff_t * ppos)
 	if (!wait_event_interruptible_timeout(cam->still_queue,
 					      cam->still_counter != 0,
 					      10 * HZ)) {
-		printk(KERN_ERR "mxc_v4l_read timeout counter %x\n",
+		pr_err("ERROR: v4l2 capture: mxc_v4l_read timeout counter %x\n",
 		       cam->still_counter);
 		err = -ETIME;
 		goto exit2;
@@ -1087,392 +1505,404 @@ mxc_v4l_read(struct file *file, char *buf, size_t count, loff_t * ppos)
 /*!
  * V4L interface - ioctl function
  *
- * @param inode      struct inode *
+ * @param inode      struct inode*
  *
- * @param file       struct file *
+ * @param file       struct file*
  *
  * @param ioctlnr    unsigned int
  *
- * @param arg        void *
+ * @param arg        void*
  *
  * @return           0 success, ENODEV for invalid device instance,
  *                   -1 for other errors.
  */
-static int
-mxc_v4l_do_ioctl(struct inode *inode, struct file *file,
-		 unsigned int ioctlnr, void *arg)
+static int mxc_v4l_do_ioctl(struct inode *inode, struct file *file,
+			    unsigned int ioctlnr, void *arg)
 {
 	struct video_device *dev = video_devdata(file);
 	cam_data *cam = dev->priv;
 	int retval = 0;
 	unsigned long lock_flags;
 
+	pr_debug("In MVC: mxc_v4l_do_ioctl %x\n", ioctlnr);
 	wait_event_interruptible(cam->power_queue, cam->low_power == false);
 	/* make this _really_ smp-safe */
 	if (down_interruptible(&cam->busy_lock))
 		return -EBUSY;
 
 	switch (ioctlnr) {
-		/*!
-		 * V4l2 VIDIOC_QUERYCAP ioctl
-		 */
-	case VIDIOC_QUERYCAP:{
-			struct v4l2_capability *cap = arg;
-			strcpy(cap->driver, "mxc_v4l2");
-			cap->version = KERNEL_VERSION(0, 1, 11);
-			cap->capabilities = V4L2_CAP_VIDEO_CAPTURE |
-			    V4L2_CAP_VIDEO_OVERLAY | V4L2_CAP_STREAMING
-			    | V4L2_CAP_READWRITE;
-			cap->card[0] = '\0';
-			cap->bus_info[0] = '\0';
-			retval = 0;
-			break;
-		}
+	/*!
+	 * V4l2 VIDIOC_QUERYCAP ioctl
+	 */
+	case VIDIOC_QUERYCAP: {
+		struct v4l2_capability *cap = arg;
+		pr_debug("   case VIDIOC_QUERYCAP\n");
+		strcpy(cap->driver, "mxc_v4l2");
+		cap->version = KERNEL_VERSION(0, 1, 11);
+		cap->capabilities = V4L2_CAP_VIDEO_CAPTURE |
+				    V4L2_CAP_VIDEO_OVERLAY |
+				    V4L2_CAP_STREAMING |
+				    V4L2_CAP_READWRITE;
+		cap->card[0] = '\0';
+		cap->bus_info[0] = '\0';
+		break;
+	}
 
-		/*!
-		 * V4l2 VIDIOC_G_FMT ioctl
-		 */
-	case VIDIOC_G_FMT:{
-			struct v4l2_format *gf = arg;
-			retval = mxc_v4l2_g_fmt(cam, gf);
-			break;
+	/*!
+	 * V4l2 VIDIOC_G_FMT ioctl
+	 */
+	case VIDIOC_G_FMT: {
+		struct v4l2_format *gf = arg;
+		pr_debug("   case VIDIOC_G_FMT\n");
+		retval = mxc_v4l2_g_fmt(cam, gf);
+		break;
+	}
+
+	/*!
+	 * V4l2 VIDIOC_S_FMT ioctl
+	 */
+	case VIDIOC_S_FMT: {
+		struct v4l2_format *sf = arg;
+		pr_debug("   case VIDIOC_S_FMT\n");
+		retval = mxc_v4l2_s_fmt(cam, sf);
+		break;
+	}
+
+	/*!
+	 * V4l2 VIDIOC_REQBUFS ioctl
+	 */
+	case VIDIOC_REQBUFS: {
+		struct v4l2_requestbuffers *req = arg;
+		pr_debug("   case VIDIOC_REQBUFS\n");
+
+		if (req->count > FRAME_NUM) {
+			pr_err("ERROR: v4l2 capture: VIDIOC_REQBUFS: "
+			       "not enough buffers\n");
+			req->count = FRAME_NUM;
 		}
 
-		/*!
-		 * V4l2 VIDIOC_S_FMT ioctl
-		 */
-	case VIDIOC_S_FMT:{
-			struct v4l2_format *sf = arg;
-			retval = mxc_v4l2_s_fmt(cam, sf);
+		if ((req->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) ||
+		    (req->memory != V4L2_MEMORY_MMAP)) {
+			pr_err("ERROR: v4l2 capture: VIDIOC_REQBUFS: "
+			       "wrong buffer type\n");
+			retval = -EINVAL;
 			break;
 		}
 
-		/*!
-		 * V4l2 VIDIOC_REQBUFS ioctl
-		 */
-	case VIDIOC_REQBUFS:{
-			struct v4l2_requestbuffers *req = arg;
-			if (req->count > FRAME_NUM) {
-				printk(KERN_ERR
-				       "VIDIOC_REQBUFS: not enough buffer\n");
-				req->count = FRAME_NUM;
-			}
-
-			if ((req->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) ||
-			    (req->memory != V4L2_MEMORY_MMAP)) {
-				printk(KERN_ERR
-				       "VIDIOC_REQBUFS: wrong buffer type\n");
-				retval = -EINVAL;
-				break;
-			}
+		mxc_streamoff(cam);
+		mxc_free_frame_buf(cam);
+		cam->enc_counter = 0;
+		cam->skip_frame = 0;
+		INIT_LIST_HEAD(&cam->ready_q);
+		INIT_LIST_HEAD(&cam->working_q);
+		INIT_LIST_HEAD(&cam->done_q);
 
-			mxc_streamoff(cam);
-			mxc_free_frame_buf(cam);
-			cam->enc_counter = 0;
-			cam->skip_frame = 0;
-			INIT_LIST_HEAD(&cam->ready_q);
-			INIT_LIST_HEAD(&cam->working_q);
-			INIT_LIST_HEAD(&cam->done_q);
+		retval = mxc_allocate_frame_buf(cam, req->count);
+		break;
+	}
 
-			retval = mxc_allocate_frame_buf(cam, req->count);
+	/*!
+	 * V4l2 VIDIOC_QUERYBUF ioctl
+	 */
+	case VIDIOC_QUERYBUF: {
+		struct v4l2_buffer *buf = arg;
+		int index = buf->index;
+		pr_debug("   case VIDIOC_QUERYBUF\n");
+
+		if (buf->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) {
+			pr_err("ERROR: v4l2 capture: "
+			       "VIDIOC_QUERYBUFS: "
+			       "wrong buffer type\n");
+			retval = -EINVAL;
 			break;
 		}
 
-		/*!
-		 * V4l2 VIDIOC_QUERYBUF ioctl
-		 */
-	case VIDIOC_QUERYBUF:{
-			struct v4l2_buffer *buf = arg;
-			int index = buf->index;
-
-			if (buf->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) {
-				printk(KERN_ERR
-				       "VIDIOC_QUERYBUFS: wrong buffer type\n");
-				retval = -EINVAL;
-				break;
-			}
+		memset(buf, 0, sizeof(buf));
+		buf->index = index;
 
-			memset(buf, 0, sizeof(buf));
-			buf->index = index;
-
-			down(&cam->param_lock);
-			retval = mxc_v4l2_buffer_status(cam, buf);
-			up(&cam->param_lock);
-			break;
-		}
+		down(&cam->param_lock);
+		retval = mxc_v4l2_buffer_status(cam, buf);
+		up(&cam->param_lock);
+		break;
+	}
 
-		/*!
-		 * V4l2 VIDIOC_QBUF ioctl
-		 */
-	case VIDIOC_QBUF:{
-			struct v4l2_buffer *buf = arg;
-			int index = buf->index;
-
-			spin_lock_irqsave(&cam->int_lock, lock_flags);
-			cam->frame[index].buffer.m.offset = buf->m.offset;
-			if ((cam->frame[index].buffer.flags & 0x7) ==
-			    V4L2_BUF_FLAG_MAPPED) {
-				cam->frame[index].buffer.flags |=
-				    V4L2_BUF_FLAG_QUEUED;
-				if (cam->skip_frame > 0) {
-					list_add_tail(&cam->frame[index].queue,
-						      &cam->working_q);
-					retval =
-					    cam->enc_update_eba(cam->
-								frame[index].
-								buffer.m.offset,
-								&cam->
-								ping_pong_csi);
-					cam->skip_frame = 0;
-				} else {
-					list_add_tail(&cam->frame[index].queue,
-						      &cam->ready_q);
-				}
-			} else if (cam->frame[index].buffer.
-				   flags & V4L2_BUF_FLAG_QUEUED) {
-				printk(KERN_ERR
-				       "VIDIOC_QBUF: buffer already queued\n");
-			} else if (cam->frame[index].buffer.
-				   flags & V4L2_BUF_FLAG_DONE) {
-				printk(KERN_ERR
-				       "VIDIOC_QBUF: overwrite done buffer.\n");
-				cam->frame[index].buffer.flags &=
-				    ~V4L2_BUF_FLAG_DONE;
-				cam->frame[index].buffer.flags |=
-				    V4L2_BUF_FLAG_QUEUED;
+	/*!
+	 * V4l2 VIDIOC_QBUF ioctl
+	 */
+	case VIDIOC_QBUF: {
+		struct v4l2_buffer *buf = arg;
+		int index = buf->index;
+		pr_debug("   case VIDIOC_QBUF\n");
+
+		spin_lock_irqsave(&cam->int_lock, lock_flags);
+		cam->frame[index].buffer.m.offset = buf->m.offset;
+		if ((cam->frame[index].buffer.flags & 0x7) ==
+		    V4L2_BUF_FLAG_MAPPED) {
+			cam->frame[index].buffer.flags |=
+			    V4L2_BUF_FLAG_QUEUED;
+			if (cam->skip_frame > 0) {
+				list_add_tail(&cam->frame[index].queue,
+					      &cam->working_q);
+				retval =
+				    cam->enc_update_eba(cam->
+							frame[index].
+							buffer.m.offset,
+							&cam->
+							ping_pong_csi);
+				cam->skip_frame = 0;
+			} else {
+				list_add_tail(&cam->frame[index].queue,
+					      &cam->ready_q);
 			}
-
-			buf->flags = cam->frame[index].buffer.flags;
-			spin_unlock_irqrestore(&cam->int_lock, lock_flags);
-			break;
+		} else if (cam->frame[index].buffer.
+			   flags & V4L2_BUF_FLAG_QUEUED) {
+			pr_err("ERROR: v4l2 capture: VIDIOC_QBUF: "
+			       "buffer already queued\n");
+		} else if (cam->frame[index].buffer.
+			   flags & V4L2_BUF_FLAG_DONE) {
+			pr_err("ERROR: v4l2 capture: VIDIOC_QBUF: "
+			       "overwrite done buffer.\n");
+			cam->frame[index].buffer.flags &=
+			    ~V4L2_BUF_FLAG_DONE;
+			cam->frame[index].buffer.flags |=
+			    V4L2_BUF_FLAG_QUEUED;
 		}
 
-		/*!
-		 * V4l2 VIDIOC_DQBUF ioctl
-		 */
-	case VIDIOC_DQBUF:{
-			struct v4l2_buffer *buf = arg;
+		buf->flags = cam->frame[index].buffer.flags;
+		spin_unlock_irqrestore(&cam->int_lock, lock_flags);
+		break;
+	}
 
-			retval = mxc_v4l_dqueue(cam, buf);
+	/*!
+	 * V4l2 VIDIOC_DQBUF ioctl
+	 */
+	case VIDIOC_DQBUF: {
+		struct v4l2_buffer *buf = arg;
+		pr_debug("   case VIDIOC_DQBUF\n");
 
-			break;
-		}
+		retval = mxc_v4l_dqueue(cam, buf);
 
-		/*!
-		 * V4l2 VIDIOC_STREAMON ioctl
-		 */
-	case VIDIOC_STREAMON:{
-			retval = mxc_streamon(cam);
-			break;
-		}
+		break;
+	}
 
-		/*!
-		 * V4l2 VIDIOC_STREAMOFF ioctl
-		 */
-	case VIDIOC_STREAMOFF:{
-			retval = mxc_streamoff(cam);
-			break;
-		}
+	/*!
+	 * V4l2 VIDIOC_STREAMON ioctl
+	 */
+	case VIDIOC_STREAMON: {
+		pr_debug("   case VIDIOC_STREAMON\n");
+		retval = mxc_streamon(cam);
+		break;
+	}
 
-		/*!
-		 * V4l2 VIDIOC_G_CTRL ioctl
-		 */
-	case VIDIOC_G_CTRL:{
-			retval = mxc_get_v42l_control(cam, arg);
-			break;
-		}
+	/*!
+	 * V4l2 VIDIOC_STREAMOFF ioctl
+	 */
+	case VIDIOC_STREAMOFF: {
+		pr_debug("   case VIDIOC_STREAMOFF\n");
+		retval = mxc_streamoff(cam);
+		break;
+	}
 
-		/*!
-		 * V4l2 VIDIOC_S_CTRL ioctl
-		 */
-	case VIDIOC_S_CTRL:{
-			retval = mxc_set_v42l_control(cam, arg);
-			break;
-		}
+	/*!
+	 * V4l2 VIDIOC_G_CTRL ioctl
+	 */
+	case VIDIOC_G_CTRL: {
+		pr_debug("   case VIDIOC_G_CTRL\n");
+		retval = mxc_v4l2_g_ctrl(cam, arg);
+		break;
+	}
 
-		/*!
-		 * V4l2 VIDIOC_CROPCAP ioctl
-		 */
-	case VIDIOC_CROPCAP:{
-			struct v4l2_cropcap *cap = arg;
+	/*!
+	 * V4l2 VIDIOC_S_CTRL ioctl
+	 */
+	case VIDIOC_S_CTRL: {
+		pr_debug("   case VIDIOC_S_CTRL\n");
+		retval = mxc_v4l2_s_ctrl(cam, arg);
+		break;
+	}
 
-			if (cap->type != V4L2_BUF_TYPE_VIDEO_CAPTURE &&
-			    cap->type != V4L2_BUF_TYPE_VIDEO_OVERLAY) {
-				retval = -EINVAL;
-				break;
-			}
-			cap->bounds = cam->crop_bounds;
-			cap->defrect = cam->crop_defrect;
+	/*!
+	 * V4l2 VIDIOC_CROPCAP ioctl
+	 */
+	case VIDIOC_CROPCAP: {
+		struct v4l2_cropcap *cap = arg;
+		pr_debug("   case VIDIOC_CROPCAP\n");
+		if (cap->type != V4L2_BUF_TYPE_VIDEO_CAPTURE &&
+		    cap->type != V4L2_BUF_TYPE_VIDEO_OVERLAY) {
+			retval = -EINVAL;
 			break;
 		}
+		cap->bounds = cam->crop_bounds;
+		cap->defrect = cam->crop_defrect;
+		break;
+	}
 
-		/*!
-		 * V4l2 VIDIOC_G_CROP ioctl
-		 */
-	case VIDIOC_G_CROP:{
-			struct v4l2_crop *crop = arg;
+	/*!
+	 * V4l2 VIDIOC_G_CROP ioctl
+	 */
+	case VIDIOC_G_CROP: {
+		struct v4l2_crop *crop = arg;
+		pr_debug("   case VIDIOC_G_CROP\n");
 
-			if (crop->type != V4L2_BUF_TYPE_VIDEO_CAPTURE &&
-			    crop->type != V4L2_BUF_TYPE_VIDEO_OVERLAY) {
-				retval = -EINVAL;
-				break;
-			}
-			crop->c = cam->crop_current;
+		if (crop->type != V4L2_BUF_TYPE_VIDEO_CAPTURE &&
+		    crop->type != V4L2_BUF_TYPE_VIDEO_OVERLAY) {
+			retval = -EINVAL;
 			break;
 		}
+		crop->c = cam->crop_current;
+		break;
+	}
 
-		/*!
-		 * V4l2 VIDIOC_S_CROP ioctl
-		 */
-	case VIDIOC_S_CROP:{
-			struct v4l2_crop *crop = arg;
-			struct v4l2_rect *b = &cam->crop_bounds;
-
-			if (crop->type != V4L2_BUF_TYPE_VIDEO_CAPTURE &&
-			    crop->type != V4L2_BUF_TYPE_VIDEO_OVERLAY) {
-				retval = -EINVAL;
-				break;
-			}
-
-			crop->c.top = (crop->c.top < b->top) ? b->top
-			    : crop->c.top;
-			if (crop->c.top > b->top + b->height)
-				crop->c.top = b->top + b->height - 1;
-			if (crop->c.height > b->top + b->height - crop->c.top)
-				crop->c.height =
-				    b->top + b->height - crop->c.top;
-
-			crop->c.left = (crop->c.left < b->left) ? b->left
-			    : crop->c.left;
-			if (crop->c.left > b->left + b->width)
-				crop->c.left = b->left + b->width - 1;
-			if (crop->c.width > b->left - crop->c.left + b->width)
-				crop->c.width =
-				    b->left - crop->c.left + b->width;
-
-			crop->c.width -= crop->c.width % 8;
-			crop->c.left -= crop->c.left % 4;
-			cam->crop_current = crop->c;
-
-			ipu_csi_set_window_size(cam->crop_current.width,
-						cam->crop_current.height,
-						cam->cam_sensor->csi);
-			ipu_csi_set_window_pos(cam->crop_current.left,
-					       cam->crop_current.top,
-						cam->cam_sensor->csi);
+	/*!
+	 * V4l2 VIDIOC_S_CROP ioctl
+	 */
+	case VIDIOC_S_CROP: {
+		struct v4l2_crop *crop = arg;
+		struct v4l2_rect *b = &cam->crop_bounds;
+		pr_debug("   case VIDIOC_S_CROP\n");
+
+		if (crop->type != V4L2_BUF_TYPE_VIDEO_CAPTURE &&
+		    crop->type != V4L2_BUF_TYPE_VIDEO_OVERLAY) {
+			retval = -EINVAL;
 			break;
 		}
 
-		/*!
-		 * V4l2 VIDIOC_OVERLAY ioctl
-		 */
-	case VIDIOC_OVERLAY:{
-			int *on = arg;
-			if (*on) {
-				cam->overlay_on = true;
-				cam->overlay_pid = current->pid;
-				retval = start_preview(cam);
-			}
-			if (!*on) {
-				retval = stop_preview(cam);
-				cam->overlay_on = false;
-			}
-			break;
-		}
+		crop->c.top = (crop->c.top < b->top) ? b->top
+			      : crop->c.top;
+		if (crop->c.top > b->top + b->height)
+			crop->c.top = b->top + b->height - 1;
+		if (crop->c.height > b->top + b->height - crop->c.top)
+			crop->c.height =
+				b->top + b->height - crop->c.top;
+
+		crop->c.left = (crop->c.left < b->left) ? b->left
+		    : crop->c.left;
+		if (crop->c.left > b->left + b->width)
+			crop->c.left = b->left + b->width - 1;
+		if (crop->c.width > b->left - crop->c.left + b->width)
+			crop->c.width =
+				b->left - crop->c.left + b->width;
+
+		crop->c.width -= crop->c.width % 8;
+		crop->c.left -= crop->c.left % 4;
+		cam->crop_current = crop->c;
+
+		pr_debug("   Cropping Input to ipu size %d x %d\n",
+				cam->crop_current.width,
+				cam->crop_current.height);
+		ipu_csi_set_window_size(cam->crop_current.width,
+					cam->crop_current.height,
+					cam->csi);
+		ipu_csi_set_window_pos(cam->crop_current.left,
+				       cam->crop_current.top,
+				       cam->csi);
+		break;
+	}
 
-		/*!
-		 * V4l2 VIDIOC_G_FBUF ioctl
-		 */
-	case VIDIOC_G_FBUF:{
-			struct v4l2_framebuffer *fb = arg;
-			*fb = cam->v4l2_fb;
-			fb->capability = V4L2_FBUF_CAP_EXTERNOVERLAY;
-			break;
+	/*!
+	 * V4l2 VIDIOC_OVERLAY ioctl
+	 */
+	case VIDIOC_OVERLAY: {
+		int *on = arg;
+		pr_debug("   VIDIOC_OVERLAY on=%d\n", *on);
+		if (*on) {
+			cam->overlay_on = true;
+			cam->overlay_pid = current->pid;
+			retval = start_preview(cam);
 		}
-
-		/*!
-		 * V4l2 VIDIOC_S_FBUF ioctl
-		 */
-	case VIDIOC_S_FBUF:{
-			struct v4l2_framebuffer *fb = arg;
-			cam->v4l2_fb = *fb;
-			break;
+		if (!*on) {
+			retval = stop_preview(cam);
+			cam->overlay_on = false;
 		}
+		break;
+	}
 
-	case VIDIOC_G_PARM:{
-			struct v4l2_streamparm *parm = arg;
-			if (parm->type != V4L2_BUF_TYPE_VIDEO_CAPTURE) {
-				printk(KERN_ERR "VIDIOC_G_PARM invalid type\n");
-				retval = -EINVAL;
-				break;
-			}
-			parm->parm.capture = cam->streamparm.parm.capture;
-			break;
-		}
-	case VIDIOC_S_PARM:{
-			struct v4l2_streamparm *parm = arg;
-			retval = mxc_v4l2_s_param(cam, parm);
-			break;
-		}
+	/*!
+	 * V4l2 VIDIOC_G_FBUF ioctl
+	 */
+	case VIDIOC_G_FBUF: {
+		struct v4l2_framebuffer *fb = arg;
+		pr_debug("   case VIDIOC_G_FBUF\n");
+		*fb = cam->v4l2_fb;
+		fb->capability = V4L2_FBUF_CAP_EXTERNOVERLAY;
+		break;
+	}
 
-		/* linux v4l2 bug, kernel c0485619 user c0405619 */
-	case VIDIOC_ENUMSTD:{
-			struct v4l2_standard *e = arg;
-			*e = cam->standard;
-			printk(KERN_ERR "VIDIOC_ENUMSTD call\n");
-			retval = 0;
-			break;
-		}
+	/*!
+	 * V4l2 VIDIOC_S_FBUF ioctl
+	 */
+	case VIDIOC_S_FBUF: {
+		struct v4l2_framebuffer *fb = arg;
+		pr_debug("   case VIDIOC_S_FBUF\n");
+		cam->v4l2_fb = *fb;
+		break;
+	}
 
-	case VIDIOC_G_STD:{
-			v4l2_std_id *e = arg;
-			*e = cam->standard.id;
-			if (cam->cam_sensor->get_std)
-				cam->cam_sensor->get_std(e);
-			retval = 0;
-			break;
-		}
+	case VIDIOC_G_PARM: {
+		struct v4l2_streamparm *parm = arg;
+		pr_debug("   case VIDIOC_G_PARM\n");
+		vidioc_int_g_parm(cam->sensor, parm);
+		break;
+	}
 
-	case VIDIOC_S_STD:{
-			v4l2_std_id * e = arg;
-			if (cam->cam_sensor->set_std)
-				cam->cam_sensor->set_std(*e);
-			retval = 0;
-			break;
-		}
+	case VIDIOC_S_PARM:  {
+		struct v4l2_streamparm *parm = arg;
+		pr_debug("   case VIDIOC_S_PARM\n");
+		retval = mxc_v4l2_s_param(cam, parm);
+		break;
+	}
 
-	case VIDIOC_ENUMOUTPUT:
-		{
-			struct v4l2_output *output = arg;
+	/* linux v4l2 bug, kernel c0485619 user c0405619 */
+	case VIDIOC_ENUMSTD: {
+		struct v4l2_standard *e = arg;
+		pr_debug("   case VIDIOC_ENUMSTD\n");
+		*e = cam->standard;
+		break;
+	}
 
-			if (output->index >= MXC_V4L2_CAPTURE_NUM_OUTPUTS) {
-				retval = -EINVAL;
-				break;
-			}
+	case VIDIOC_G_STD: {
+		v4l2_std_id *e = arg;
+		pr_debug("   case VIDIOC_G_STD\n");
+		retval = mxc_v4l2_g_std(cam, e);
+		break;
+	}
 
-			*output = mxc_capture_outputs[output->index];
+	case VIDIOC_S_STD: {
+		v4l2_std_id *e = arg;
+		pr_debug("   case VIDIOC_S_STD\n");
+		retval = mxc_v4l2_s_std(cam, *e);
 
-			break;
-		}
-	case VIDIOC_G_OUTPUT:
-		{
-			int *p_output_num = arg;
+		break;
+	}
 
-			*p_output_num = cam->output;
+	case VIDIOC_ENUMOUTPUT: {
+		struct v4l2_output *output = arg;
+		pr_debug("   case VIDIOC_ENUMOUTPUT\n");
+		if (output->index >= MXC_V4L2_CAPTURE_NUM_OUTPUTS) {
+			retval = -EINVAL;
 			break;
 		}
-	case VIDIOC_S_OUTPUT:
-		{
-			int *p_output_num = arg;
+		*output = mxc_capture_outputs[output->index];
 
-			if (*p_output_num >= MXC_V4L2_CAPTURE_NUM_OUTPUTS) {
-				retval = -EINVAL;
-				break;
-			}
+		break;
+	}
+	case VIDIOC_G_OUTPUT: {
+		int *p_output_num = arg;
+		pr_debug("   case VIDIOC_G_OUTPUT\n");
+		*p_output_num = cam->output;
+		break;
+	}
 
-			cam->output = *p_output_num;
+	case VIDIOC_S_OUTPUT: {
+		int *p_output_num = arg;
+		pr_debug("   case VIDIOC_S_OUTPUT\n");
+		if (*p_output_num >= MXC_V4L2_CAPTURE_NUM_OUTPUTS) {
+			retval = -EINVAL;
 			break;
 		}
+		cam->output = *p_output_num;
+		break;
+	}
 
 	case VIDIOC_ENUM_FMT:
 	case VIDIOC_TRY_FMT:
@@ -1485,6 +1915,7 @@ mxc_v4l_do_ioctl(struct inode *inode, struct file *file,
 	case VIDIOC_G_FREQUENCY:
 	case VIDIOC_S_FREQUENCY:
 	default:
+		pr_debug("   case default or not supported\n");
 		retval = -EINVAL;
 		break;
 	}
@@ -1498,10 +1929,10 @@ mxc_v4l_do_ioctl(struct inode *inode, struct file *file,
  *
  * @return  None
  */
-static int
-mxc_v4l_ioctl(struct inode *inode, struct file *file,
-	      unsigned int cmd, unsigned long arg)
+static int mxc_v4l_ioctl(struct inode *inode, struct file *file,
+			 unsigned int cmd, unsigned long arg)
 {
+	pr_debug("In MVC:mxc_v4l_ioctl\n");
 	return video_usercopy(inode, file, cmd, arg, mxc_v4l_do_ioctl);
 }
 
@@ -1521,7 +1952,8 @@ static int mxc_mmap(struct file *file, struct vm_area_struct *vma)
 	int res = 0;
 	cam_data *cam = dev->priv;
 
-	pr_debug("pgoff=0x%lx, start=0x%lx, end=0x%lx\n",
+	pr_debug("In MVC:mxc_mmap\n");
+	pr_debug("   pgoff=0x%lx, start=0x%lx, end=0x%lx\n",
 		 vma->vm_pgoff, vma->vm_start, vma->vm_end);
 
 	/* make this _really_ smp-safe */
@@ -1533,7 +1965,8 @@ static int mxc_mmap(struct file *file, struct vm_area_struct *vma)
 
 	if (remap_pfn_range(vma, vma->vm_start,
 			    vma->vm_pgoff, size, vma->vm_page_prot)) {
-		printk(KERN_ERR "mxc_mmap: remap_pfn_range failed\n");
+		pr_err("ERROR: v4l2 capture: mxc_mmap: "
+			"remap_pfn_range failed\n");
 		res = -ENOBUFS;
 		goto mxc_mmap_exit;
 	}
@@ -1554,13 +1987,15 @@ static int mxc_mmap(struct file *file, struct vm_area_struct *vma)
  *
  * @return  status   POLLIN | POLLRDNORM
  */
-static unsigned int mxc_poll(struct file *file, poll_table * wait)
+static unsigned int mxc_poll(struct file *file, poll_table *wait)
 {
 	struct video_device *dev = video_devdata(file);
 	cam_data *cam = dev->priv;
 	wait_queue_head_t *queue = NULL;
 	int res = POLLIN | POLLRDNORM;
 
+	pr_debug("In MVC:mxc_poll\n");
+
 	if (down_interruptible(&cam->busy_lock))
 		return -EINTR;
 
@@ -1568,11 +2003,14 @@ static unsigned int mxc_poll(struct file *file, poll_table * wait)
 	poll_wait(file, queue, wait);
 
 	up(&cam->busy_lock);
+
 	return res;
 }
 
-static struct
-file_operations mxc_v4l_fops = {
+/*!
+ * This structure defines the functions to be called in this driver.
+ */
+static struct file_operations mxc_v4l_fops = {
 	.owner = THIS_MODULE,
 	.open = mxc_v4l_open,
 	.release = mxc_v4l_close,
@@ -1591,6 +2029,9 @@ static struct video_device mxc_v4l_template = {
 	.release = video_device_release,
 };
 
+/*!
+ * This function can be used to release any platform data on closing.
+ */
 static void camera_platform_release(struct device *device)
 {
 }
@@ -1604,17 +2045,15 @@ static struct platform_device mxc_v4l2_devices = {
 	.id = 0,
 };
 
-extern struct camera_sensor camera_sensor_if;
-
 /*!
-* Camera V4l2 callback function.
-*
-* @param mask      u32
-*
-* @param dev       void device structure
-*
-* @return status
-*/
+ * Camera V4l2 callback function.
+ *
+ * @param mask      u32
+ *
+ * @param dev       void device structure
+ *
+ * @return status
+ */
 static void camera_callback(u32 mask, void *dev)
 {
 	struct mxc_v4l_frame *done_frame;
@@ -1624,13 +2063,16 @@ static void camera_callback(u32 mask, void *dev)
 	if (cam == NULL)
 		return;
 
+	pr_debug("In MVC:camera_callback\n");
+
 	if (list_empty(&cam->working_q)) {
-		printk(KERN_ERR "camera_callback: working queue empty\n");
+		pr_err("ERROR: v4l2 capture: camera_callback: "
+			"working queue empty\n");
 		return;
 	}
 
 	done_frame =
-	    list_entry(cam->working_q.next, struct mxc_v4l_frame, queue);
+		list_entry(cam->working_q.next, struct mxc_v4l_frame, queue);
 	if (done_frame->buffer.flags & V4L2_BUF_FLAG_QUEUED) {
 		done_frame->buffer.flags |= V4L2_BUF_FLAG_DONE;
 		done_frame->buffer.flags &= ~V4L2_BUF_FLAG_QUEUED;
@@ -1638,9 +2080,9 @@ static void camera_callback(u32 mask, void *dev)
 		if (list_empty(&cam->ready_q)) {
 			cam->skip_frame++;
 		} else {
-			ready_frame =
-			    list_entry(cam->ready_q.next, struct mxc_v4l_frame,
-				       queue);
+			ready_frame = list_entry(cam->ready_q.next,
+						 struct mxc_v4l_frame,
+						 queue);
 			list_del(cam->ready_q.next);
 			list_add_tail(&ready_frame->queue, &cam->working_q);
 			cam->enc_update_eba(ready_frame->buffer.m.offset,
@@ -1655,7 +2097,8 @@ static void camera_callback(u32 mask, void *dev)
 		cam->enc_counter++;
 		wake_up_interruptible(&cam->enc_queue);
 	} else {
-		printk(KERN_ERR "camera_callback :buffer not queued\n");
+		pr_err("ERROR: v4l2 capture: camera_callback: "
+			"buffer not queued\n");
 	}
 }
 
@@ -1666,8 +2109,10 @@ static void camera_callback(u32 mask, void *dev)
  *
  * @return status  0 Success
  */
-static void init_camera_struct(cam_data * cam)
+static void init_camera_struct(cam_data *cam)
 {
+	pr_debug("In MVC: init_camera_struct\n");
+
 	/* Default everything to 0 */
 	memset(cam, 0, sizeof(cam_data));
 
@@ -1687,8 +2132,6 @@ static void init_camera_struct(cam_data * cam)
 	init_waitqueue_head(&cam->enc_queue);
 	init_waitqueue_head(&cam->still_queue);
 
-	cam->cam_sensor = &camera_sensor_if;
-
 	/* setup cropping */
 	cam->crop_bounds.left = 0;
 	cam->crop_bounds.width = 640;
@@ -1696,9 +2139,9 @@ static void init_camera_struct(cam_data * cam)
 	cam->crop_bounds.height = 480;
 	cam->crop_current = cam->crop_defrect = cam->crop_bounds;
 	ipu_csi_set_window_size(cam->crop_current.width,
-				cam->crop_current.height, cam->cam_sensor->csi);
+				cam->crop_current.height, cam->csi);
 	ipu_csi_set_window_pos(cam->crop_current.left,
-		cam->crop_current.top, cam->cam_sensor->csi);
+				cam->crop_current.top, cam->csi);
 	cam->streamparm.parm.capture.capturemode = 0;
 
 	cam->standard.index = 0;
@@ -1706,6 +2149,7 @@ static void init_camera_struct(cam_data * cam)
 	cam->standard.frameperiod.denominator = 30;
 	cam->standard.frameperiod.numerator = 1;
 	cam->standard.framelines = 480;
+	cam->standard_autodetect = true;
 	cam->streamparm.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
 	cam->streamparm.parm.capture.timeperframe = cam->standard.frameperiod;
 	cam->streamparm.parm.capture.capability = V4L2_CAP_TIMEPERFRAME;
@@ -1724,58 +2168,42 @@ static void init_camera_struct(cam_data * cam)
 	cam->win.w.left = 0;
 	cam->win.w.top = 0;
 
+	cam->csi = 0;  /* Need to determine how to set this correctly with
+			* multiple video input devices. */
+
 	cam->enc_callback = camera_callback;
 	init_waitqueue_head(&cam->power_queue);
 	cam->int_lock = SPIN_LOCK_UNLOCKED;
 	spin_lock_init(&cam->int_lock);
 }
 
-#ifdef CONFIG_MXC_IPU_V1
-extern void gpio_sensor_active(void);
-extern void gpio_sensor_inactive(void);
-#else
-extern void gpio_sensor_active(unsigned int csi);
-extern void gpio_sensor_inactive(unsigned int csi);
-#endif
-
 /*!
  * camera_power function
- *    Turn Sensor power On/Off
+ *    Turns Sensor power On/Off
  *
  * @param       cam           cam data struct
- * @param       cameraOn      true to turn camera on, otherwise shut down
+ * @param       cameraOn      true to turn camera on, false to turn off power.
  *
  * @return status
  */
 static u8 camera_power(cam_data *cam, bool cameraOn)
 {
-#ifdef CONFIG_MXC_IPU_V1
-	if (cameraOn == true) {
-		gpio_sensor_active();
-		ipu_csi_enable_mclk_if(csi_mclk_flag_backup,
-			cam->cam_sensor->csi, true, true);
-	} else {
-		csi_mclk_flag_backup = ipu_csi_read_mclk_flag();
-		ipu_csi_enable_mclk_if(csi_mclk_flag_backup,
-			cam->cam_sensor->csi, false, false);
-		gpio_sensor_inactive();
-	}
-#else
+	pr_debug("In MVC:camera_power on=%d\n", cameraOn);
+
 	if (cameraOn == true) {
-		gpio_sensor_active(cam->cam_sensor->csi);
-		ipu_csi_enable_mclk_if(0, cam->cam_sensor->csi, true, true);
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, true, true);
+		vidioc_int_s_power(cam->sensor, 1);
 	} else {
-		ipu_csi_enable_mclk_if(0, cam->cam_sensor->csi, false, false);
-		gpio_sensor_inactive(cam->cam_sensor->csi);
+		ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, false, false);
+		vidioc_int_s_power(cam->sensor, 0);
 	}
-#endif
 	return 0;
 }
 
 /*!
- * This function is called to put the sensor in a low power state. Refer to the
- * document driver-model/driver.txt in the kernel source tree for more
- * information.
+ * This function is called to put the sensor in a low power state.
+ * Refer to the document driver-model/driver.txt in the kernel source tree
+ * for more information.
  *
  * @param   pdev  the device structure used to give information on which I2C
  *                to suspend
@@ -1787,6 +2215,8 @@ static int mxc_v4l2_suspend(struct platform_device *pdev, pm_message_t state)
 {
 	cam_data *cam = platform_get_drvdata(pdev);
 
+	pr_debug("In MVC:mxc_v4l2_suspend\n");
+
 	if (cam == NULL) {
 		return -1;
 	}
@@ -1804,9 +2234,9 @@ static int mxc_v4l2_suspend(struct platform_device *pdev, pm_message_t state)
 }
 
 /*!
- * This function is called to bring the sensor back from a low power state.Refer
- * to the document driver-model/driver.txt in the kernel source tree for more
- * information.
+ * This function is called to bring the sensor back from a low power state.
+ * Refer to the document driver-model/driver.txt in the kernel source tree
+ * for more information.
  *
  * @param   pdev   the device structure
  *
@@ -1816,6 +2246,8 @@ static int mxc_v4l2_resume(struct platform_device *pdev)
 {
 	cam_data *cam = platform_get_drvdata(pdev);
 
+	pr_debug("In MVC:mxc_v4l2_resume\n");
+
 	if (cam == NULL) {
 		return -1;
 	}
@@ -1847,6 +2279,73 @@ static struct platform_driver mxc_v4l2_driver = {
 };
 
 /*!
+ * Initializes the camera driver.
+ */
+static int mxc_v4l2_master_attach(struct v4l2_int_device *slave)
+{
+	cam_data *cam = slave->u.slave->master->priv;
+	struct v4l2_format cam_fmt;
+
+	pr_debug("In MVC: mxc_v4l2_master_attach\n");
+	pr_debug("   slave.name = %s\n", slave->name);
+	pr_debug("   master.name = %s\n", slave->u.slave->master->name);
+
+	cam->sensor = slave;
+	if (slave == NULL) {
+		pr_err("ERROR: v4l2 capture: slave parameter not valid.\n");
+		return -1;
+	}
+
+	ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, true, true);
+	vidioc_int_dev_init(slave);
+	ipu_csi_enable_mclk_if(CSI_MCLK_I2C, cam->csi, false, false);
+	cam_fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+	vidioc_int_g_fmt_cap(cam->sensor, &cam_fmt);
+
+	/* Used to detect TV in (type 1) vs. camera (type 0)*/
+	cam->device_type = cam_fmt.fmt.pix.priv;
+
+	/* Set the input size to the ipu for this device */
+	cam->crop_bounds.top = cam->crop_bounds.left = 0;
+	cam->crop_bounds.width = cam_fmt.fmt.pix.width;
+	cam->crop_bounds.height = cam_fmt.fmt.pix.height;
+
+	/* This also is the max crop size for this device. */
+	cam->crop_defrect.top = cam->crop_defrect.left = 0;
+	cam->crop_defrect.width = cam_fmt.fmt.pix.width;
+	cam->crop_defrect.height = cam_fmt.fmt.pix.height;
+
+	/* At this point, this is also the current image size. */
+	cam->crop_current.top = cam->crop_current.left = 0;
+	cam->crop_current.width = cam_fmt.fmt.pix.width;
+	cam->crop_current.height = cam_fmt.fmt.pix.height;
+
+	pr_debug("End of %s: v2f pix widthxheight %d x %d\n",
+		 __func__,
+		 cam->v2f.fmt.pix.width, cam->v2f.fmt.pix.height);
+	pr_debug("End of %s: crop_bounds widthxheight %d x %d\n",
+		 __func__,
+		 cam->crop_bounds.width, cam->crop_bounds.height);
+	pr_debug("End of %s: crop_defrect widthxheight %d x %d\n",
+		 __func__,
+		 cam->crop_defrect.width, cam->crop_defrect.height);
+	pr_debug("End of %s: crop_current widthxheight %d x %d\n",
+		 __func__,
+		 cam->crop_current.width, cam->crop_current.height);
+
+	return 0;
+}
+
+/*!
+ * Disconnects the camera driver.
+ */
+static void mxc_v4l2_master_detach(struct v4l2_int_device *slave)
+{
+	pr_debug("In MVC:mxc_v4l2_master_detach\n");
+	/* vidioc_int_dev_exit(slave); */
+}
+
+/*!
  * Entry point for the V4L2
  *
  * @return  Error code indicating success or failure
@@ -1855,61 +2354,75 @@ static __init int camera_init(void)
 {
 	u8 err = 0;
 
+	pr_debug("In MVC:camera_init\n");
+
 	/* Register the device driver structure. */
 	err = platform_driver_register(&mxc_v4l2_driver);
 	if (err != 0) {
-		printk("camera_init: platform_driver_register failed.\n");
+		pr_err("ERROR: v4l2 capture:camera_init: "
+			"platform_driver_register failed.\n");
 		return err;
 	}
 
+	/* Create g_cam and initialize it. */
 	if ((g_cam = kmalloc(sizeof(cam_data), GFP_KERNEL)) == NULL) {
-		printk(KERN_ERR "failed to mxc_v4l_register_camera\n");
+		pr_err("ERROR: v4l2 capture: failed to register camera\n");
+		platform_driver_unregister(&mxc_v4l2_driver);
 		return -1;
 	}
-
 	init_camera_struct(g_cam);
 
+	/* Set up the v4l2 device and register it*/
+	mxc_v4l2_int_device.priv = g_cam;
+	/* This function contains a bug that won't let this be rmmod'd. */
+	v4l2_int_device_register(&mxc_v4l2_int_device);
+
 	/* Register the I2C device */
 	err = platform_device_register(&mxc_v4l2_devices);
 	if (err != 0) {
-		printk(KERN_ERR
-		       "camera_init: platform_device_register failed.\n");
-		video_device_release(g_cam->video_dev);
+		pr_err("ERROR: v4l2 capture: camera_init: "
+		       "platform_device_register failed.\n");
+		platform_driver_unregister(&mxc_v4l2_driver);
 		kfree(g_cam);
 		g_cam = NULL;
+		return err;
 	}
 
-	/* register v4l device */
+	/* register v4l video device */
 	if (video_register_device(g_cam->video_dev, VFL_TYPE_GRABBER, video_nr)
 	    == -1) {
 		platform_device_unregister(&mxc_v4l2_devices);
 		platform_driver_unregister(&mxc_v4l2_driver);
-		video_device_release(g_cam->video_dev);
 		kfree(g_cam);
 		g_cam = NULL;
-		printk(KERN_ERR "video_register_device failed\n");
+		pr_err("ERROR: v4l2 capture: video_register_device failed\n");
 		return -1;
 	}
+	pr_debug("   Video device registered: %s #%d\n",
+		 g_cam->video_dev->name, g_cam->video_dev->minor);
 
 	return err;
 }
 
 /*!
  * Exit and cleanup for the V4L2
- *
  */
 static void __exit camera_exit(void)
 {
-	pr_info("unregistering video\n");
-	video_unregister_device(g_cam->video_dev);
+	pr_debug("In MVC: camera_exit\n");
 
-	platform_driver_unregister(&mxc_v4l2_driver);
-	platform_device_unregister(&mxc_v4l2_devices);
+	pr_info("V4L2 unregistering video\n");
 
 	if (g_cam->open_count) {
-		printk(KERN_ERR "camera open -- setting ops to NULL\n");
+		pr_err("ERROR: v4l2 capture:camera open "
+			"-- setting ops to NULL\n");
 	} else {
-		pr_info("freeing camera\n");
+		pr_info("V4L2 freeing image input device\n");
+		v4l2_int_device_unregister(&mxc_v4l2_int_device);
+		video_unregister_device(g_cam->video_dev);
+		platform_driver_unregister(&mxc_v4l2_driver);
+		platform_device_unregister(&mxc_v4l2_devices);
+
 		mxc_free_frame_buf(g_cam);
 		kfree(g_cam);
 		g_cam = NULL;
diff --git a/drivers/media/video/mxc/capture/mxc_v4l2_capture.h b/drivers/media/video/mxc/capture/mxc_v4l2_capture.h
index 0237ad8..2c7c549 100644
--- a/drivers/media/video/mxc/capture/mxc_v4l2_capture.h
+++ b/drivers/media/video/mxc/capture/mxc_v4l2_capture.h
@@ -52,6 +52,7 @@ struct mxc_v4l_frame {
 	int index;
 };
 
+/* Only for old version.  Will go away soon. */
 typedef struct {
 	u8 clk_mode;
 	u8 ext_vsync;
@@ -72,6 +73,7 @@ typedef struct {
 } sensor_interface;
 
 /* Sensor control function */
+/* Only for old version.  Will go away soon. */
 struct camera_sensor {
 	void (*set_color) (int bright, int saturation, int red, int green,
 			   int blue);
@@ -91,6 +93,7 @@ struct camera_sensor {
  */
 typedef struct _cam_data {
 	struct video_device *video_dev;
+	int device_type;
 
 	/* semaphore guard against SMP multithreading */
 	struct semaphore busy_lock;
@@ -100,7 +103,7 @@ typedef struct _cam_data {
 	/* params lock for this camera */
 	struct semaphore param_lock;
 
-	/* Encorder */
+	/* Encoder */
 	struct list_head ready_q;
 	struct list_head done_q;
 	struct list_head working_q;
@@ -149,9 +152,10 @@ typedef struct _cam_data {
 	int blue;
 	int ae_mode;
 
-	/* standart */
+	/* standard */
 	struct v4l2_streamparm streamparm;
 	struct v4l2_standard standard;
+	bool standard_autodetect;
 
 	/* crop */
 	struct v4l2_rect crop_bounds;
@@ -176,9 +180,11 @@ typedef struct _cam_data {
 	int capture_pid;
 	bool low_power;
 	wait_queue_head_t power_queue;
+	unsigned int csi;
 
 	/* camera sensor interface */
-	struct camera_sensor *cam_sensor;
+	struct camera_sensor *cam_sensor; 	/* old version */
+	struct v4l2_int_device *sensor;
 } cam_data;
 
 #if defined(CONFIG_MXC_IPU_V1) || defined(CONFIG_VIDEO_MXC_EMMA_CAMERA)
diff --git a/drivers/media/video/mxc/capture/ov2640.c b/drivers/media/video/mxc/capture/ov2640.c
index 8d237da..9e3d2c9 100644
--- a/drivers/media/video/mxc/capture/ov2640.c
+++ b/drivers/media/video/mxc/capture/ov2640.c
@@ -10,6 +10,14 @@
  * http://www.opensource.org/licenses/gpl-license.html
  * http://www.gnu.org/copyleft/gpl.html
  */
+
+/*!
+ * @file ov2640.c
+ *
+ * @brief ov2640 camera driver functions
+ *
+ * @ingroup Camera
+ */
 #include <linux/module.h>
 #include <linux/init.h>
 #include <linux/slab.h>
@@ -20,12 +28,22 @@
 #include <linux/i2c.h>
 #include <linux/regulator/regulator.h>
 
+#include <media/v4l2-int-device.h>
 #include "mxc_v4l2_capture.h"
 
+#define MIN_FPS 5
+#define MAX_FPS 30
+#define DEFAULT_FPS 30
+
+#define OV2640_XCLK_MIN 6000000
+#define OV2640_XCLK_MAX 24000000
+
+/*
 enum ov2640_mode {
 	ov2640_mode_1600_1120,
 	ov2640_mode_800_600
 };
+*/
 
 struct reg_value {
 	u8 reg;
@@ -135,279 +153,626 @@ static struct reg_value ov2640_setting_800_600[] = {
 	{0xe1, 0x67, 0}, {0xe0, 0x00, 0}, {0xdd, 0x7f, 0}, {0x05, 0x00, 0}
 };
 
+/*!
+ * Maintains the information on the current state of the sesor.
+ */
+struct sensor {
+	const struct ov2640_platform_data *platform_data;
+	struct v4l2_int_device *v4l2_int_device;
+	struct i2c_client *i2c_client;
+	struct v4l2_pix_format pix;
+	struct v4l2_captureparm streamcap;
+	bool on;
+
+	/* control settings */
+	int brightness;
+	int hue;
+	int contrast;
+	int saturation;
+	int red;
+	int green;
+	int blue;
+	int ae_mode;
+
+	u32 csi;
+	u32 mclk;
+
+} ov2640_data;
+
 static struct regulator *io_regulator;
 static struct regulator *core_regulator;
 static struct regulator *analog_regulator;
 static struct regulator *gpo_regulator;
-u32 mclk = 24000000;
-
-struct i2c_client *ov2640_i2c_client;
 
-static sensor_interface *interface_param;
-static int reset_frame_rate = 30;
-static int ov2640_probe(struct i2c_client *adapter, const struct i2c_device_id *id);
-static int ov2640_remove(struct i2c_client *client);
-
-static const struct i2c_device_id ov2640_id[] = {
-	{ "ov2640", 0 },
-	{},
-};
-MODULE_DEVICE_TABLE(i2c, ov2640_id);
+extern void gpio_sensor_active(void);
+extern void gpio_sensor_inactive(void);
 
-static struct i2c_driver ov2640_i2c_driver = {
-	.driver = {
-		   .owner = THIS_MODULE,
-		   .name = "ov2640",
-		   },
-	.probe = ov2640_probe,
-	.remove = ov2640_remove,
-	.id_table = ov2640_id,
+/* list of image formats supported by this sensor */
+/*
+const static struct v4l2_fmtdesc ov2640_formats[] = {
+	{
+		.description = "YUYV (YUV 4:2:2), packed",
+		.pixelformat = V4L2_PIX_FMT_UYVY,
+	},
 };
-
-/*!
- * ov2640 I2C attach function
- *
- * @param adapter            struct i2c_adapter *
- * @return  Error code indicating success or failure
  */
-static int ov2640_probe(struct i2c_client *client, const struct i2c_device_id *id)
+
+static int ov2640_init_mode(struct sensor *s)
 {
-	struct mxc_camera_platform_data *plat_data = client->dev.platform_data;
+	int ret;
+	struct reg_value *setting;
+	int i, num;
 
-	ov2640_i2c_client = client;
-	mclk = plat_data->mclk;
+	pr_debug("In ov2640:ov2640_init_mode capturemode is %d\n",
+		s->streamcap.capturemode);
 
-	io_regulator = regulator_get(&client->dev, plat_data->io_regulator);
-	core_regulator = regulator_get(&client->dev, plat_data->core_regulator);
-	analog_regulator =
-	    regulator_get(&client->dev, plat_data->analog_regulator);
-	gpo_regulator = regulator_get(&client->dev, plat_data->gpo_regulator);
+	if (s->streamcap.capturemode & V4L2_MODE_HIGHQUALITY) {
+		s->pix.width = 1600;
+		s->pix.height = 1120;
+		setting = ov2640_setting_1600_1120;
+		num = ARRAY_SIZE(ov2640_setting_1600_1120);
+	} else {
+		s->pix.width = 800;
+		s->pix.height = 600;
+		setting = ov2640_setting_800_600;
+		num = ARRAY_SIZE(ov2640_setting_800_600);
+	}
 
-	interface_param = (sensor_interface *)
-	    kmalloc(sizeof(sensor_interface), GFP_KERNEL);
-	if (!interface_param) {
-		dev_dbg(&ov2640_i2c_client->dev,
-			"ov2640_probe: kmalloc failed \n");
-		return -1;
+	for (i = 0; i < num; i++) {
+		ret = i2c_smbus_write_byte_data(s->i2c_client,
+						setting[i].reg,
+						setting[i].value);
+		if (ret < 0) {
+			pr_err("write reg error: reg=%x, val=%x\n",
+			       setting[i].reg, setting[i].value);
+			return ret;
+		}
+		if (setting[i].delay_ms > 0)
+			msleep(setting[i].delay_ms);
 	}
 
-	return 0;
+	return ret;
 }
 
+/* --------------- IOCTL functions from v4l2_int_ioctl_desc --------------- */
+
 /*!
- * ov2640 I2C detach function
+ * ioctl_g_ifparm - V4L2 sensor interface handler for vidioc_int_g_ifparm_num
+ * s: pointer to standard V4L2 device structure
+ * p: pointer to standard V4L2 vidioc_int_g_ifparm_num ioctl structure
  *
- * @param client            struct i2c_client *
- * @return  Error code indicating success or failure
+ * Gets slave interface parameters.
+ * Calculates the required xclk value to support the requested
+ * clock parameters in p.  This value is returned in the p
+ * parameter.
+ *
+ * vidioc_int_g_ifparm returns platform-specific information about the
+ * interface settings used by the sensor.
+ *
+ * Given the image capture format in pix, the nominal frame period in
+ * timeperframe, calculate the required xclk frequency.
+ *
+ * Called on open.
  */
-static int ov2640_remove(struct i2c_client *client)
+static int ioctl_g_ifparm(struct v4l2_int_device *s, struct v4l2_ifparm *p)
 {
-	kfree(interface_param);
-	interface_param = NULL;
+	pr_debug("In ov2640:ioctl_g_ifparm\n");
 
-	if (!IS_ERR_VALUE((unsigned long)io_regulator)) {
-		regulator_disable(io_regulator);
-		regulator_put(io_regulator, NULL);
+	if (s == NULL) {
+		pr_err("   ERROR!! no slave device set!\n");
+		return -1;
 	}
 
-	if (!IS_ERR_VALUE((unsigned long)core_regulator)) {
-		regulator_disable(core_regulator);
-		regulator_put(core_regulator, NULL);
-	}
+	memset(p, 0, sizeof(*p));
+	p->u.bt656.clock_curr = ov2640_data.mclk;
+	p->if_type = V4L2_IF_TYPE_BT656;
+	p->u.bt656.mode = V4L2_IF_TYPE_BT656_MODE_NOBT_8BIT;
+	p->u.bt656.clock_min = OV2640_XCLK_MIN;
+	p->u.bt656.clock_max = OV2640_XCLK_MAX;
 
-	if (!IS_ERR_VALUE((unsigned long)gpo_regulator)) {
-		regulator_disable(gpo_regulator);
-		regulator_put(gpo_regulator, NULL);
-	}
+	return 0;
+}
 
-	if (!IS_ERR_VALUE((unsigned long)analog_regulator)) {
-		regulator_disable(analog_regulator);
-		regulator_put(analog_regulator, NULL);
+/*!
+ * Sets the camera power.
+ *
+ * s  pointer to the camera device
+ * on if 1, power is to be turned on.  0 means power is to be turned off
+ *
+ * ioctl_s_power - V4L2 sensor interface handler for vidioc_int_s_power_num
+ * @s: pointer to standard V4L2 device structure
+ * @on: power state to which device is to be set
+ *
+ * Sets devices power state to requrested state, if possible.
+ * This is called on open, close, suspend and resume.
+ */
+static int ioctl_s_power(struct v4l2_int_device *s, int on)
+{
+	struct sensor *sensor = s->priv;
+
+	pr_debug("In ov2640:ioctl_s_power\n");
+
+	if (on && !sensor->on) {
+		gpio_sensor_active();
+		if (!IS_ERR_VALUE((unsigned long)io_regulator))
+			if (regulator_enable(io_regulator) != 0)
+				return -EIO;
+		if (!IS_ERR_VALUE((unsigned long)core_regulator))
+			if (regulator_enable(core_regulator) != 0)
+				return -EIO;
+		if (!IS_ERR_VALUE((unsigned long)gpo_regulator))
+			if (regulator_enable(gpo_regulator) != 0)
+				return -EIO;
+		if (!IS_ERR_VALUE((unsigned long)analog_regulator))
+			if (regulator_enable(analog_regulator) != 0)
+				return -EIO;
+	} else if (!on && sensor->on) {
+		if (!IS_ERR_VALUE((unsigned long)analog_regulator))
+			regulator_disable(analog_regulator);
+		if (!IS_ERR_VALUE((unsigned long)core_regulator))
+			regulator_disable(core_regulator);
+		if (!IS_ERR_VALUE((unsigned long)io_regulator))
+			regulator_disable(io_regulator);
+		if (!IS_ERR_VALUE((unsigned long)gpo_regulator))
+			regulator_disable(gpo_regulator);
+		gpio_sensor_inactive();
 	}
 
+	sensor->on = on;
+
 	return 0;
 }
 
-static int ov2640_write_reg(u8 reg, u8 val)
+/*!
+ * ioctl_g_parm - V4L2 sensor interface handler for VIDIOC_G_PARM ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @a: pointer to standard V4L2 VIDIOC_G_PARM ioctl structure
+ *
+ * Returns the sensor's video CAPTURE parameters.
+ */
+static int ioctl_g_parm(struct v4l2_int_device *s, struct v4l2_streamparm *a)
 {
-	if (i2c_smbus_write_byte_data(ov2640_i2c_client, reg, val) < 0) {
-		dev_dbg(&ov2640_i2c_client->dev,
-			"%s:write reg errorr:reg=%x,val=%x\n", __func__, reg,
-			val);
-		return -1;
+	struct sensor *sensor = s->priv;
+	struct v4l2_captureparm *cparm = &a->parm.capture;
+	int ret = 0;
+
+	pr_debug("In ov2640:ioctl_g_parm\n");
+
+	switch (a->type) {
+	/* This is the only case currently handled. */
+	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
+		pr_debug("   type is V4L2_BUF_TYPE_VIDEO_CAPTURE\n");
+		memset(a, 0, sizeof(*a));
+		a->type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+		cparm->capability = sensor->streamcap.capability;
+		cparm->timeperframe = sensor->streamcap.timeperframe;
+		cparm->capturemode = sensor->streamcap.capturemode;
+		ret = 0;
+		break;
+
+	/* These are all the possible cases. */
+	case V4L2_BUF_TYPE_VIDEO_OUTPUT:
+	case V4L2_BUF_TYPE_VIDEO_OVERLAY:
+	case V4L2_BUF_TYPE_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_VBI_OUTPUT:
+	case V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:
+		pr_err("   type is not V4L2_BUF_TYPE_VIDEO_CAPTURE " \
+			"but %d\n", a->type);
+		ret = -EINVAL;
+		break;
+
+	default:
+		pr_err("   type is unknown - %d\n", a->type);
+		ret = -EINVAL;
+		break;
 	}
-	return 0;
+
+	return ret;
 }
 
-static int ov2640_init_mode(enum ov2640_mode mode)
+/*!
+ * ioctl_s_parm - V4L2 sensor interface handler for VIDIOC_S_PARM ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @a: pointer to standard V4L2 VIDIOC_S_PARM ioctl structure
+ *
+ * Configures the sensor to use the input parameters, if possible.  If
+ * not possible, reverts to the old parameters and returns the
+ * appropriate error code.
+ */
+static int ioctl_s_parm(struct v4l2_int_device *s, struct v4l2_streamparm *a)
 {
-	struct reg_value *setting;
-	int i, num;
+	struct sensor *sensor = s->priv;
+	struct v4l2_fract *timeperframe = &a->parm.capture.timeperframe;
+	u32 tgt_fps;	/* target frames per secound */
+	int ret = 0;
+
+	pr_debug("In ov2640:ioctl_s_parm\n");
+
+	switch (a->type) {
+	/* This is the only case currently handled. */
+	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
+		pr_debug("   type is V4L2_BUF_TYPE_VIDEO_CAPTURE\n");
+
+		/* Check that the new frame rate is allowed. */
+		if ((timeperframe->numerator == 0)
+		    || (timeperframe->denominator == 0)) {
+			timeperframe->denominator = DEFAULT_FPS;
+			timeperframe->numerator = 1;
+		}
+		tgt_fps = timeperframe->denominator
+			  / timeperframe->numerator;
+
+		if (tgt_fps > MAX_FPS) {
+			timeperframe->denominator = MAX_FPS;
+			timeperframe->numerator = 1;
+		} else if (tgt_fps < MIN_FPS) {
+			timeperframe->denominator = MIN_FPS;
+			timeperframe->numerator = 1;
+		}
+		sensor->streamcap.timeperframe = *timeperframe;
+		sensor->streamcap.capturemode =
+				(u32)a->parm.capture.capturemode;
 
-	switch (mode) {
-	case ov2640_mode_1600_1120:
-		setting = ov2640_setting_1600_1120;
-		num = ARRAY_SIZE(ov2640_setting_1600_1120);
+		ret = ov2640_init_mode(sensor);
 		break;
-	case ov2640_mode_800_600:
-		setting = ov2640_setting_800_600;
-		num = ARRAY_SIZE(ov2640_setting_800_600);
+
+	/* These are all the possible cases. */
+	case V4L2_BUF_TYPE_VIDEO_OUTPUT:
+	case V4L2_BUF_TYPE_VIDEO_OVERLAY:
+	case V4L2_BUF_TYPE_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_VBI_OUTPUT:
+	case V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:
+		pr_err("   type is not V4L2_BUF_TYPE_VIDEO_CAPTURE " \
+			"but %d\n", a->type);
+		ret = -EINVAL;
 		break;
-	default:
-		return 0;
-	}
 
-	for (i = 0; i < num; i++) {
-		ov2640_write_reg(setting[i].reg, setting[i].value);
-		if (setting[i].delay_ms > 0)
-			msleep(setting[i].delay_ms);
+	default:
+		pr_err("   type is unknown - %d\n", a->type);
+		ret = -EINVAL;
+		break;
 	}
 
-	return 0;
+	return ret;
 }
 
 /*!
- * ov2640 sensor interface Initialization
- * @param param            sensor_interface *
- * @param width            u32
- * @param height           u32
- * @return  None
+ * ioctl_g_fmt_cap - V4L2 sensor interface handler for ioctl_g_fmt_cap
+ * @s: pointer to standard V4L2 device structure
+ * @f: pointer to standard V4L2 v4l2_format structure
+ *
+ * Returns the sensor's current pixel format in the v4l2_format
+ * parameter.
  */
-static void ov2640_interface(sensor_interface *param, u32 width, u32 height)
+static int ioctl_g_fmt_cap(struct v4l2_int_device *s, struct v4l2_format *f)
 {
-	param->Vsync_pol = 0x0;
-	param->clk_mode = 0x0;	/*gated */
-	param->pixclk_pol = 0x0;
-	param->data_width = 0x1;
-	param->data_pol = 0x0;
-	param->ext_vsync = 0x0;
-	param->Vsync_pol = 0x0;
-	param->Hsync_pol = 0x0;
-	param->width = width - 1;
-	param->height = height - 1;
-	param->active_width = width;
-	param->active_height = height;
-	param->pixel_fmt = IPU_PIX_FMT_UYVY;
-	param->mclk = mclk;
-}
+	struct sensor *sensor = s->priv;
 
-static void ov2640_set_color(int bright, int saturation, int red, int green,
-			     int blue)
-{
+	pr_debug("In ov2640:ioctl_g_fmt_cap.\n");
+
+	f->fmt.pix = sensor->pix;
 
+	return 0;
 }
 
-static void ov2640_get_color(int *bright, int *saturation, int *red, int *green,
-			     int *blue)
+/*!
+ * ioctl_g_ctrl - V4L2 sensor interface handler for VIDIOC_G_CTRL ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @vc: standard V4L2 VIDIOC_G_CTRL ioctl structure
+ *
+ * If the requested control is supported, returns the control's current
+ * value from the video_control[] array.  Otherwise, returns -EINVAL
+ * if the control is not supported.
+ */
+static int ioctl_g_ctrl(struct v4l2_int_device *s, struct v4l2_control *vc)
 {
+	int ret = 0;
+
+	pr_debug("In ov2640:ioctl_g_ctrl\n");
 
+	switch (vc->id) {
+	case V4L2_CID_BRIGHTNESS:
+		vc->value = ov2640_data.brightness;
+		break;
+	case V4L2_CID_HUE:
+		vc->value = ov2640_data.hue;
+		break;
+	case V4L2_CID_CONTRAST:
+		vc->value = ov2640_data.contrast;
+		break;
+	case V4L2_CID_SATURATION:
+		vc->value = ov2640_data.saturation;
+		break;
+	case V4L2_CID_RED_BALANCE:
+		vc->value = ov2640_data.red;
+		break;
+	case V4L2_CID_BLUE_BALANCE:
+		vc->value = ov2640_data.blue;
+		break;
+	case V4L2_CID_EXPOSURE:
+		vc->value = ov2640_data.ae_mode;
+		break;
+	default:
+		ret = -EINVAL;
+	}
+
+	return ret;
 }
-static void ov2640_set_ae_mode(int ae_mode)
+
+/*!
+ * ioctl_s_ctrl - V4L2 sensor interface handler for VIDIOC_S_CTRL ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @vc: standard V4L2 VIDIOC_S_CTRL ioctl structure
+ *
+ * If the requested control is supported, sets the control's current
+ * value in HW (and updates the video_control[] array).  Otherwise,
+ * returns -EINVAL if the control is not supported.
+ */
+static int ioctl_s_ctrl(struct v4l2_int_device *s, struct v4l2_control *vc)
 {
+	int retval = 0;
+
+	pr_debug("In ov2640:ioctl_s_ctrl %d\n", vc->id);
 
+	switch (vc->id) {
+	case V4L2_CID_BRIGHTNESS:
+		pr_debug("   V4L2_CID_BRIGHTNESS\n");
+		break;
+	case V4L2_CID_CONTRAST:
+		pr_debug("   V4L2_CID_CONTRAST\n");
+		break;
+	case V4L2_CID_SATURATION:
+		pr_debug("   V4L2_CID_SATURATION\n");
+		break;
+	case V4L2_CID_HUE:
+		pr_debug("   V4L2_CID_HUE\n");
+		break;
+	case V4L2_CID_AUTO_WHITE_BALANCE:
+		pr_debug(
+			"   V4L2_CID_AUTO_WHITE_BALANCE\n");
+		break;
+	case V4L2_CID_DO_WHITE_BALANCE:
+		pr_debug(
+			"   V4L2_CID_DO_WHITE_BALANCE\n");
+		break;
+	case V4L2_CID_RED_BALANCE:
+		pr_debug("   V4L2_CID_RED_BALANCE\n");
+		break;
+	case V4L2_CID_BLUE_BALANCE:
+		pr_debug("   V4L2_CID_BLUE_BALANCE\n");
+		break;
+	case V4L2_CID_GAMMA:
+		pr_debug("   V4L2_CID_GAMMA\n");
+		break;
+	case V4L2_CID_EXPOSURE:
+		pr_debug("   V4L2_CID_EXPOSURE\n");
+		break;
+	case V4L2_CID_AUTOGAIN:
+		pr_debug("   V4L2_CID_AUTOGAIN\n");
+		break;
+	case V4L2_CID_GAIN:
+		pr_debug("   V4L2_CID_GAIN\n");
+		break;
+	case V4L2_CID_HFLIP:
+		pr_debug("   V4L2_CID_HFLIP\n");
+		break;
+	case V4L2_CID_VFLIP:
+		pr_debug("   V4L2_CID_VFLIP\n");
+		break;
+	default:
+		pr_debug("   Default case\n");
+		retval = -EPERM;
+		break;
+	}
+
+	return retval;
 }
-static void ov2640_get_ae_mode(int *ae_mode)
+
+/*!
+ * ioctl_init - V4L2 sensor interface handler for VIDIOC_INT_INIT
+ * @s: pointer to standard V4L2 device structure
+ */
+static int ioctl_init(struct v4l2_int_device *s)
 {
+	pr_debug("In ov2640:ioctl_init\n");
 
+	return 0;
 }
 
-extern void gpio_sensor_active(void);
-
-static sensor_interface *ov2640_config(int *frame_rate, int high_quality)
+/*!
+ * ioctl_dev_init - V4L2 sensor interface handler for vidioc_int_dev_init_num
+ * @s: pointer to standard V4L2 device structure
+ *
+ * Initialise the device when slave attaches to the master.
+ */
+static int ioctl_dev_init(struct v4l2_int_device *s)
 {
+	struct sensor *sensor = s->priv;
+	u32 tgt_xclk;	/* target xclk */
 
-	u32 out_width, out_height;
+	pr_debug("In ov2640:ioctl_dev_init\n");
+
+	gpio_sensor_active();
+	ov2640_data.on = true;
 
-	/*set io votage */
 	if (!IS_ERR_VALUE((unsigned long)io_regulator)) {
 		regulator_set_voltage(io_regulator, 2800000);
-		if (regulator_enable(io_regulator) != 0) {
-			dev_dbg(&ov2640_i2c_client->dev,
-				"%s:io set voltage error\n", __func__);
-			return NULL;
-		} else {
-			dev_dbg(&ov2640_i2c_client->dev,
-				"%s:io set voltage ok\n", __func__);
-		}
+		if (regulator_enable(io_regulator) != 0)
+			return -EIO;
 	}
-
-	/*core votage */
 	if (!IS_ERR_VALUE((unsigned long)core_regulator)) {
 		regulator_set_voltage(core_regulator, 1300000);
-		if (regulator_enable(core_regulator) != 0) {
-			dev_dbg(&ov2640_i2c_client->dev,
-				"%s:core set voltage error\n", __func__);
-			return NULL;
-		} else {
-			dev_dbg(&ov2640_i2c_client->dev,
-				"%s:core set voltage ok\n", __func__);
+		if (regulator_enable(core_regulator) != 0)
+			return -EIO;
 		}
-	}
-
 	/*GPO 3 */
 	if (!IS_ERR_VALUE((unsigned long)gpo_regulator)) {
 		if (regulator_enable(gpo_regulator) != 0) {
-			dev_dbg(&ov2640_i2c_client->dev,
-				"%s:gpo3 enable error\n", __func__);
-			return NULL;
-		} else {
-			dev_dbg(&ov2640_i2c_client->dev, "%s:gpo3 enable ok\n",
-				__func__);
+			return -EIO;
 		}
 	}
-
 	if (!IS_ERR_VALUE((unsigned long)analog_regulator)) {
+		/* regulator_set_voltage(analog_regulator, 2800000); */
 		regulator_set_voltage(analog_regulator, 2000000);
-		if (regulator_enable(analog_regulator) != 0) {
-			dev_dbg(&ov2640_i2c_client->dev,
-				"%s:analog set voltage error\n", __func__);
-			return NULL;
-		} else {
-			dev_dbg(&ov2640_i2c_client->dev,
-				"%s:analog set voltage ok\n", __func__);
-		}
+		if (regulator_enable(analog_regulator) != 0)
+			return -EIO;
 	}
 
-	gpio_sensor_active();
+	tgt_xclk = ov2640_data.mclk;
+	tgt_xclk = min(tgt_xclk, (u32)OV2640_XCLK_MAX);
+	tgt_xclk = max(tgt_xclk, (u32)OV2640_XCLK_MIN);
+	ov2640_data.mclk = tgt_xclk;
 
-	if (high_quality) {
-		out_width = 1600;
-		out_height = 1120;
-	} else {
-		out_width = 800;
-		out_height = 600;
-	}
-	ov2640_interface(interface_param, out_width, out_height);
-	set_mclk_rate(&interface_param->mclk);
+	pr_debug("   Setting mclk to %d MHz\n",
+		tgt_xclk / 1000000);
+	set_mclk_rate(&ov2640_data.mclk);
+
+	return ov2640_init_mode(sensor);
+}
+
+/*!
+ * This structure defines all the ioctls for this module and links them to the
+ * enumeration.
+ */
+static struct v4l2_int_ioctl_desc ov2640_ioctl_desc[] = {
+	{vidioc_int_dev_init_num, (v4l2_int_ioctl_func *)ioctl_dev_init},
+/*	{vidioc_int_dev_exit_num, (v4l2_int_ioctl_func *)ioctl_dev_exit}, */
+	{vidioc_int_s_power_num, (v4l2_int_ioctl_func *)ioctl_s_power},
+	{vidioc_int_g_ifparm_num, (v4l2_int_ioctl_func *)ioctl_g_ifparm},
+/*	{vidioc_int_g_needs_reset_num,
+				(v4l2_int_ioctl_func *)ioctl_g_needs_reset}, */
+/*	{vidioc_int_reset_num, (v4l2_int_ioctl_func *)ioctl_reset}, */
+	{vidioc_int_init_num, (v4l2_int_ioctl_func *)ioctl_init},
+/*	{vidioc_int_enum_fmt_cap_num,
+				(v4l2_int_ioctl_func *)ioctl_enum_fmt_cap}, */
+/*	{vidioc_int_try_fmt_cap_num,
+				(v4l2_int_ioctl_func *)ioctl_try_fmt_cap}, */
+	{vidioc_int_g_fmt_cap_num, (v4l2_int_ioctl_func *)ioctl_g_fmt_cap},
+/*	{vidioc_int_s_fmt_cap_num, (v4l2_int_ioctl_func *)ioctl_s_fmt_cap}, */
+	{vidioc_int_g_parm_num, (v4l2_int_ioctl_func *)ioctl_g_parm},
+	{vidioc_int_s_parm_num, (v4l2_int_ioctl_func *)ioctl_s_parm},
+/*	{vidioc_int_queryctrl_num, (v4l2_int_ioctl_func *)ioctl_queryctrl}, */
+	{vidioc_int_g_ctrl_num, (v4l2_int_ioctl_func *)ioctl_g_ctrl},
+	{vidioc_int_s_ctrl_num, (v4l2_int_ioctl_func *)ioctl_s_ctrl},
+};
+
+static struct v4l2_int_slave ov2640_slave = {
+	.ioctls = ov2640_ioctl_desc,
+	.num_ioctls = ARRAY_SIZE(ov2640_ioctl_desc),
+};
+
+static struct v4l2_int_device ov2640_int_device = {
+	.module = THIS_MODULE,
+	.name = "ov2640",
+	.type = v4l2_int_type_slave,
+	.u = {
+		.slave = &ov2640_slave,
+		},
+};
+
+/*!
+ * ov2640 I2C attach function
+ * Function set in i2c_driver struct.
+ * Called by insmod ov2640_camera.ko.
+ *
+ * @param client            struct i2c_client*
+ * @return  Error code indicating success or failure
+ */
+static int ov2640_probe(struct i2c_client *client,
+			const struct i2c_device_id *id)
+{
+	int retval;
+	struct mxc_camera_platform_data *plat_data = client->dev.platform_data;
+
+	pr_debug("In ov2640_probe (RH_BT565)\n");
+
+	/* Set initial values for the sensor struct. */
+	memset(&ov2640_data, 0, sizeof(ov2640_data));
+	ov2640_data.i2c_client = client;
+	ov2640_data.mclk = 24000000;
+	ov2640_data.mclk = plat_data->mclk;
+	ov2640_data.pix.pixelformat = V4L2_PIX_FMT_UYVY;
+	ov2640_data.pix.width = 800;
+	ov2640_data.pix.height = 600;
+	ov2640_data.streamcap.capability = V4L2_MODE_HIGHQUALITY
+					   | V4L2_CAP_TIMEPERFRAME;
+	ov2640_data.streamcap.capturemode = 0;
+	ov2640_data.streamcap.timeperframe.denominator = DEFAULT_FPS;
+	ov2640_data.streamcap.timeperframe.numerator = 1;
 
-	if (high_quality)
-		ov2640_init_mode(ov2640_mode_1600_1120);
-	else
-		ov2640_init_mode(ov2640_mode_800_600);
+	io_regulator = regulator_get(&client->dev, plat_data->io_regulator);
+	core_regulator = regulator_get(&client->dev, plat_data->core_regulator);
+	analog_regulator =
+		regulator_get(&client->dev, plat_data->analog_regulator);
+	gpo_regulator = regulator_get(&client->dev, plat_data->gpo_regulator);
 
-	msleep(300);
+	/* This function attaches this structure to the /dev/video0 device.
+	 * The pointer in priv points to the mt9v111_data structure here.*/
+	ov2640_int_device.priv = &ov2640_data;
+	retval = v4l2_int_device_register(&ov2640_int_device);
 
-	return interface_param;
+	return retval;
 }
 
-static sensor_interface *ov2640_reset(void)
+/*!
+ * ov2640 I2C detach function
+ * Called on rmmod ov2640_camera.ko
+ *
+ * @param client            struct i2c_client*
+ * @return  Error code indicating success or failure
+ */
+static int ov2640_remove(struct i2c_client *client)
 {
-	return ov2640_config(&reset_frame_rate, 0);
+	pr_debug("In ov2640_remove\n");
+
+	v4l2_int_device_unregister(&ov2640_int_device);
+
+	if (!IS_ERR_VALUE((unsigned long)gpo_regulator)) {
+		regulator_disable(gpo_regulator);
+		regulator_put(gpo_regulator, &client->dev);
+	}
+
+	if (!IS_ERR_VALUE((unsigned long)analog_regulator)) {
+		regulator_disable(analog_regulator);
+		regulator_put(analog_regulator, &client->dev);
+	}
+
+	if (!IS_ERR_VALUE((unsigned long)core_regulator)) {
+		regulator_disable(core_regulator);
+		regulator_put(core_regulator, &client->dev);
+	}
+
+	if (!IS_ERR_VALUE((unsigned long)io_regulator)) {
+		regulator_disable(io_regulator);
+		regulator_put(io_regulator, &client->dev);
+	}
+
+	return 0;
 }
 
-struct camera_sensor camera_sensor_if = {
-	.set_color = ov2640_set_color,
-	.get_color = ov2640_get_color,
-	.set_ae_mode = ov2640_set_ae_mode,
-	.get_ae_mode = ov2640_get_ae_mode,
-	.config = ov2640_config,
-	.reset = ov2640_reset,
+static const struct i2c_device_id ov2640_id[] = {
+	{"ov2640", 0},
+	{},
 };
 
-EXPORT_SYMBOL(camera_sensor_if);
+MODULE_DEVICE_TABLE(i2c, ov2640_id);
+
+static struct i2c_driver ov2640_i2c_driver = {
+	.driver = {
+		   .owner = THIS_MODULE,
+		   .name = "ov2640",
+		  },
+	.probe = ov2640_probe,
+	.remove = ov2640_remove,
+	.id_table = ov2640_id,
+/* To add power management add .suspend and .resume functions */
+};
 
 /*!
  * ov2640 init function
+ * Called by insmod ov2640_camera.ko.
  *
  * @return  Error code indicating success or failure
  */
@@ -415,21 +780,26 @@ static __init int ov2640_init(void)
 {
 	u8 err;
 
+	pr_debug("In ov2640_init\n");
+
 	err = i2c_add_driver(&ov2640_i2c_driver);
+	if (err != 0)
+		pr_err("%s:driver registration failed, error=%d \n",
+			__func__, err);
 
 	return err;
 }
 
-extern void gpio_sensor_inactive(void);
 /*!
  * OV2640 cleanup function
+ * Called on rmmod ov2640_camera.ko
  *
  * @return  Error code indicating success or failure
  */
 static void __exit ov2640_clean(void)
 {
+	pr_debug("In ov2640_clean\n");
 	i2c_del_driver(&ov2640_i2c_driver);
-
 	gpio_sensor_inactive();
 }
 
diff --git a/drivers/media/video/mxc/capture/ov3640.c b/drivers/media/video/mxc/capture/ov3640.c
index 932b5e5..16ef199 100644
--- a/drivers/media/video/mxc/capture/ov3640.c
+++ b/drivers/media/video/mxc/capture/ov3640.c
@@ -10,7 +10,6 @@
  * http://www.opensource.org/licenses/gpl-license.html
  * http://www.gnu.org/copyleft/gpl.html
  */
-
 #include <linux/module.h>
 #include <linux/init.h>
 #include <linux/slab.h>
@@ -20,9 +19,11 @@
 #include <linux/device.h>
 #include <linux/i2c.h>
 #include <linux/regulator/regulator.h>
-
+#include <media/v4l2-int-device.h>
 #include "mxc_v4l2_capture.h"
 
+#define CAMERA_DBG
+
 #ifdef CAMERA_DBG
 	#define CAMERA_TRACE(x) (printk)x
 #else
@@ -33,29 +34,64 @@
 #define OV3640_VOLTAGE_DIGITAL_CORE         1500000
 #define OV3640_VOLTAGE_DIGITAL_IO           1800000
 
+
+/* Check these values! */
+#define MIN_FPS 5
+#define MAX_FPS 30
+#define DEFAULT_FPS 30
+
+#define OV3640_XCLK_MIN 6000000
+#define OV3640_XCLK_MAX 24000000
+
 enum ov3640_mode {
 	ov3640_mode_MIN = 0,
-	ov3640_mode_VGA_640_480    = 0,
-	ov3640_mode_QVGA_320_240   = 1,
+	ov3640_mode_VGA_640_480 = 0,
+	ov3640_mode_QVGA_320_240 = 1,
 	ov3640_mode_QXGA_2048_1536 = 2,
-	ov3640_mode_XGA_1024_768   = 3,
+	ov3640_mode_XGA_1024_768 = 3,
 	ov3640_mode_MAX = 3
 };
 
 struct reg_value {
 	u16 u16RegAddr;
-	u8  u8Val;
+	u8 u8Val;
 	u32 u32Delay_ms;
 };
 
 struct ov3640_mode_info {
 	enum ov3640_mode mode;
-	u32		width;
-	u32		height;
+	u32 width;
+	u32 height;
 	struct reg_value *init_data_ptr;
-	u32		init_data_size;
+	u32 init_data_size;
 };
 
+/*!
+ * Maintains the information on the current state of the sesor.
+ */
+struct sensor {
+	const struct ov3640_platform_data *platform_data;
+	struct v4l2_int_device *v4l2_int_device;
+	struct i2c_client *i2c_client;
+	struct v4l2_pix_format pix;
+	struct v4l2_captureparm streamcap;
+	bool on;
+
+	/* control settings */
+	int brightness;
+	int hue;
+	int contrast;
+	int saturation;
+	int red;
+	int green;
+	int blue;
+	int ae_mode;
+
+	u32 mclk;
+	int csi;
+
+} ov3640_data;
+
 static struct reg_value ov3640_setting_QXGA_2048_1536[] = {
 	{0x3012, 0x80, 0}, {0x304d, 0x45, 0}, {0x30a7, 0x5e, 0},
 	{0x3087, 0x16, 0}, {0x309c, 0x1a, 0}, {0x30a2, 0xe4, 0},
@@ -225,232 +261,72 @@ static struct ov3640_mode_info ov3640_mode_info_data[] = {
 	ARRAY_SIZE(ov3640_setting_XGA_1024_768)},
 };
 
-static s32 s32csi_index;
 static struct regulator *io_regulator;
 static struct regulator *core_regulator;
 static struct regulator *analog_regulator;
 static struct regulator *gpo_regulator;
 
-u32 mclk = 24000000; /* 6 - 54 MHz, typical 24MHz */
-
-struct i2c_client *ov3640_i2c_client;
-
-static sensor_interface *interface_param;
-static s32 reset_frame_rate = 30;
 static int ov3640_probe(struct i2c_client *adapter,
 				const struct i2c_device_id *device_id);
 static int ov3640_remove(struct i2c_client *client);
 
-static s32 ov3640_read_reg(u16 reg, u8 *val);
+/* static s32 ov3640_read_reg(u16 reg, u8 *val);  Not currently used. */
 static s32 ov3640_write_reg(u16 reg, u8 val);
 
 static const struct i2c_device_id ov3640_id[] = {
 	{"ov3640", 0},
 	{},
 };
+
 MODULE_DEVICE_TABLE(i2c, ov3640_id);
 
 static struct i2c_driver ov3640_i2c_driver = {
 	.driver = {
-		.owner = THIS_MODULE,
-		.name  = "ov3640",
-	},
+		  .owner = THIS_MODULE,
+		  .name  = "ov3640",
+		  },
 	.probe  = ov3640_probe,
 	.remove = ov3640_remove,
 	.id_table = ov3640_id,
 };
 
-extern struct camera_sensor camera_sensor_if;
-
-/*!
- * ov3640 I2C attach function
- *
- * @param adapter            struct i2c_adapter *
- * @return  Error code indicating success or failure
- */
-static int ov3640_probe(struct i2c_client *client,
-				const struct i2c_device_id *device_id)
-{
-	struct mxc_camera_platform_data *plat_data = client->dev.platform_data;
-
-	CAMERA_TRACE(("CAMERA_DBG Entry: ov3640_probe\n"));
-
-	ov3640_i2c_client = client;
-	mclk = plat_data->mclk;
-	s32csi_index = camera_sensor_if.csi = plat_data->csi;
-
-	io_regulator = regulator_get(&client->dev,
-				     plat_data->io_regulator);
-
-	if (!IS_ERR_VALUE((u32)io_regulator)) {
-		regulator_set_voltage(io_regulator, OV3640_VOLTAGE_DIGITAL_IO);
-		if (regulator_enable(io_regulator) != 0) {
-			dev_dbg(&ov3640_i2c_client->dev,
-				"%s:io set voltage error\n", __func__);
-			goto err1;
-		} else {
-			dev_dbg(&ov3640_i2c_client->dev,
-				"%s:io set voltage ok\n", __func__);
-		}
-	}
-
-	core_regulator = regulator_get(&client->dev,
-				       plat_data->core_regulator);
-
-	if (!IS_ERR_VALUE((u32)core_regulator)) {
-		regulator_set_voltage(core_regulator,
-					OV3640_VOLTAGE_DIGITAL_CORE);
-		if (regulator_enable(core_regulator) != 0) {
-			dev_dbg(&ov3640_i2c_client->dev,
-				"%s:core set voltage error\n", __func__);
-			goto err2;
-		} else {
-			dev_dbg(&ov3640_i2c_client->dev,
-				"%s:core set voltage ok\n", __func__);
-		}
-	}
-
-	analog_regulator = regulator_get(&client->dev,
-					 plat_data->analog_regulator);
-
-	if (!IS_ERR_VALUE((u32)analog_regulator)) {
-		regulator_set_voltage(analog_regulator, OV3640_VOLTAGE_ANALOG);
-		if (regulator_enable(analog_regulator) != 0) {
-			dev_dbg(&ov3640_i2c_client->dev,
-				"%s:analog set voltage error\n", __func__);
-			goto err3;
-		} else {
-			dev_dbg(&ov3640_i2c_client->dev,
-				"%s:analog set voltage ok\n", __func__);
-		}
-	}
-
-	gpo_regulator = regulator_get(&client->dev,
-				      plat_data->gpo_regulator);
-
-	if (!IS_ERR_VALUE((u32)gpo_regulator)) {
-		if (regulator_enable(gpo_regulator) != 0) {
-			dev_dbg(&ov3640_i2c_client->dev,
-				"%s:gpo3 enable error\n", __func__);
-			goto err4;
-		} else {
-			dev_dbg(&ov3640_i2c_client->dev,
-				"%s:gpo3 enable ok\n", __func__);
-		}
-	}
-
-	if (NULL == interface_param) {
-		interface_param = kmalloc(sizeof(sensor_interface), GFP_KERNEL);
-		if (!interface_param) {
-			dev_dbg(&ov3640_i2c_client->dev,
-				"ov3640_probe: kmalloc failed \n");
-			return -1;
-		}
-		memset(interface_param, 0, sizeof(sensor_interface));
-	} else {
-		dev_dbg(&ov3640_i2c_client->dev,
-				"ov3640_probe: kmalloc pointer not NULL \n");
-		return -1;
-	}
-
-	CAMERA_TRACE(("CAMERA_DBG Exit: ov3640_probe\n"));
-
-	return 0;
-err4:
-	if (!IS_ERR_VALUE((u32)analog_regulator)) {
-		regulator_disable(analog_regulator);
-		regulator_put(analog_regulator, &client->dev);
-	}
-err3:
-	if (!IS_ERR_VALUE((u32)core_regulator)) {
-		regulator_disable(core_regulator);
-		regulator_put(core_regulator, &client->dev);
-	}
-err2:
-	if (!IS_ERR_VALUE((u32)io_regulator)) {
-		regulator_disable(io_regulator);
-		regulator_put(io_regulator, &client->dev);
-	}
-err1:
-	return -1;
-}
-
-/*!
- * ov3640 I2C detach function
- *
- * @param client            struct i2c_client *
- * @return  Error code indicating success or failure
- */
-static int ov3640_remove(struct i2c_client *client)
-{
-	CAMERA_TRACE(("CAMERA_DBG Entry: ov3640_remove\n"));
-
-	if (NULL != interface_param) {
-		kfree(interface_param);
-		interface_param = NULL;
-	}
-
-	if (!IS_ERR_VALUE((u32)io_regulator)) {
-		regulator_disable(io_regulator);
-		regulator_put(io_regulator, &client->dev);
-	}
-
-	if (!IS_ERR_VALUE((u32)core_regulator)) {
-		regulator_disable(core_regulator);
-		regulator_put(core_regulator, &client->dev);
-	}
-
-	if (!IS_ERR_VALUE((u32)gpo_regulator)) {
-		regulator_disable(gpo_regulator);
-		regulator_put(gpo_regulator, &client->dev);
-	}
-
-	if (!IS_ERR_VALUE((u32)analog_regulator)) {
-		regulator_disable(analog_regulator);
-		regulator_put(analog_regulator, &client->dev);
-	}
-
-	CAMERA_TRACE(("CAMERA_DBG Exit: ov3640_remove\n"));
-
-	return 0;
-}
+extern void gpio_sensor_active(unsigned int csi_index);
+extern void gpio_sensor_inactive(unsigned int csi);
 
 static s32 ov3640_write_reg(u16 reg, u8 val)
 {
-	u8 au8Buf[3] = { 0 };
+	u8 au8Buf[3] = {0};
 
 	au8Buf[0] = reg >> 8;
 	au8Buf[1] = reg & 0xff;
 	au8Buf[2] = val;
 
-	if (i2c_master_send(ov3640_i2c_client, au8Buf, 3) < 0) {
-		dev_dbg(&ov3640_i2c_client->dev,
-				"%s:write reg error:reg=%x,val=%x\n",
-				__func__, reg, val);
+	if (i2c_master_send(ov3640_data.i2c_client, au8Buf, 3) < 0) {
+		pr_err("%s:write reg error:reg=%x,val=%x\n",
+			__func__, reg, val);
 		return -1;
 	}
 
 	return 0;
 }
 
+#ifdef DEBUG
 static s32 ov3640_read_reg(u16 reg, u8 *val)
 {
-	u8 au8RegBuf[2] = { 0 };
+	u8 au8RegBuf[2] = {0};
 	u8 u8RdVal = 0;
 
 	au8RegBuf[0] = reg >> 8;
 	au8RegBuf[1] = reg & 0xff;
 
-	if (2 != i2c_master_send(ov3640_i2c_client, au8RegBuf, 2)) {
-		dev_dbg(&ov3640_i2c_client->dev,
-				"%s:write reg error:reg=%x\n",
+	if (2 != i2c_master_send(ov3640_data.i2c_client, au8RegBuf, 2)) {
+		pr_err("%s:write reg error:reg=%x\n",
 				__func__, reg);
 		return -1;
 	}
 
-	if (1 != i2c_master_recv(ov3640_i2c_client, &u8RdVal, 1)) {
-		dev_dbg(&ov3640_i2c_client->dev,
-				"%s:read reg error:reg=%x,val=%x\n",
+	if (1 != i2c_master_recv(ov3640_data.i2c_client, &u8RdVal, 1)) {
+		pr_err("%s:read reg error:reg=%x,val=%x\n",
 				__func__, reg, u8RdVal);
 		return -1;
 	}
@@ -459,6 +335,7 @@ static s32 ov3640_read_reg(u16 reg, u8 *val)
 
 	return u8RdVal;
 }
+#endif
 
 static int ov3640_init_mode(enum ov3640_mode mode)
 {
@@ -469,14 +346,17 @@ static int ov3640_init_mode(enum ov3640_mode mode)
 	CAMERA_TRACE(("CAMERA_DBG Entry: ov3640_init_mode\n"));
 
 	if (mode > ov3640_mode_MAX || mode < ov3640_mode_MIN) {
-		dev_dbg(&ov3640_i2c_client->dev,
-				"Wrong ov3640 mode detected!\n");
+		pr_err("Wrong ov3640 mode detected!\n");
 		return -1;
 	}
 
 	pModeSetting = ov3640_mode_info_data[mode].init_data_ptr;
 	iModeSettingArySize = ov3640_mode_info_data[mode].init_data_size;
 
+	ov3640_data.pix.width = ov3640_mode_info_data[mode].width;
+	ov3640_data.pix.height = ov3640_mode_info_data[mode].height;
+
+
 	for (i = 0; i < iModeSettingArySize; ++i, ++pModeSetting) {
 		u32 u32TmpVal = pModeSetting->u32Delay_ms;
 
@@ -490,123 +370,538 @@ static int ov3640_init_mode(enum ov3640_mode mode)
 	return 0;
 }
 
+/* --------------- IOCTL functions from v4l2_int_ioctl_desc --------------- */
+
+static int ioctl_g_ifparm(struct v4l2_int_device *s, struct v4l2_ifparm *p)
+{
+	CAMERA_TRACE(("In ov3640:ioctl_g_ifparm\n"));
+	if (s == NULL) {
+		pr_err("   ERROR!! no slave device set!\n");
+		return -1;
+	}
+
+	memset(p, 0, sizeof(*p));
+	p->u.bt656.clock_curr = ov3640_data.mclk;
+	pr_debug("   clock_curr=mclk=%d\n", ov3640_data.mclk);
+	p->if_type = V4L2_IF_TYPE_BT656;
+	p->u.bt656.mode = V4L2_IF_TYPE_BT656_MODE_NOBT_8BIT;
+	p->u.bt656.clock_min = OV3640_XCLK_MIN;
+	p->u.bt656.clock_max = OV3640_XCLK_MAX;
+	p->u.bt656.bt_sync_correct = 1;  /* Indicate external vsync */
+
+	return 0;
+}
+
 /*!
- * ov3640 sensor interface Initialization
- * @param param            sensor_interface *
- * @param width            u32
- * @param height           u32
- * @return  None
+ * ioctl_s_power - V4L2 sensor interface handler for VIDIOC_S_POWER ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @on: indicates power mode (on or off)
+ *
+ * Turns the power on or off, depending on the value of on and returns the
+ * appropriate error code.
  */
-static void ov3640_interface(sensor_interface *param, u32 width, u32 height)
+static int ioctl_s_power(struct v4l2_int_device *s, int on)
 {
+	struct sensor *sensor = s->priv;
+
+	CAMERA_TRACE(("In ov3640:ioctl_s_power\n"));
+
+	if (on && !sensor->on) {
+		gpio_sensor_active(ov3640_data.csi);
+		if (!IS_ERR_VALUE((unsigned long)io_regulator))
+			if (regulator_enable(io_regulator) != 0)
+				return -EIO;
+		if (!IS_ERR_VALUE((unsigned long)core_regulator))
+			if (regulator_enable(core_regulator) != 0)
+				return -EIO;
+		if (!IS_ERR_VALUE((unsigned long)gpo_regulator))
+			if (regulator_enable(gpo_regulator) != 0)
+				return -EIO;
+		if (!IS_ERR_VALUE((unsigned long)analog_regulator))
+			if (regulator_enable(analog_regulator) != 0)
+				return -EIO;
+	} else if (!on && sensor->on) {
+		if (!IS_ERR_VALUE((unsigned long)analog_regulator))
+			regulator_disable(analog_regulator);
+		if (!IS_ERR_VALUE((unsigned long)core_regulator))
+			regulator_disable(core_regulator);
+		if (!IS_ERR_VALUE((unsigned long)io_regulator))
+			regulator_disable(io_regulator);
+		if (!IS_ERR_VALUE((unsigned long)gpo_regulator))
+			regulator_disable(gpo_regulator);
+		gpio_sensor_inactive(ov3640_data.csi);
+	}
+
+	sensor->on = on;
 
-	CAMERA_TRACE(("CAMERA_DBG Entry: ov3640_interface\n"));
-
-	param->data_width = IPU_CSI_DATA_WIDTH_8;
-	param->clk_mode = IPU_CSI_CLK_MODE_GATED_CLK;  /* gated */
-	param->pixel_fmt = IPU_PIX_FMT_UYVY;
-	param->ext_vsync = 1;
-	param->Vsync_pol = 0;
-	param->Hsync_pol = 0;
-	param->pixclk_pol = 0;
-	param->data_pol = 0;
-	param->pack_tight = 0;
-	param->force_eof = 0;
-	param->data_en_pol = 0;
-	param->width = width;
-	param->height = height;
-	param->active_width = width;
-	param->active_height = height;
-	param->mclk = mclk;
-
-	CAMERA_TRACE(("CAMERA_DBG Exit: ov3640_interface\n"));
+	return 0;
 }
 
-static void ov3640_set_color(int bright, int saturation, int red, int green,
-				int blue)
+/*!
+ * ioctl_g_parm - V4L2 sensor interface handler for VIDIOC_G_PARM ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @a: pointer to standard V4L2 VIDIOC_G_PARM ioctl structure
+ *
+ * Returns the sensor's video CAPTURE parameters.
+ */
+static int ioctl_g_parm(struct v4l2_int_device *s, struct v4l2_streamparm *a)
 {
+	struct sensor *sensor = s->priv;
+	struct v4l2_captureparm *cparm = &a->parm.capture;
+	int ret = 0;
+
+	CAMERA_TRACE(("In ov3640:ioctl_g_parm\n"));
+	switch (a->type) {
+	/* This is the only case currently handled. */
+	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
+		CAMERA_TRACE(("   type is V4L2_BUF_TYPE_VIDEO_CAPTURE\n"));
+		memset(a, 0, sizeof(*a));
+		a->type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+		cparm->capability = sensor->streamcap.capability;
+		cparm->timeperframe = sensor->streamcap.timeperframe;
+		cparm->capturemode = sensor->streamcap.capturemode;
+		ret = 0;
+		break;
+
+	/* These are all the possible cases. */
+	case V4L2_BUF_TYPE_VIDEO_OUTPUT:
+	case V4L2_BUF_TYPE_VIDEO_OVERLAY:
+	case V4L2_BUF_TYPE_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_VBI_OUTPUT:
+	case V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:
+		CAMERA_TRACE(("   type is not " \
+			"V4L2_BUF_TYPE_VIDEO_CAPTURE but %d\n",
+			a->type));
+		ret = -EINVAL;
+		break;
+
+	default:
+		pr_debug("   type is unknown - %d\n", a->type);
+		ret = -EINVAL;
+		break;
+	}
 
+	return ret;
 }
 
-static void ov3640_get_color(int *bright, int *saturation, int *red, int *green,
-				int *blue)
+/*!
+ * ioctl_s_parm - V4L2 sensor interface handler for VIDIOC_S_PARM ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @a: pointer to standard V4L2 VIDIOC_S_PARM ioctl structure
+ *
+ * Configures the sensor to use the input parameters, if possible.  If
+ * not possible, reverts to the old parameters and returns the
+ * appropriate error code.
+ */
+static int ioctl_s_parm(struct v4l2_int_device *s, struct v4l2_streamparm *a)
 {
+	struct sensor *sensor = s->priv;
+	struct v4l2_fract *timeperframe = &a->parm.capture.timeperframe;
+	u32 tgt_fps;	/* target frames per secound */
+	int ret = 0;
+
+	CAMERA_TRACE(("In ov3640:ioctl_s_parm\n"));
+	switch (a->type) {
+	/* This is the only case currently handled. */
+	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
+		CAMERA_TRACE(("   type is V4L2_BUF_TYPE_VIDEO_CAPTURE\n"));
+
+		/* Check that the new frame rate is allowed. */
+		if ((timeperframe->numerator == 0)
+		    || (timeperframe->denominator == 0)) {
+			timeperframe->denominator = DEFAULT_FPS;
+			timeperframe->numerator = 1;
+		}
+		tgt_fps = timeperframe->denominator
+			  / timeperframe->numerator;
+
+		if (tgt_fps > MAX_FPS) {
+			timeperframe->denominator = MAX_FPS;
+			timeperframe->numerator = 1;
+		} else if (tgt_fps < MIN_FPS) {
+			timeperframe->denominator = MIN_FPS;
+			timeperframe->numerator = 1;
+		}
+		sensor->streamcap.timeperframe = *timeperframe;
+		sensor->streamcap.capturemode =
+				(u32)a->parm.capture.capturemode;
+
+		ret = ov3640_init_mode(sensor->streamcap.capturemode);
+		break;
+
+	/* These are all the possible cases. */
+	case V4L2_BUF_TYPE_VIDEO_OUTPUT:
+	case V4L2_BUF_TYPE_VIDEO_OVERLAY:
+	case V4L2_BUF_TYPE_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_VBI_OUTPUT:
+	case V4L2_BUF_TYPE_SLICED_VBI_CAPTURE:
+	case V4L2_BUF_TYPE_SLICED_VBI_OUTPUT:
+		pr_debug("   type is not " \
+			"V4L2_BUF_TYPE_VIDEO_CAPTURE but %d\n",
+			a->type);
+		ret = -EINVAL;
+		break;
+
+	default:
+		pr_debug("   type is unknown - %d\n", a->type);
+		ret = -EINVAL;
+		break;
+	}
 
+	return ret;
 }
 
-static void ov3640_set_ae_mode(int ae_mode)
+/*!
+ * ioctl_g_fmt_cap - V4L2 sensor interface handler for ioctl_g_fmt_cap
+ * @s: pointer to standard V4L2 device structure
+ * @f: pointer to standard V4L2 v4l2_format structure
+ *
+ * Returns the sensor's current pixel format in the v4l2_format
+ * parameter.
+ */
+static int ioctl_g_fmt_cap(struct v4l2_int_device *s, struct v4l2_format *f)
 {
+	struct sensor *sensor = s->priv;
+
+	CAMERA_TRACE(("In ov3640:ioctl_g_fmt_cap.\n"));
 
+	f->fmt.pix = sensor->pix;
+
+	return 0;
 }
 
-static void ov3640_get_ae_mode(int *ae_mode)
+/*!
+ * ioctl_g_ctrl - V4L2 sensor interface handler for VIDIOC_G_CTRL ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @vc: standard V4L2 VIDIOC_G_CTRL ioctl structure
+ *
+ * If the requested control is supported, returns the control's current
+ * value from the video_control[] array.  Otherwise, returns -EINVAL
+ * if the control is not supported.
+ */
+static int ioctl_g_ctrl(struct v4l2_int_device *s, struct v4l2_control *vc)
 {
+	int ret = 0;
+
+	CAMERA_TRACE(("In ov3640:ioctl_g_ctrl\n"));
+	switch (vc->id) {
+	case V4L2_CID_BRIGHTNESS:
+		vc->value = ov3640_data.brightness;
+		break;
+	case V4L2_CID_HUE:
+		vc->value = ov3640_data.hue;
+		break;
+	case V4L2_CID_CONTRAST:
+		vc->value = ov3640_data.contrast;
+		break;
+	case V4L2_CID_SATURATION:
+		vc->value = ov3640_data.saturation;
+		break;
+	case V4L2_CID_RED_BALANCE:
+		vc->value = ov3640_data.red;
+		break;
+	case V4L2_CID_BLUE_BALANCE:
+		vc->value = ov3640_data.blue;
+		break;
+	case V4L2_CID_EXPOSURE:
+		vc->value = ov3640_data.ae_mode;
+		break;
+	default:
+		ret = -EINVAL;
+	}
 
+	return ret;
 }
 
-static void ov3640_set_std_mode(v4l2_std_id std)
+/*!
+ * ioctl_s_ctrl - V4L2 sensor interface handler for VIDIOC_S_CTRL ioctl
+ * @s: pointer to standard V4L2 device structure
+ * @vc: standard V4L2 VIDIOC_S_CTRL ioctl structure
+ *
+ * If the requested control is supported, sets the control's current
+ * value in HW (and updates the video_control[] array).  Otherwise,
+ * returns -EINVAL if the control is not supported.
+ */
+static int ioctl_s_ctrl(struct v4l2_int_device *s, struct v4l2_control *vc)
 {
+	int retval = 0;
+
+	pr_debug("In ov3640:ioctl_s_ctrl %d\n",
+		 vc->id);
+
+	switch (vc->id) {
+	case V4L2_CID_BRIGHTNESS:
+		CAMERA_TRACE(("   V4L2_CID_BRIGHTNESS\n"));
+		break;
+	case V4L2_CID_CONTRAST:
+		CAMERA_TRACE(("   V4L2_CID_CONTRAST\n"));
+		break;
+	case V4L2_CID_SATURATION:
+		CAMERA_TRACE(("   V4L2_CID_SATURATION\n"));
+		break;
+	case V4L2_CID_HUE:
+		CAMERA_TRACE(("   V4L2_CID_HUE\n"));
+		break;
+	case V4L2_CID_AUTO_WHITE_BALANCE:
+		CAMERA_TRACE(("   V4L2_CID_AUTO_WHITE_BALANCE\n"));
+		break;
+	case V4L2_CID_DO_WHITE_BALANCE:
+		CAMERA_TRACE(("   V4L2_CID_DO_WHITE_BALANCE\n"));
+		break;
+	case V4L2_CID_RED_BALANCE:
+		CAMERA_TRACE(("   V4L2_CID_RED_BALANCE\n"));
+		break;
+	case V4L2_CID_BLUE_BALANCE:
+		CAMERA_TRACE(("   V4L2_CID_BLUE_BALANCE\n"));
+		break;
+	case V4L2_CID_GAMMA:
+		CAMERA_TRACE(("   V4L2_CID_GAMMA\n"));
+		break;
+	case V4L2_CID_EXPOSURE:
+		CAMERA_TRACE(("   V4L2_CID_EXPOSURE\n"));
+		break;
+	case V4L2_CID_AUTOGAIN:
+		CAMERA_TRACE(("   V4L2_CID_AUTOGAIN\n"));
+		break;
+	case V4L2_CID_GAIN:
+		CAMERA_TRACE(("   V4L2_CID_GAIN\n"));
+		break;
+	case V4L2_CID_HFLIP:
+		CAMERA_TRACE(("   V4L2_CID_HFLIP\n"));
+		break;
+	case V4L2_CID_VFLIP:
+		CAMERA_TRACE(("   V4L2_CID_VFLIP\n"));
+		break;
+	default:
+		CAMERA_TRACE(("   Default case\n"));
+		retval = -EPERM;
+		break;
+	}
 
+	return retval;
 }
 
-static void ov3640_get_std_mode(v4l2_std_id * std)
+/*!
+ * ioctl_init - V4L2 sensor interface handler for VIDIOC_INT_INIT
+ * @s: pointer to standard V4L2 device structure
+ */
+static int ioctl_init(struct v4l2_int_device *s)
 {
+	CAMERA_TRACE(("In ov3640:ioctl_init\n"));
 
+	return 0;
 }
 
-static sensor_interface *ov3640_config(int *frame_rate, int mode)
+/*!
+ * ioctl_dev_init - V4L2 sensor interface handler for vidioc_int_dev_init_num
+ * @s: pointer to standard V4L2 device structure
+ *
+ * Initialise the device when slave attaches to the master.
+ */
+static int ioctl_dev_init(struct v4l2_int_device *s)
 {
+	struct sensor *sensor = s->priv;
+	u32 tgt_xclk;	/* target xclk */
 
-	u32 u32OutWidth  = 0;
-	u32 u32OutHeight = 0;
+	CAMERA_TRACE(("In ov3640:ioctl_dev_init\n"));
 
-	CAMERA_TRACE(("CAMERA_DBG Entry: ov3640_config\n"));
 
-	if (mode > ov3640_mode_MAX || mode < ov3640_mode_MIN) {
-		dev_dbg(&ov3640_i2c_client->dev,
-				"Wrong ov3640 mode detected!\n");
-		return NULL;
+	gpio_sensor_active(ov3640_data.csi);
+	ov3640_data.on = true;
+
+	tgt_xclk = ov3640_data.mclk;
+	tgt_xclk = min(tgt_xclk, (u32)OV3640_XCLK_MAX);
+	tgt_xclk = max(tgt_xclk, (u32)OV3640_XCLK_MIN);
+	ov3640_data.mclk = tgt_xclk;
+
+	pr_debug("   Setting mclk to %d MHz\n", tgt_xclk / 1000000);
+	set_mclk_rate(&ov3640_data.mclk, ov3640_data.csi);
+
+	return ov3640_init_mode(sensor->streamcap.capturemode);
+}
+
+/*!
+ * This structure defines all the ioctls for this module and links them to the
+ * enumeration.
+ */
+static struct v4l2_int_ioctl_desc ov3640_ioctl_desc[] = {
+	{vidioc_int_dev_init_num, (v4l2_int_ioctl_func *)ioctl_dev_init},
+/*	{vidioc_int_dev_exit_num, (v4l2_int_ioctl_func *)ioctl_dev_exit}, */
+	{vidioc_int_s_power_num, (v4l2_int_ioctl_func *)ioctl_s_power},
+	{vidioc_int_g_ifparm_num, (v4l2_int_ioctl_func *)ioctl_g_ifparm},
+/*	{vidioc_int_g_needs_reset_num,
+				(v4l2_int_ioctl_func *)ioctl_g_needs_reset}, */
+/*	{vidioc_int_reset_num, (v4l2_int_ioctl_func *)ioctl_reset}, */
+	{vidioc_int_init_num, (v4l2_int_ioctl_func *)ioctl_init},
+/*	{vidioc_int_enum_fmt_cap_num,
+				(v4l2_int_ioctl_func *)ioctl_enum_fmt_cap}, */
+/*	{vidioc_int_try_fmt_cap_num,
+				(v4l2_int_ioctl_func *)ioctl_try_fmt_cap}, */
+	{vidioc_int_g_fmt_cap_num, (v4l2_int_ioctl_func *)ioctl_g_fmt_cap},
+/*	{vidioc_int_s_fmt_cap_num, (v4l2_int_ioctl_func *)ioctl_s_fmt_cap}, */
+	{vidioc_int_g_parm_num, (v4l2_int_ioctl_func *)ioctl_g_parm},
+	{vidioc_int_s_parm_num, (v4l2_int_ioctl_func *)ioctl_s_parm},
+/*	{vidioc_int_queryctrl_num, (v4l2_int_ioctl_func *)ioctl_queryctrl}, */
+	{vidioc_int_g_ctrl_num, (v4l2_int_ioctl_func *)ioctl_g_ctrl},
+	{vidioc_int_s_ctrl_num, (v4l2_int_ioctl_func *)ioctl_s_ctrl},
+};
+
+static struct v4l2_int_slave ov3640_slave = {
+	.ioctls = ov3640_ioctl_desc,
+	.num_ioctls = ARRAY_SIZE(ov3640_ioctl_desc),
+};
+
+static struct v4l2_int_device ov3640_int_device = {
+	.module = THIS_MODULE,
+	.name = "ov3640",
+	.type = v4l2_int_type_slave,
+	.u = {
+		.slave = &ov3640_slave,
+	},
+};
+
+/*!
+ * ov3640 I2C probe function
+ *
+ * @param adapter            struct i2c_adapter *
+ * @return  Error code indicating success or failure
+ */
+static int ov3640_probe(struct i2c_client *client,
+			const struct i2c_device_id *id)
+{
+	int retval;
+	struct mxc_camera_platform_data *plat_data = client->dev.platform_data;
+
+	CAMERA_TRACE(("CAMERA_DBG Entry: ov3640_probe\n"));
+
+	/* Set initial values for the sensor struct. */
+	memset(&ov3640_data, 0, sizeof(ov3640_data));
+	ov3640_data.mclk = 24000000; /* 6 - 54 MHz, typical 24MHz */
+	ov3640_data.mclk = plat_data->mclk;
+	ov3640_data.csi = plat_data->csi;
+
+	ov3640_data.i2c_client = client;
+	ov3640_data.pix.pixelformat = V4L2_PIX_FMT_UYVY;
+	ov3640_data.pix.width = 640;
+	ov3640_data.pix.height = 480;
+	ov3640_data.streamcap.capability = V4L2_MODE_HIGHQUALITY
+					   | V4L2_CAP_TIMEPERFRAME;
+	ov3640_data.streamcap.capturemode = 0;
+	ov3640_data.streamcap.timeperframe.denominator = DEFAULT_FPS;
+	ov3640_data.streamcap.timeperframe.numerator = 1;
+
+	io_regulator = regulator_get(&client->dev, plat_data->io_regulator);
+	if (!IS_ERR_VALUE((u32)io_regulator)) {
+		regulator_set_voltage(io_regulator, OV3640_VOLTAGE_DIGITAL_IO);
+		if (regulator_enable(io_regulator) != 0) {
+			pr_err("%s:io set voltage error\n", __func__);
+			goto err1;
+		} else {
+			dev_dbg(&client->dev,
+				"%s:io set voltage ok\n", __func__);
+		}
 	}
 
-	CAMERA_TRACE(("mode: %d\n", mode));
+	core_regulator = regulator_get(&client->dev, plat_data->core_regulator);
+	if (!IS_ERR_VALUE((u32)core_regulator)) {
+		regulator_set_voltage(core_regulator,
+				      OV3640_VOLTAGE_DIGITAL_CORE);
+		if (regulator_enable(core_regulator) != 0) {
+			pr_err("%s:core set voltage error\n", __func__);
+			goto err2;
+		} else {
+			dev_dbg(&client->dev,
+				"%s:core set voltage ok\n", __func__);
+		}
+	}
 
-	u32OutWidth  = ov3640_mode_info_data[mode].width;
-	u32OutHeight = ov3640_mode_info_data[mode].height;
+	analog_regulator =
+		regulator_get(&client->dev, plat_data->analog_regulator);
+	if (!IS_ERR_VALUE((u32)analog_regulator)) {
+		regulator_set_voltage(analog_regulator, OV3640_VOLTAGE_ANALOG);
+		if (regulator_enable(analog_regulator) != 0) {
+			pr_err("%s:analog set voltage error\n", __func__);
+			goto err3;
+		} else {
+			dev_dbg(&client->dev,
+				"%s:analog set voltage ok\n", __func__);
+		}
+	}
 
-	ov3640_interface(interface_param, u32OutWidth, u32OutHeight);
-	set_mclk_rate(&interface_param->mclk, s32csi_index);
+	gpo_regulator = regulator_get(&client->dev, plat_data->gpo_regulator);
+	if (!IS_ERR_VALUE((u32)gpo_regulator)) {
+		if (regulator_enable(gpo_regulator) != 0) {
+			pr_err("%s:gpo3 enable error\n", __func__);
+			goto err4;
+		} else {
+			dev_dbg(&client->dev,
+				"%s:gpo3 enable ok\n", __func__);
+		}
+	}
 
-	ov3640_init_mode(mode);
+	ov3640_int_device.priv = &ov3640_data;
+	retval = v4l2_int_device_register(&ov3640_int_device);
 
-	CAMERA_TRACE(("CAMERA_DBG Exit: ov3640_config\n"));
+	return retval;
 
-	return interface_param;
+err4:
+	if (!IS_ERR_VALUE((u32)analog_regulator)) {
+		regulator_disable(analog_regulator);
+		regulator_put(analog_regulator, &client->dev);
+	}
+err3:
+	if (!IS_ERR_VALUE((u32)core_regulator)) {
+		regulator_disable(core_regulator);
+		regulator_put(core_regulator, &client->dev);
+	}
+err2:
+	if (!IS_ERR_VALUE((u32)io_regulator)) {
+		regulator_disable(io_regulator);
+		regulator_put(io_regulator, &client->dev);
+	}
+err1:
+	return -1;
 }
 
-static sensor_interface *ov3640_reset(void)
+/*!
+ * ov3640 I2C detach function
+ *
+ * @param client            struct i2c_client *
+ * @return  Error code indicating success or failure
+ */
+static int ov3640_remove(struct i2c_client *client)
 {
-	CAMERA_TRACE(("CAMERA_DBG Entry: ov3640_reset\n"));
+	CAMERA_TRACE(("In ov3640_remove\n"));
 
-	return ov3640_config(&reset_frame_rate, ov3640_mode_VGA_640_480);
-}
+	v4l2_int_device_unregister(&ov3640_int_device);
 
-struct camera_sensor camera_sensor_if = {
-	.set_color =   ov3640_set_color,
-	.get_color =   ov3640_get_color,
-	.set_ae_mode = ov3640_set_ae_mode,
-	.get_ae_mode = ov3640_get_ae_mode,
-	.config =      ov3640_config,
-	.reset =       ov3640_reset,
-	.set_std =     ov3640_set_std_mode,
-	.get_std =     ov3640_get_std_mode,
-};
+	if (!IS_ERR_VALUE((unsigned long)gpo_regulator)) {
+		regulator_disable(gpo_regulator);
+		regulator_put(gpo_regulator, &client->dev);
+	}
+
+	if (!IS_ERR_VALUE((unsigned long)analog_regulator)) {
+		regulator_disable(analog_regulator);
+		regulator_put(analog_regulator, &client->dev);
+	}
 
-EXPORT_SYMBOL(camera_sensor_if);
+	if (!IS_ERR_VALUE((unsigned long)core_regulator)) {
+		regulator_disable(core_regulator);
+		regulator_put(core_regulator, &client->dev);
+	}
 
-extern void gpio_sensor_active(unsigned int csi_index);
+	if (!IS_ERR_VALUE((unsigned long)io_regulator)) {
+		regulator_disable(io_regulator);
+		regulator_put(io_regulator, &client->dev);
+	}
+
+	return 0;
+}
 
 /*!
  * ov3640 init function
+ * Called by insmod ov3640_camera.ko.
  *
  * @return  Error code indicating success or failure
  */
@@ -616,19 +911,19 @@ static __init int ov3640_init(void)
 
 	CAMERA_TRACE(("CAMERA_DBG Entry: ov3640_init\n"));
 
-	gpio_sensor_active(s32csi_index);
-
 	err = i2c_add_driver(&ov3640_i2c_driver);
+	if (err != 0)
+		pr_err("%s:driver registration failed, error=%d \n",
+			__func__, err);
 
 	CAMERA_TRACE(("CAMERA_DBG Exit: ov3640_init\n"));
 
 	return err;
 }
 
-extern void gpio_sensor_inactive(unsigned int csi);
-
 /*!
  * OV3640 cleanup function
+ * Called on rmmod ov3640_camera.ko
  *
  * @return  Error code indicating success or failure
  */
@@ -637,8 +932,7 @@ static void __exit ov3640_clean(void)
 	CAMERA_TRACE(("CAMERA_DBG Entry: ov3640_clean\n"));
 
 	i2c_del_driver(&ov3640_i2c_driver);
-
-	gpio_sensor_inactive(s32csi_index);
+	gpio_sensor_inactive(ov3640_data.csi);
 
 	CAMERA_TRACE(("CAMERA_DBG Exit: ov3640_clean\n"));
 }
diff --git a/drivers/media/video/v4l2-int-device.c b/drivers/media/video/v4l2-int-device.c
index 0e45499..820a745 100644
--- a/drivers/media/video/v4l2-int-device.c
+++ b/drivers/media/video/v4l2-int-device.c
@@ -145,6 +145,8 @@ int v4l2_int_ioctl_0(struct v4l2_int_device *d, int cmd)
 			   (v4l2_int_ioctl_func *)no_such_ioctl_0))(d);
 }
 
+EXPORT_SYMBOL(v4l2_int_ioctl_0);
+
 static int no_such_ioctl_1(struct v4l2_int_device *d, void *arg)
 {
 	return -ENOIOCTLCMD;
@@ -157,4 +159,5 @@ int v4l2_int_ioctl_1(struct v4l2_int_device *d, int cmd, void *arg)
 			   (v4l2_int_ioctl_func *)no_such_ioctl_1))(d, arg);
 }
 
-MODULE_LICENSE("GPL");
+EXPORT_SYMBOL(v4l2_int_ioctl_1);
+
-- 
1.5.4.4

